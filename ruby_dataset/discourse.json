[
  {
    "raw_code": "def murder_lazy_workers\n        next_sleep = @timeout - 1\n        now = time_now.to_i\n        @workers.dup.each_pair do |wpid, worker|\n          tick = worker.tick\n          0 == tick and next # skip workers that haven't processed any clients\n          diff = now - tick\n          tmp = @timeout - diff\n\n          # START MONKEY PATCH\n          if tmp < 2 && !worker.instance_variable_get(:@timing_out_logged)\n            logger.error do\n              \"worker=#{worker.nr} PID:#{wpid} running too long (#{diff}s), sending USR2 to dump thread backtraces\"\n            end",
    "comment": "Original source: https://github.com/defunkt/unicorn/blob/6c9c442fb6aa12fd871237bc2bb5aec56c5b3538/lib/unicorn/http_server.rb#L477-L496",
    "label": "",
    "id": "1"
  },
  {
    "raw_code": "def self.deep_delete_matches(deleting_from, checking_hashes)\n    checking_hashes.compact!\n\n    new_hash = deleting_from.dup\n    deleting_from.each do |key, value|\n      if value.is_a?(Hash)\n        new_at_key = deep_delete_matches(deleting_from[key], checking_hashes.map { |h| h[key] })\n        if new_at_key.empty?\n          new_hash.delete(key)\n        else\n          new_hash[key] = new_at_key\n        end",
    "comment": "deeply removes keys from \"deleting_from\" that are already present in \"checking_hashes\"",
    "label": "",
    "id": "2"
  },
  {
    "raw_code": "def can_see?(obj)\n    if obj\n      see_method = method_name_for :see, obj\n      see_method && public_send(see_method, obj)\n    end",
    "comment": "Can the user see the object?",
    "label": "",
    "id": "3"
  },
  {
    "raw_code": "def can_edit?(obj)\n    can_do?(:edit, obj)\n  end",
    "comment": "Can the user edit the obj",
    "label": "",
    "id": "4"
  },
  {
    "raw_code": "def can_delete?(obj)\n    can_do?(:delete, obj)\n  end",
    "comment": "Can we delete the object",
    "label": "",
    "id": "5"
  },
  {
    "raw_code": "def can_impersonate?(target)\n    GlobalSetting.allow_impersonation && target &&\n      # You must be an admin to impersonate\n      is_admin? &&\n      # You may not impersonate other admins unless you are a dev\n      (!target.admin? || is_developer?)\n\n    # Additionally, you may not impersonate yourself;\n    # but the two tests for different admin statuses\n    # make it impossible to be the same user.\n  end",
    "comment": "Can we impersonate this user?",
    "label": "",
    "id": "6"
  },
  {
    "raw_code": "def can_approve?(target)\n    is_staff? && target && target.active? && !target.approved?\n  end",
    "comment": "Can we approve it?",
    "label": "",
    "id": "7"
  },
  {
    "raw_code": "def can_access_forum?\n    return true unless SiteSetting.must_approve_users?\n    return false if anonymous?\n\n    # Staff can't lock themselves out of a site\n    return true if is_staff?\n\n    @user.approved?\n  end",
    "comment": "Support sites that have to approve users",
    "label": "",
    "id": "8"
  },
  {
    "raw_code": "def can_send_private_messages?(notify_moderators: false)\n    from_system = @user.is_system_user?\n    from_bot = @user.bot?\n\n    # User is authenticated\n    authenticated? &&\n      # User can send PMs, this can be covered by trust levels as well via AUTO_GROUPS\n      (\n        from_bot || from_system || notify_moderators ||\n          @user.in_any_groups?(SiteSetting.personal_message_enabled_groups_map)\n      )\n  end",
    "comment": " This should be used as a general, but not definitive, check for whether the user can send private messages _generally_, which is mostly useful for changing the UI.  Please otherwise use can_send_private_message?(target, notify_moderators) to check if a single target can be messaged.",
    "label": "",
    "id": "9"
  },
  {
    "raw_code": "def can_send_private_message?(target, notify_moderators: false)\n    target_is_user = target.is_a?(User)\n    target_is_group = target.is_a?(Group)\n    from_system = @user.is_system_user?\n\n    # Must be a valid target\n    return false if !(target_is_group || target_is_user)\n\n    can_send_private_message =\n      DiscoursePluginRegistry.apply_modifier(\n        :guardian_can_send_private_message,\n        target: target,\n        user: @user,\n      )\n    return false if !can_send_private_message\n\n    # Users can send messages to certain groups with the `everyone` messageable_level\n    # even if they are not in personal_message_enabled_groups\n    group_is_messageable = target_is_group && Group.messageable(@user).where(id: target.id).exists?\n\n    # User is authenticated and can send PMs, this can be covered by trust levels as well via AUTO_GROUPS\n    (can_send_private_messages?(notify_moderators: notify_moderators) || group_is_messageable) &&\n      # User disabled private message\n      (is_staff? || target_is_group || target.user_option.allow_private_messages) &&\n      # Can't send PMs to suspended users\n      (is_staff? || target_is_group || !target.suspended?) &&\n      # Check group messageable level\n      (from_system || target_is_user || group_is_messageable || notify_moderators) &&\n      # Silenced users can only send PM to staff\n      (!is_silenced? || target.staff?)\n  end",
    "comment": " This should be used as a final check for when a user is sending a message to a target user or group.",
    "label": "",
    "id": "10"
  },
  {
    "raw_code": "def can_view?(user_id: nil, group_ids: nil)\n    return true if config.public\n    return true if user_id && config.allowed_user_ids&.include?(user_id)\n\n    if user_id && config.allowed_group_ids.present?\n      return true if config.allowed_group_ids.include?(Group::AUTO_GROUPS[:everyone])\n      group_ids ||= GroupUser.where(user_id: user_id).pluck(\"group_id\")\n      return true if (group_ids & config.allowed_group_ids).present?\n    end",
    "comment": "Is this user allowed to view this channel? Pass `nil` for anonymous viewers",
    "label": "",
    "id": "11"
  },
  {
    "raw_code": "def can_enter?(user_id: nil, group_ids: nil)\n    return false if user_id.nil?\n    can_view?(user_id: user_id, group_ids: group_ids)\n  end",
    "comment": "Is a user allowed to enter this channel? Currently equal to the can_view? permission",
    "label": "",
    "id": "12"
  },
  {
    "raw_code": "def present(user_id:, client_id:)\n    raise PresenceChannel::InvalidAccess if !can_enter?(user_id: user_id)\n\n    mutex_value = SecureRandom.hex\n    result =\n      retry_on_mutex_error do\n        PresenceChannel.redis_eval(\n          :present,\n          redis_keys,\n          [name, user_id, client_id, (Time.zone.now + timeout).to_i, mutex_value],\n        )\n      end",
    "comment": "Mark a user's client as present in this channel. The client_id should be unique per browser tab. This method should be called repeatedly (at least once every DEFAULT_TIMEOUT) while the user is present in the channel.",
    "label": "",
    "id": "13"
  },
  {
    "raw_code": "def leave(user_id:, client_id:)\n    mutex_value = SecureRandom.hex\n    result =\n      retry_on_mutex_error do\n        PresenceChannel.redis_eval(:leave, redis_keys, [name, user_id, client_id, \"\", mutex_value])\n      end",
    "comment": "Immediately mark a user's client as leaving the channel",
    "label": "",
    "id": "14"
  },
  {
    "raw_code": "def state(count_only: config.count_only)\n    if count_only\n      last_id, count = retry_on_mutex_error { PresenceChannel.redis_eval(:count, redis_keys) }\n    else\n      last_id, ids = retry_on_mutex_error { PresenceChannel.redis_eval(:user_ids, redis_keys) }\n    end",
    "comment": "Fetch a {PresenceChannel::State} instance representing the current state of this  @param [Boolean] count_only set true to skip fetching the list of user ids from redis",
    "label": "",
    "id": "15"
  },
  {
    "raw_code": "def auto_leave\n    mutex_value = SecureRandom.hex\n    left_user_ids =\n      retry_on_mutex_error do\n        PresenceChannel.redis_eval(:auto_leave, redis_keys, [name, Time.zone.now.to_i, mutex_value])\n      end",
    "comment": "Automatically expire all users which have not been 'present' for more than +DEFAULT_TIMEOUT+",
    "label": "",
    "id": "16"
  },
  {
    "raw_code": "def clear\n    PresenceChannel.redis.del(redis_key_zlist)\n    PresenceChannel.redis.del(redis_key_hash)\n    PresenceChannel.redis.del(redis_key_config)\n    PresenceChannel.redis.del(redis_key_mutex)\n    PresenceChannel.redis.zrem(self.class.redis_key_channel_list, name)\n  end",
    "comment": "Clear all members of the channel. This is intended for debugging/development only",
    "label": "",
    "id": "17"
  },
  {
    "raw_code": "def self.auto_leave_all\n    channels_with_expiring_members =\n      PresenceChannel.redis.zrangebyscore(redis_key_channel_list, \"-inf\", Time.zone.now.to_i)\n    channels_with_expiring_members.each { |name| new(name, raise_not_found: false).auto_leave }\n  end",
    "comment": "Designed to be run periodically. Checks the channel list for channels with expired members, and runs auto_leave for each eligible channel",
    "label": "",
    "id": "18"
  },
  {
    "raw_code": "def self.clear_all!\n    channels = PresenceChannel.redis.zrangebyscore(redis_key_channel_list, \"-inf\", \"+inf\")\n    channels.each { |name| new(name, raise_not_found: false).clear }\n\n    config_cache_keys =\n      PresenceChannel\n        .redis\n        .scan_each(match: Discourse.redis.namespace_key(\"_presence_*_config\"))\n        .to_a\n    PresenceChannel.redis.del(*config_cache_keys) if config_cache_keys.present?\n  end",
    "comment": "Clear all known channels. This is intended for debugging/development only",
    "label": "",
    "id": "19"
  },
  {
    "raw_code": "def self.redis\n    if MessageBus.backend == :redis\n      MessageBus.backend_instance.send(:pub_redis) # TODO: avoid a private API?\n    elsif Rails.env.test?\n      Discourse.redis.without_namespace\n    else\n      raise \"PresenceChannel is unable to access MessageBus's Redis instance\"\n    end",
    "comment": "Shortcut to access a redis client for all PresenceChannel activities. PresenceChannel must use the same Redis server as MessageBus, so that actions can be applied atomically. For the vast majority of Discourse installations, this is the same Redis server as `Discourse.redis`.",
    "label": "",
    "id": "20"
  },
  {
    "raw_code": "def self.register_prefix(prefix, &block)\n    unless prefix.match? /[a-zA-Z0-9_-]+/\n      raise \"PresenceChannel prefix #{prefix} must match [a-zA-Z0-9_-]+\"\n    end",
    "comment": "Register a callback to configure channels with a given prefix Prefix must match [a-zA-Z0-9_-]+  For example, this registration will be used for all channels starting /topic-reply/...:  register_prefix(\"topic-reply\") do |channel_name| PresenceChannel::Config.new(public: true) end  At runtime, the block will be passed a full channel name. If the channel should not exist, the block should return `nil`. If the channel should exist, the block should return a PresenceChannel::Config object.  Return values may be cached for up to 10 seconds.  Plugins should use the {Plugin::Instance.register_presence_channel_prefix} API instead",
    "label": "",
    "id": "21"
  },
  {
    "raw_code": "def self.unregister_prefix(prefix)\n    raise \"Only allowed in test environment\" if !Rails.env.test?\n    @@configuration_blocks&.delete(prefix)\n  end",
    "comment": "For use in a test environment only",
    "label": "",
    "id": "22"
  },
  {
    "raw_code": "def redis_key_mutex\n    Discourse.redis.namespace_key(\"_presence_#{name}_mutex\")\n  end",
    "comment": "Most atomic actions are achieved via lua scripts. However, when a lua action will result in publishing a messagebus message, the atomicity is broken.  For example, if one process is handling a 'user enter' event, and another is handling a 'user leave' event, we need to make sure the messagebus messages are published in the same sequence that the PresenceChannel lua script are run.  The present/leave/auto_leave lua scripts will automatically acquire this mutex if needed. If their return value indicates a change has occurred, the mutex should be released via #release_mutex after the messagebus message has been sent  If they need a change, and the mutex is not available, they will raise an error and should be retried periodically",
    "label": "",
    "id": "23"
  },
  {
    "raw_code": "def message_bus_last_id_key\n    return \"\" if Rails.env.test? && MessageBus.backend == :memory\n\n    # TODO: Avoid using private MessageBus methods here\n    encoded_channel_name = MessageBus.send(:encode_channel_name, message_bus_channel_name)\n    MessageBus.backend_instance.send(:backlog_id_key, encoded_channel_name)\n  end",
    "comment": "The redis key which MessageBus uses to store the 'last_id' for the channel associated with this PresenceChannel.",
    "label": "",
    "id": "24"
  },
  {
    "raw_code": "def redis_key_zlist\n    Discourse.redis.namespace_key(\"_presence_#{name}_zlist\")\n  end",
    "comment": "The zlist is a list of client_ids, ranked by their expiration timestamp we periodically delete the 'lowest ranked' items in this list based on the `timeout` of the channel",
    "label": "",
    "id": "25"
  },
  {
    "raw_code": "def redis_key_hash\n    Discourse.redis.namespace_key(\"_presence_#{name}_hash\")\n  end",
    "comment": "The hash contains a map of user_id => session_count when the count for a user reaches 0, the key is deleted We use this hash to efficiently count the number of present users",
    "label": "",
    "id": "26"
  },
  {
    "raw_code": "def redis_key_config\n    Discourse.redis.namespace_key(\"_presence_#{name}_config\")\n  end",
    "comment": "The hash contains a map of user_id => session_count when the count for a user reaches 0, the key is deleted We use this hash to efficiently count the number of present users",
    "label": "",
    "id": "27"
  },
  {
    "raw_code": "def self.redis_key_channel_list\n    Discourse.redis.namespace_key(\"_presence_channels\")\n  end",
    "comment": "This list contains all active presence channels, ranked with the expiration timestamp of their least-recently-seen  client_id We periodically check the 'lowest ranked' items in this list based on the `timeout` of the channel",
    "label": "",
    "id": "28"
  },
  {
    "raw_code": "def entropy\n    @entropy ||= @text.strip.bytes.uniq.size\n  end",
    "comment": "Number of unique bytes",
    "label": "",
    "id": "29"
  },
  {
    "raw_code": "def seems_meaningful?\n    @opts[:min_entropy].nil? || entropy >= @opts[:min_entropy]\n  end",
    "comment": "Ensure minimum entropy",
    "label": "",
    "id": "30"
  },
  {
    "raw_code": "def seems_pronounceable?\n    @text.match?(/\\p{Alnum}/)\n  end",
    "comment": "At least one non-symbol character",
    "label": "",
    "id": "31"
  },
  {
    "raw_code": "def seems_unpretentious?\n    skipped_locales.include?(SiteSetting.default_locale) || @opts[:max_word_length].nil? ||\n      !@text.match?(/\\p{Alnum}{#{@opts[:max_word_length] + 1},}/)\n  end",
    "comment": "Ensure maximum word length",
    "label": "",
    "id": "32"
  },
  {
    "raw_code": "def seems_quiet?\n    SiteSetting.allow_uppercase_posts || @text.match?(/\\p{Lowercase_Letter}|\\p{Other_Letter}/) ||\n      !@text.match?(/\\p{Letter}/)\n  end",
    "comment": "Ensure at least one lowercase letter",
    "label": "",
    "id": "33"
  },
  {
    "raw_code": "def skipped_locales\n    @skipped_locales ||= %w[ja ko zh_CN zh_TW].freeze\n  end",
    "comment": "Hard to tell \"word length\" for CJK languages",
    "label": "",
    "id": "34"
  },
  {
    "raw_code": "def filter_users(values:)\n    values.each do |prefix, value|\n      require_all, usernames = calculate_all_or_any(value)\n\n      if usernames.empty?\n        @scope = @scope.none\n        next\n      end",
    "comment": "users:a,b => any of a or b participated in the topic users:a+b => both a and b participated in the topic -users:a,b => neither a nor b participated in the topic -users:a+b => at least one of a or b did not participate in the topic",
    "label": "",
    "id": "35"
  },
  {
    "raw_code": "def filter_groups(values:)\n    values.each do |value|\n      require_all, group_names = calculate_all_or_any(value)\n\n      if group_names.empty?\n        @scope = @scope.none\n        next\n      end",
    "comment": "group:staff,moderators => any of the groups have participation group:staff+moderators => both groups have participation",
    "label": "",
    "id": "36"
  },
  {
    "raw_code": "def tag_ids_from_tag_names(tag_names)\n    tag_ids, alias_tag_ids =\n      DiscourseTagging\n        .filter_visible(Tag, @guardian)\n        .where_name(tag_names)\n        .pluck(:id, :target_tag_id)\n        .transpose\n\n    tag_ids ||= []\n    alias_tag_ids ||= []\n\n    yield(tag_ids, alias_tag_ids) if block_given?\n\n    all_tag_ids = tag_ids.concat(alias_tag_ids)\n    all_tag_ids.compact!\n    all_tag_ids.uniq!\n    all_tag_ids\n  end",
    "comment": "Accepts an array of tag names and returns an array of tag ids and the tag ids of aliases for the tag names which the user can see. If a block is given, it will be called with the tag ids and alias tag ids as arguments.",
    "label": "",
    "id": "37"
  },
  {
    "raw_code": "def get(redirects = @limit, extra_headers: {}, except_headers: [], &blk)\n    raise \"Must specify block\" unless block_given?\n\n    if @uri && @uri.port == 80 && FinalDestination.is_https_domain?(@uri.hostname)\n      @uri.scheme = \"https\"\n      @uri = URI(@uri.to_s)\n    end",
    "comment": "this is a new interface for simply getting N bytes accounting for all internal logic",
    "label": "",
    "id": "38"
  },
  {
    "raw_code": "def initialize(string, options = [2], entities = {})\n    super string\n\n    @options = [*options]\n    @entities = default_entities.update(entities)\n  end",
    "comment": "Create a new RubyPants instance with the text in +string+.  Allowed elements in the options array:  0  :: do nothing 1  :: enable all, using only em-dash shortcuts 2  :: enable all, using old school en- and em-dash shortcuts (*default*) 3  :: enable all, using inverted old school en and em-dash shortcuts -1 :: stupefy (translate HTML entities to their ASCII-counterparts)  If you don't like any of these defaults, you can pass symbols to change RubyPants' behavior:  <tt>:quotes</tt>        :: quotes <tt>:backticks</tt>     :: backtick quotes (``double'' only) <tt>:allbackticks</tt>  :: backtick quotes (``double'' and `single') <tt>:dashes</tt>        :: dashes <tt>:oldschool</tt>     :: old school dashes <tt>:inverted</tt>      :: inverted old school dashes <tt>:ellipses</tt>      :: ellipses <tt>:convertquotes</tt> :: convert <tt>&quot;</tt> entities to <tt>\"</tt> <tt>:stupefy</tt>       :: translate RubyPants HTML entities to their ASCII counterparts.  In addition, you can customize the HTML entities that will be injected by passing in a hash for the final argument.  The defaults for these entities are as follows:  <tt>:single_left_quote</tt>  :: <tt>&#8216;</tt> <tt>:double_left_quote</tt>  :: <tt>&#8220;</tt> <tt>:single_right_quote</tt> :: <tt>&#8217;</tt> <tt>:double_right_quote</tt> :: <tt>&#8221;</tt> <tt>:em_dash</tt>            :: <tt>&#8212;</tt> <tt>:en_dash</tt>            :: <tt>&#8211;</tt> <tt>:ellipsis</tt>           :: <tt>&#8230;</tt> <tt>:html_quote</tt>         :: <tt>&quot; </tt> ",
    "label": "",
    "id": "39"
  },
  {
    "raw_code": "def to_html\n    do_quotes = do_backticks = do_dashes = do_ellipses = nil\n\n    if @options.include?(0)\n      # Do nothing.\n      return self\n    elsif @options.include?(1)\n      # Do everything, turn all options on.\n      do_quotes = do_backticks = do_ellipses = true\n      do_dashes = :normal\n    elsif @options.include?(2)\n      # Do everything, turn all options on, use old school dash shorthand.\n      do_quotes = do_backticks = do_ellipses = true\n      do_dashes = :oldschool\n    elsif @options.include?(3)\n      # Do everything, turn all options on, use inverted old school\n      # dash shorthand.\n      do_quotes = do_backticks = do_ellipses = true\n      do_dashes = :inverted\n    elsif @options.include?(-1)\n      do_stupefy = true\n    else\n      do_quotes = @options.include?(:quotes)\n      do_backticks = @options.include?(:backticks)\n      do_backticks = :both if @options.include?(:allbackticks)\n      do_dashes = :normal if @options.include?(:dashes)\n      do_dashes = :oldschool if @options.include?(:oldschool)\n      do_dashes = :inverted if @options.include?(:inverted)\n      do_ellipses = @options.include?(:ellipses)\n      do_stupefy = @options.include?(:stupefy)\n    end",
    "comment": "Apply SmartyPants transformations.",
    "label": "",
    "id": "40"
  },
  {
    "raw_code": "def educate_dashes(str)\n    str.gsub(/--/, entity(:em_dash))\n  end",
    "comment": "The string, with each instance of \"<tt>--</tt>\" translated to an em-dash HTML entity. ",
    "label": "",
    "id": "41"
  },
  {
    "raw_code": "def educate_dashes_oldschool(str)\n    str.gsub(/---/, entity(:em_dash)).gsub(/--/, entity(:en_dash))\n  end",
    "comment": "The string, with each instance of \"<tt>--</tt>\" translated to an en-dash HTML entity, and each \"<tt>---</tt>\" translated to an em-dash HTML entity. ",
    "label": "",
    "id": "42"
  },
  {
    "raw_code": "def educate_dashes_inverted(str)\n    str.gsub(/---/, entity(:en_dash)).gsub(/--/, entity(:em_dash))\n  end",
    "comment": "Return the string, with each instance of \"<tt>--</tt>\" translated to an em-dash HTML entity, and each \"<tt>---</tt>\" translated to an en-dash HTML entity. Two reasons why: First, unlike the en- and em-dash syntax supported by +educate_dashes_oldschool+, it's compatible with existing entries written before SmartyPants 1.1, back when \"<tt>--</tt>\" was only used for em-dashes.  Second, em-dashes are more common than en-dashes, and so it sort of makes sense that the shortcut should be shorter to type. (Thanks to Aaron Swartz for the idea.) ",
    "label": "",
    "id": "43"
  },
  {
    "raw_code": "def educate_ellipses(str)\n    str.gsub(\"...\", entity(:ellipsis)).gsub(\". . .\", entity(:ellipsis))\n  end",
    "comment": "Return the string, with each instance of \"<tt>...</tt>\" translated to an ellipsis HTML entity. Also converts the case where there are spaces between the dots. ",
    "label": "",
    "id": "44"
  },
  {
    "raw_code": "def educate_backticks(str)\n    str.gsub(\"``\", entity(:double_left_quote)).gsub(\"''\", entity(:double_right_quote))\n  end",
    "comment": "Return the string, with \"<tt>``backticks''</tt>\"-style single quotes translated into HTML curly quote entities. ",
    "label": "",
    "id": "45"
  },
  {
    "raw_code": "def educate_single_backticks(str)\n    str.gsub(\"`\", entity(:single_left_quote)).gsub(\"'\", entity(:single_right_quote))\n  end",
    "comment": "Return the string, with \"<tt>`backticks'</tt>\"-style single quotes translated into HTML curly quote entities. ",
    "label": "",
    "id": "46"
  },
  {
    "raw_code": "def educate_quotes(str)\n    punct_class = '[!\"#\\$\\%\\'()*+,\\-.\\/:;<=>?\\@\\[\\\\\\\\\\]\\^_`{|}~]'\n\n    # normalize html\n    str = str.dup\n    # Special case if the very first character is a quote followed by\n    # punctuation at a non-word-break. Close the quotes by brute\n    # force:\n    str.gsub!(/\\A'(?=#{punct_class}\\B)/, entity(:single_right_quote))\n    str.gsub!(/\\A\"(?=#{punct_class}\\B)/, entity(:double_right_quote))\n\n    # Special case for double sets of quotes, e.g.:\n    #   <p>He said, \"'Quoted' words in a larger quote.\"</p>\n    str.gsub!(/\"'(?=\\w)/, \"#{entity(:double_left_quote)}#{entity(:single_left_quote)}\")\n    str.gsub!(/'\"(?=\\w)/, \"#{entity(:single_left_quote)}#{entity(:double_left_quote)}\")\n\n    # Special case for decade abbreviations (the '80s):\n    str.gsub!(/'(?=\\d\\ds)/, entity(:single_right_quote))\n\n    close_class = %![^\\ \\t\\r\\n\\\\[\\{\\(\\-]!\n    dec_dashes = \"#{entity(:en_dash)}|#{entity(:em_dash)}\"\n\n    # Get most opening single quotes:\n    str.gsub!(\n      /(\\s|&nbsp;|=|--|&[mn]dash;|#{dec_dashes}|&#x201[34];)'(?=\\w)/,\n      '\\1' + entity(:single_left_quote),\n    )\n\n    # Single closing quotes:\n    str.gsub!(/(#{close_class})'/, '\\1' + entity(:single_right_quote))\n    str.gsub!(/'(\\s|s\\b|$)/, entity(:single_right_quote) + '\\1')\n\n    # Any remaining single quotes should be opening ones:\n    str.gsub!(/'/, entity(:single_left_quote))\n\n    # Get most opening double quotes:\n    str.gsub!(\n      /(\\s|&nbsp;|=|--|&[mn]dash;|#{dec_dashes}|&#x201[34];)\"(?=\\w)/,\n      '\\1' + entity(:double_left_quote),\n    )\n\n    # Double closing quotes:\n    str.gsub!(/(#{close_class})\"/, '\\1' + entity(:double_right_quote))\n    str.gsub!(/\"(\\s|s\\b|$)/, entity(:double_right_quote) + '\\1')\n\n    # Any remaining quotes should be opening ones:\n    str.gsub!(/\"/, entity(:double_left_quote))\n\n    str\n  end",
    "comment": "Return the string, with \"educated\" curly quote HTML entities. ",
    "label": "",
    "id": "47"
  },
  {
    "raw_code": "def stupefy_entities(str)\n    new_str = str.dup\n\n    {\n      en_dash: \"-\",\n      em_dash: \"--\",\n      single_left_quote: \"'\",\n      single_right_quote: \"'\",\n      double_left_quote: '\"',\n      double_right_quote: '\"',\n      ellipsis: \"...\",\n    }.each { |k, v| new_str.gsub!(/#{entity(k)}/, v) }\n\n    new_str\n  end",
    "comment": "Return the string, with each RubyPants HTML entity translated to its ASCII counterpart.  Note: This is not reversible (but exactly the same as in SmartyPants) ",
    "label": "",
    "id": "48"
  },
  {
    "raw_code": "def tokenize\n    tag_soup = /([^<]*)(<[^>]*>)/\n\n    tokens = []\n\n    prev_end = 0\n\n    scan(tag_soup) do\n      tokens << [:text, $1] if $1 != \"\"\n      tokens << [:tag, $2]\n      prev_end = $~.end(0)\n    end",
    "comment": "Return an array of the tokens comprising the string. Each token is either a tag (possibly with nested, tags contained therein, such as <tt><a href=\"<MTFoo>\"></tt>, or a run of text between tags. Each element of the array is a two-element array; the first is either :tag or :text; the second is the actual value.  Based on the <tt>_tokenize()</tt> subroutine from Brad Choate's MTRegex plugin.  <http://www.bradchoate.com/past/mtregex.php>  This is actually the easier variant using tag_soup, as used by Chad Miller in the Python port of SmartyPants. ",
    "label": "",
    "id": "49"
  },
  {
    "raw_code": "def self.disable\n    @disabled = true\n  end",
    "comment": "Used in test mode",
    "label": "",
    "id": "50"
  },
  {
    "raw_code": "def list_suggested_for(topic, pm_params: nil, include_random: true)\n    # Don't suggest messages unless we have a user, and private messages are\n    # enabled.\n    if topic.private_message? &&\n         (@user.blank? || !@user.in_any_groups?(SiteSetting.personal_message_enabled_groups_map))\n      return\n    end",
    "comment": "Return a list of suggested topics for a topic The include_random param was added so plugins can generate a suggested topics list without the random topics",
    "label": "",
    "id": "51"
  },
  {
    "raw_code": "def list_latest\n    create_list(:latest, {}, latest_results)\n  end",
    "comment": "The latest view of topics",
    "label": "",
    "id": "52"
  },
  {
    "raw_code": "def self.tracked_filter(list, user_id)\n    tracked_category_ids_sql = <<~SQL\n    SELECT cd.category_id FROM category_users cd\n    WHERE cd.user_id = :user_id AND cd.notification_level >= :tracking\n    SQL\n\n    has_sub_sub_categories = SiteSetting.max_category_nesting == 3\n\n    sql = +<<~SQL\n      topics.category_id IN (\n        SELECT\n          c.id\n        FROM categories c\n        #{has_sub_sub_categories ? \"LEFT JOIN categories parent_categories ON parent_categories.id = c.parent_category_id\" : \"\"}\n        WHERE (c.id IN (#{tracked_category_ids_sql}))\n        OR c.parent_category_id IN (#{tracked_category_ids_sql})\n        #{has_sub_sub_categories ? \"OR (parent_categories.id IS NOT NULL AND parent_categories.parent_category_id IN (#{tracked_category_ids_sql}))\" : \"\"}\n      )\n    SQL\n\n    sql << <<~SQL if SiteSetting.tagging_enabled\n        OR topics.id IN (\n          SELECT tt.topic_id FROM topic_tags tt WHERE tt.tag_id IN (\n            SELECT tu.tag_id\n            FROM tag_users tu\n            WHERE tu.user_id = :user_id AND tu.notification_level >= :tracking\n          )\n        )\n      SQL\n\n    list.where(sql, user_id: user_id, tracking: NotificationLevels.all[:tracking])\n  end",
    "comment": "Any changes here will need to be reflected in `lib/topic-list-tracked-filter.js` for the `isTrackedTopic` function on the client side. The `f=tracked` query param is not heavily used so we do not want to be querying for a topic's tracked status by default. Instead, the client will handle the filtering when the `f=tracked` query params is present.",
    "label": "",
    "id": "53"
  },
  {
    "raw_code": "def default_results(options = {})\n    options.reverse_merge!(@options)\n    options.reverse_merge!(per_page: per_page_setting) unless options[:limit] == false\n\n    # Whether to include unlisted (visible = false) topics\n    viewing_own_topics = @user && @user.id == options[:filtered_to_user]\n\n    if options[:visible].nil?\n      options[:visible] = true if @user.nil? || @user.regular?\n      options[:visible] = false if @guardian.can_see_unlisted_topics? || viewing_own_topics\n    end",
    "comment": "Create results based on a bunch of default options",
    "label": "",
    "id": "54"
  },
  {
    "raw_code": "def self.allow_crawler?(user_agent)\n    if SiteSetting.allowed_crawler_user_agents.blank? &&\n         SiteSetting.blocked_crawler_user_agents.blank?\n      return true\n    end",
    "comment": "Given a user_agent that returns true from crawler?, should its request be allowed?",
    "label": "",
    "id": "55"
  },
  {
    "raw_code": "def self.extended(klass)\n    if GlobalSetting.respond_to?(:default_locale) && GlobalSetting.default_locale.present?\n      # protected\n      klass.send :setup_shadowed_methods, :default_locale, GlobalSetting.default_locale\n    end",
    "comment": "support default_locale being set via global settings this also adds support for testing the extension and global settings for site locale",
    "label": "",
    "id": "56"
  },
  {
    "raw_code": "def default_locale=(val)\n    val = val.to_s\n    raise Discourse::InvalidParameters.new(:value) unless LocaleSiteSetting.valid_value?(val)\n    if val != self.default_locale\n      add_override!(:default_locale, val)\n      refresh!\n      Discourse.request_refresh!\n    end",
    "comment": "we need a default here to support defaults per locale",
    "label": "",
    "id": "57"
  },
  {
    "raw_code": "def default_locale\n    # note optimised cause this is called a lot so avoiding .presence which\n    # adds 2 method calls\n    locale = current[:default_locale]\n    if locale && !locale.blank?\n      locale\n    else\n      SiteSettings::DefaultsProvider::DEFAULT_LOCALE\n    end",
    "comment": "set up some sort of default so we can look stuff up",
    "label": "",
    "id": "58"
  },
  {
    "raw_code": "def all_settings(\n    include_hidden: false,\n    include_locale_setting: true,\n    only_overridden: false,\n    basic_attributes: false,\n    filter_categories: nil,\n    filter_plugin: nil,\n    filter_names: nil,\n    filter_allowed_hidden: nil,\n    filter_area: nil\n  )\n    locale_setting_hash = {\n      setting: \"default_locale\",\n      humanized_name: humanized_names(\"default_locale\"),\n      default: SiteSettings::DefaultsProvider::DEFAULT_LOCALE,\n      category: \"required\",\n      primary_area: \"localization\",\n      description: description(\"default_locale\"),\n      type: SiteSetting.types[SiteSetting.types[:locale_enum]],\n      preview: nil,\n      value: self.default_locale,\n      valid_values: LocaleSiteSetting.values,\n      translate_names: LocaleSiteSetting.translate_names?,\n    }\n\n    include_locale_setting = false if filter_categories.present? || filter_plugin.present?\n\n    defaults\n      .all(default_locale)\n      .reject do |setting_name, _|\n        plugins[name] && !Discourse.plugins_by_name[plugins[name]].configurable?\n      end",
    "comment": "Retrieve all settings",
    "label": "",
    "id": "59"
  },
  {
    "raw_code": "def refresh!(refresh_site_settings: true, refresh_theme_site_settings: true)\n    mutex.synchronize do\n      ensure_listen_for_changes\n\n      if refresh_site_settings\n        new_hash =\n          Hash[\n            *(\n              provider\n                .all\n                .map do |s|\n                  [s.name.to_sym, type_supervisor.to_rb_value(s.name, s.value, s.data_type)]\n                end",
    "comment": "Refresh all the site settings and theme site settings",
    "label": "",
    "id": "60"
  },
  {
    "raw_code": "def remove_override!(name)\n    raise_invalid_setting_access(name) if themeable[name]\n\n    old_val = current[name]\n    provider.destroy(name)\n    current[name] = defaults.get(name, default_locale)\n\n    return if current[name] == old_val\n\n    clear_uploads_cache(name)\n    clear_cache!\n    if old_val != current[name]\n      DiscourseEvent.trigger(:site_setting_changed, name, old_val, current[name])\n    end",
    "comment": " Removes an override for a setting, reverting it to the default value. This method is only called manually usually, more often than not setting overrides are removed in database migrations.  Here we also handle notifying the UI of the change in the case of theme site settings and clearing relevant caches, and triggering server-side events for changed settings.  Themeable site settings cannot be removed this way, they must be changed via the ThemeSiteSetting model.  @param name [Symbol] the name of the setting @param val [Any] the value to set",
    "label": "",
    "id": "61"
  },
  {
    "raw_code": "def add_override!(name, val)\n    raise_invalid_setting_access(name) if themeable[name]\n\n    old_val = current[name]\n    val, type = type_supervisor.to_db_value(name, val)\n\n    sanitize_override = val.is_a?(String) && client_settings.include?(name)\n\n    sanitized_val = sanitize_override ? sanitize_field(val) : val\n\n    if mandatory_values[name.to_sym]\n      sanitized_val =\n        (mandatory_values[name.to_sym].split(\"|\") | sanitized_val.to_s.split(\"|\")).join(\"|\")\n    end",
    "comment": " Adds an override, which is to say a database entry for the setting instead of using the default.  The `set`, `set_and_log`, and `setting_name=` methods all call this method. Its opposite is remove_override!.  Here we also handle notifying the UI of the change in the case of theme site settings and clearing relevant caches, and triggering server-side events for changed settings.  Themeable site settings cannot be changed this way, they must be changed via the ThemeSiteSetting model.  @param name [Symbol] the name of the setting @param val [Any] the value to set  @example SiteSetting.add_override!(:site_description, \"My awesome forum\")  @raise [SiteSettingExtension::InvalidSettingAccess] if the setting is themeable (themeable settings must be changed via ThemeSiteSetting model)  @note When called from the Rails console, this method automatically logs the change with the system user.  @see remove_override! for removing an override and reverting to default value",
    "label": "",
    "id": "62"
  },
  {
    "raw_code": "def change_themeable_site_setting(theme_id, name, val)\n    name = name.to_sym\n\n    theme_site_settings[theme_id] ||= {}\n    old_val = theme_site_settings[theme_id][name]\n    theme_site_settings[theme_id][name] = val\n\n    notify_clients!(name, theme_id: theme_id) if client_settings.include?(name)\n    notify_changed!\n\n    clear_cache!(expire_theme_site_setting_cache: true)\n\n    DiscourseEvent.trigger(:theme_site_setting_changed, name, old_val, val)\n  end",
    "comment": "Updates a theme-specific site setting value in memory and notifies observers.  This method is used to change site settings that are marked as \"themeable\", which means they can have different values per theme. Unlike `add_override!`, the database isn't touched here.  @param theme_id [Integer] The ID of the theme to update the setting for @param name [String, Symbol] The name of the site setting to change @param val [Object] The new \"ruby\" value for the site setting  @example SiteSetting.change_themeable_site_setting(5, \"enable_welcome_banner\", false)  @note Unlike regular site settings which use add_override!, themeable settings should be changed via the ThemeSiteSettingManager service.  @see ThemeSiteSettingManager service for the higher-level implementation that handles database persistence and logging.",
    "label": "",
    "id": "63"
  },
  {
    "raw_code": "def info(name)\n      {\n        resolved_value: get(name),\n        default_value: defaults[name],\n        global_override: GlobalSetting.respond_to?(name) ? GlobalSetting.public_send(name) : nil,\n        database_value: provider.find(name)&.value,\n        refresh?: refresh_settings.include?(name),\n        client?: client_settings.include?(name),\n        secret?: secret_settings.include?(name),\n      }\n    end",
    "comment": "Convenience method for debugging site setting issues Returns a hash with information about a specific setting",
    "label": "",
    "id": "64"
  },
  {
    "raw_code": "def self.sanitize_filename(filename)\n    filename.strip.tap do |name|\n      # NOTE: File.basename doesn't work right with Windows paths on Unix\n      # get only the filename, not the whole path\n      name.sub! %r{\\A.*(\\\\|/)}, \"\"\n      # Replace all non alphanumeric, underscore\n      # or periods with underscore\n      name.gsub! /[^\\w\\.\\-]/, \"_\"\n      # Finally, replace all double underscores with a single one\n      name.gsub! /_+/, \"_\"\n    end",
    "comment": "https://guides.rubyonrails.org/security.html#file-uploads",
    "label": "",
    "id": "65"
  },
  {
    "raw_code": "def initialize(file, filename, opts = {})\n    @file = file\n    @filename = (filename || \"\").gsub(/[^[:print:]]/, \"\")\n    @upload = Upload.new(original_filename: @filename, filesize: 0)\n    @opts = opts\n    @filesize = @opts[:filesize] if @opts[:external_upload_too_big]\n    @opts[:validate] = (\n      if opts[:skip_validations].present?\n        !ActiveRecord::Type::Boolean.new.cast(opts[:skip_validations])\n      else\n        true\n      end",
    "comment": "Available options - type (string) - origin (string) - for_group_message (boolean) - for_theme (boolean) - for_private_message (boolean) - pasted (boolean) - for_export (boolean) - for_gravatar (boolean) - skip_validations (boolean)",
    "label": "",
    "id": "66"
  },
  {
    "raw_code": "def hoist_line_breaks!(doc)\n    klass = \"_\" + SecureRandom.hex\n    doc.css(\"br\").each { |br| br.add_class(klass) }\n\n    loop do\n      changed = false\n\n      doc\n        .css(\"br.#{klass}\")\n        .each do |br|\n          parent = br.parent\n\n          if block?(parent)\n            br.remove_class(klass)\n          else\n            before, after = parent.children.slice_when { |n| n == br }.to_a\n\n            if before.size > 1\n              b = doc.document.create_element(parent.name)\n              before[0...-1].each { |c| b.add_child(c) }\n              parent.previous = b if b.inner_html.present?\n            end",
    "comment": "When there's a <br> inside an inline element, split the inline element around the <br>",
    "label": "",
    "id": "67"
  },
  {
    "raw_code": "def remove_whitespaces!(node)\n    return true if \"pre\" == node.name\n\n    node\n      .children\n      .chunk { |n| is_inline?(n) }\n      .each do |inline, nodes|\n        if inline\n          collapse_spaces!(nodes) && remove_trailing_space!(nodes)\n        else\n          nodes.each { |n| remove_whitespaces!(n) }\n        end",
    "comment": "Removes most of the unnecessary white spaces for better markdown conversion Loosely based on the CSS' White Space Processing Rules (https://www.w3.org/TR/css-text-3/#white-space-rules)",
    "label": "",
    "id": "68"
  },
  {
    "raw_code": "def self.distance_of_time_in_words(from_time, to_time = 0, include_seconds = false, options = {})\n    options = { scope: :\"datetime.distance_in_words\" }.merge!(options)\n\n    from_time = from_time.to_time if from_time.respond_to?(:to_time)\n    to_time = to_time.to_time if to_time.respond_to?(:to_time)\n    distance = (to_time.to_f - from_time.to_f).abs\n    distance_in_minutes = (distance / 60.0).round\n    distance_in_seconds = distance.round\n\n    I18n.with_options locale: options[:locale], scope: options[:scope] do |locale|\n      case distance_in_minutes\n      when 0..1\n        unless include_seconds\n          return(\n            (\n              if distance_in_minutes == 0\n                locale.t(:less_than_x_minutes, count: 1)\n              else\n                locale.t(:x_minutes, count: distance_in_minutes)\n              end",
    "comment": "Sam: This has now forked of rails. Trouble is we would never like to use \"about 1 month\" ever, we only want months for 2 or more months. Backporting a fix to rails itself may get too complex",
    "label": "",
    "id": "69"
  },
  {
    "raw_code": "def enqueue(reason = nil, creator_opts: {})\n    result = NewPostResult.new(:enqueued)\n    payload = { raw: @args[:raw], tags: @args[:tags] }\n    %w[typing_duration_msecs composer_open_duration_msecs reply_to_post_number].each do |a|\n      payload[a] = @args[a].to_i if @args[a]\n    end",
    "comment": "Enqueue this post",
    "label": "",
    "id": "70"
  },
  {
    "raw_code": "def stop\n    @mutex.synchronize { @stop_requested = true }\n\n    if @thread\n      @thread.wakeup\n      @thread.join\n      @thread = nil\n    end",
    "comment": "Used for testing to stop the thread. In production, the thread is expected to live for the lifetime of the process.",
    "label": "",
    "id": "71"
  },
  {
    "raw_code": "def self.find_compatible_resource(version_list, target_version = ::Discourse::VERSION::STRING)\n    return if version_list.blank?\n\n    begin\n      version_list = YAML.safe_load(version_list)\n    rescue Psych::SyntaxError, Psych::DisallowedClass => e\n    end",
    "comment": "lookup an external resource (theme/plugin)'s best compatible version compatible resource files are YAML, in the format: `discourse_version: plugin/theme git reference.` For example: 2.5.0.beta6: c4a6c17 2.5.0.beta4: d1d2d3f 2.5.0.beta2: bbffee 2.4.4.beta6: some-other-branch-ref 2.4.2.beta1: v1-tag",
    "label": "",
    "id": "72"
  },
  {
    "raw_code": "def self.find_compatible_git_resource(path)\n    return unless File.directory?(\"#{path}/.git\")\n\n    tree_info =\n      Discourse::Utils.execute_command(\n        \"git\",\n        \"-C\",\n        path,\n        \"ls-tree\",\n        \"-l\",\n        \"HEAD\",\n        Discourse::VERSION_COMPATIBILITY_FILENAME,\n      )\n    blob_size = tree_info.split[3].to_i\n\n    if blob_size > Discourse::MAX_METADATA_FILE_SIZE\n      $stderr.puts \"#{Discourse::VERSION_COMPATIBILITY_FILENAME} file in #{path} too big\"\n      return\n    end",
    "comment": "Find a compatible resource from a git repo",
    "label": "",
    "id": "73"
  },
  {
    "raw_code": "def last_installed_version\n      Discourse.redis.get last_installed_version_key\n    end",
    "comment": "last_installed_version is the installed version at the time of the last version check",
    "label": "",
    "id": "74"
  },
  {
    "raw_code": "def clear_current_user\n    @current_user_provider = Discourse.current_user_provider.new({})\n  end",
    "comment": "can be used to pretend current user does no exist, for CSRF attacks",
    "label": "",
    "id": "75"
  },
  {
    "raw_code": "def review\n    override = DiscoursePluginRegistry.apply_modifier(:review_trust_level, false, @user)\n    return override if override\n\n    # nil users are never promoted\n    return false if @user.blank? || !@user.manual_locked_trust_level.nil?\n\n    # Promotion beyond basic requires some expensive queries, so don't do that here.\n    return false if @user.trust_level >= TrustLevel[2]\n\n    review_method = :\"review_tl#{@user.trust_level}\"\n    return public_send(review_method) if respond_to?(review_method)\n\n    false\n  end",
    "comment": "Review a user for a promotion. Delegates work to a review_#{trust_level} method. Returns true if the user was promoted, false otherwise.",
    "label": "",
    "id": "76"
  },
  {
    "raw_code": "def self.recalculate(user, performed_by = nil, use_previous_trust_level: false)\n    granted_trust_level =\n      TrustLevel.calculate(user, use_previous_trust_level: use_previous_trust_level) ||\n        TrustLevel[0]\n\n    granted_trust_level = user.trust_level if granted_trust_level < user.trust_level &&\n      !can_downgrade_trust_level?(user)\n\n    # TrustLevel.calculate always returns a value, however we added extra protection just\n    # in case this changes\n    user.update_column(:trust_level, TrustLevel[granted_trust_level])\n\n    return if user.manual_locked_trust_level.present?\n\n    promotion = Promotion.new(user)\n\n    override =\n      DiscoursePluginRegistry.apply_modifier(:recalculate_trust_level, false, user, promotion)\n    return override if override\n\n    promotion.review_tl0 if granted_trust_level < TrustLevel[1]\n    promotion.review_tl1 if granted_trust_level < TrustLevel[2]\n    promotion.review_tl2 if granted_trust_level < TrustLevel[3]\n\n    Group.user_trust_level_change!(user.id, user.trust_level)\n\n    if user.trust_level == TrustLevel[3] && Promotion.tl3_lost?(user)\n      user.change_trust_level!(TrustLevel[2], log_action_for: performed_by || Discourse.system_user)\n    end",
    "comment": "Figure out what a user's trust level should be from scratch",
    "label": "",
    "id": "77"
  },
  {
    "raw_code": "def execute(readonly_mode: Discourse.readonly_mode?)\n    if log_query?(readonly_mode)\n      status, search_log_id =\n        SearchLog.log(\n          term: @clean_term,\n          search_type: @opts[:search_type],\n          ip_address: @opts[:ip_address],\n          user_agent: @opts[:user_agent],\n          user_id: @opts[:user_id],\n        )\n      @results.search_log_id = search_log_id unless status == :error\n    end",
    "comment": "Query a term",
    "label": "",
    "id": "78"
  },
  {
    "raw_code": "def single_topic(id)\n    if @opts[:restrict_to_archetype].present?\n      archetype =\n        (\n          if @opts[:restrict_to_archetype] == Archetype.default\n            Archetype.default\n          else\n            Archetype.private_message\n          end",
    "comment": "If we're searching for a single topic",
    "label": "",
    "id": "79"
  },
  {
    "raw_code": "def self.stage_challenge(user, server_session)\n    ::DiscourseWebauthn::ChallengeGenerator.generate.commit_to_session(\n      server_session,\n      user,\n      expires: CHALLENGE_EXPIRY,\n    )\n  end",
    "comment": " Usage:  These methods should be used in controllers where we are challenging the user that has a security key, and they must respond with a valid webauthn response and credentials.  @param user [User] the user to stage the challenge for @param server_session [ServerSession] the session to store the challenge in",
    "label": "",
    "id": "80"
  },
  {
    "raw_code": "def self.clear_challenge(user, server_session)\n    server_session.delete(session_challenge_key(user))\n  end",
    "comment": " Clears the challenge from the user's server session.  @param user [User] the user to clear the challenge for @param server_session [ServerSession] the session to clear the challenge from",
    "label": "",
    "id": "81"
  },
  {
    "raw_code": "def self.supports_cache_versioning?\n    false\n  end",
    "comment": "we don't need this feature, 1 day expiry is enough it makes lookups a tad cheaper",
    "label": "",
    "id": "82"
  },
  {
    "raw_code": "def read(name)\n    key = normalize_key(name)\n    read_entry(key).tap { |entry| break if entry == :__corrupt_cache__ }\n  end",
    "comment": "this removes a bunch of stuff we do not need like instrumentation and versioning",
    "label": "",
    "id": "83"
  },
  {
    "raw_code": "def self.relaxed_parse(url)\n    url, fragment = url.split(\"#\", 2)\n    uri = URI.parse(url)\n    if uri\n      # Addressable::URI::CharacterClasses::UNRESERVED is used here because without it\n      # the # in the fragment is not encoded\n      fragment =\n        Addressable::URI.encode_component(\n          fragment,\n          Addressable::URI::CharacterClasses::UNRESERVED,\n        ) if fragment&.include?(\"#\")\n      uri.fragment = fragment\n      uri\n    end",
    "comment": "At the moment this handles invalid URLs that browser address bar accepts where second # is not encoded  Longer term we can add support of simpleidn and encode unicode domains",
    "label": "",
    "id": "84"
  },
  {
    "raw_code": "def self.is_valid_url?(url)\n    uri = URI.parse(url)\n\n    return true if uri.is_a?(URI::Generic) && url.starts_with?(\"/\") || url.match?(/\\A\\#([^#]*)/)\n\n    if uri.scheme\n      return true if uri.is_a?(URI::MailTo)\n\n      if url.match?(%r{\\A#{uri.scheme}://[^/]}) &&\n           (\n             uri.is_a?(URI::HTTP) || uri.is_a?(URI::HTTPS) || uri.is_a?(URI::FTP) ||\n               uri.is_a?(URI::LDAP)\n           )\n        return true\n      end",
    "comment": "Heuristic checks to determine if the URL string is a valid absolute URL, path or anchor",
    "label": "",
    "id": "85"
  },
  {
    "raw_code": "def after_commit(&blk)\n    return blk.call if !transaction_open?\n\n    ActiveRecord::Base.connection.add_transaction_record(AfterCommitWrapper.new(&blk))\n  end",
    "comment": "Allows running arbitrary code after the current transaction has been committed. Works with nested ActiveRecord transaction blocks. Useful for scheduling sidekiq jobs. If not currently in a transaction, will execute immediately",
    "label": "",
    "id": "86"
  },
  {
    "raw_code": "def active_record_connection\n    ActiveRecord::Base.connection\n  end",
    "comment": "we need a tiny adapter here so we always run against the correct multisite connection",
    "label": "",
    "id": "87"
  },
  {
    "raw_code": "def prepared(condition = true)\n    if condition\n      conn = raw_connection.instance_variable_get(:@mini_sql_prepared_connection)\n      if !conn\n        conn = MiniSql::Postgres::PreparedConnection.new(self)\n        raw_connection.instance_variable_set(:@mini_sql_prepared_connection, conn)\n      end",
    "comment": "make for a multisite friendly prepared statement cache",
    "label": "",
    "id": "88"
  },
  {
    "raw_code": "def self.authentication_override(host)\n    return \"login\" if %w[smtp.office365.com smtp-mail.outlook.com].include?(host)\n    GlobalSetting.smtp_authentication\n  end",
    "comment": "Ideally we (or net-smtp) would automatically detect the correct authentication method, but this is sufficient for our purposes because we know certain providers need certain authentication methods. This may need to change when we start to use XOAUTH2 for SMTP.",
    "label": "",
    "id": "89"
  },
  {
    "raw_code": "def mem_total\n    @mem_total ||=\n      begin\n        system = `uname`.strip\n        if system == \"Darwin\"\n          s = `sysctl -n hw.memsize`.strip\n          s.to_i / 1.kilobyte\n        else\n          s = `grep MemTotal /proc/meminfo`\n          /(\\d+)/.match(s)[0].try(:to_i)\n        end",
    "comment": "Total memory in kb. On Mac OS uses \"sysctl\", elsewhere expects the system has /proc/meminfo. Returns nil if it cannot be determined.",
    "label": "",
    "id": "90"
  },
  {
    "raw_code": "def self.define_register(register_name, type)\n    return if respond_to?(register_name)\n    @@register_names << register_name\n\n    define_singleton_method(register_name) do\n      instance_variable_get(:\"@#{register_name}\") ||\n        instance_variable_set(:\"@#{register_name}\", type.new)\n    end",
    "comment": "Plugins often need to be able to register additional handlers, data, or classes that will be used by core classes. This should be used if you need to control which type the registry is, and if it doesn't need to be removed if the plugin is disabled.  Shortcut to create new register in the plugin registry - Register is created in a class variable using the specified name/type - Defines singleton method to access the register - Defines instance method as a shortcut to the singleton method - Automatically deletes the register on registry.reset!",
    "label": "",
    "id": "91"
  },
  {
    "raw_code": "def self.define_filtered_register(register_name)\n    return if respond_to?(register_name)\n    define_register(register_name, Array)\n\n    singleton_class.alias_method :\"_raw_#{register_name}\", :\"#{register_name}\"\n\n    define_singleton_method(register_name) do\n      public_send(:\"_raw_#{register_name}\").filter_map { |h| h[:value] if h[:plugin].enabled? }.uniq\n    end",
    "comment": "Plugins often need to add values to a list, and we need to filter those lists at runtime to ignore values from disabled plugins. Unlike define_register, the type of the register cannot be defined, and is always Array.  Create a new register (see `define_register`) with some additions: - Register is created in a class variable using the specified name/type - Defines singleton method to access the register - Defines instance method as a shortcut to the singleton method - Automatically deletes the register on registry.reset!",
    "label": "",
    "id": "92"
  },
  {
    "raw_code": "def self.brightness(color)\n    rgb = Converters.hex_to_rgb(color)\n    (rgb[0].to_i * 299 + rgb[1].to_i * 587 + rgb[2].to_i * 114) / 1000.0\n  end",
    "comment": "Equivalent to dc-color-brightness() in variables.scss",
    "label": "",
    "id": "93"
  },
  {
    "raw_code": "def self.dark_light_diff(adjusted_color, comparison_color, lightness, darkness)\n    if brightness(adjusted_color) < brightness(comparison_color)\n      scale_color_lightness(adjusted_color, lightness)\n    else\n      scale_color_lightness(adjusted_color, darkness)\n    end",
    "comment": "Equivalent to dark-light-diff() in variables.scss",
    "label": "",
    "id": "94"
  },
  {
    "raw_code": "def self.scale_color_lightness(color, adjustment)\n    rgb = Converters.hex_to_rgb(color)\n    h, s, l = Converters.rgb_to_hsl(*rgb)\n\n    l =\n      if adjustment > 0\n        l + (100 - l) * adjustment\n      else\n        l + l * adjustment\n      end",
    "comment": "Equivalent to scale_color(color, lightness: ) in sass",
    "label": "",
    "id": "95"
  },
  {
    "raw_code": "def self.hex_to_rgb(color)\n      color = color.gsub(/(.)/, '\\1\\1') if color.length == 3\n      raise new RuntimeError(\"Hex color must be 6 characters\") if color.length != 6\n      color.scan(/../).map { |c| c.to_i(16) }\n    end",
    "comment": "Adapted from https://github.com/anilyanduri/color_math  The MIT License (MIT)  Copyright (c) 2016 Anil Yanduri  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "label": "",
    "id": "96"
  },
  {
    "raw_code": "def self.apply_custom_default_scope(&block)\n    custom_default_scopes << block\n  end",
    "comment": "Configure a default scope to be applied to @filtered_posts. The registered block is called with @filtered_posts and an instance of `TopicView`.  This API should be considered experimental until it is exposed in `Plugin::Instance`.",
    "label": "",
    "id": "97"
  },
  {
    "raw_code": "def self.reset_custom_default_scopes\n    @custom_default_scopes = nil\n  end",
    "comment": "For testing",
    "label": "",
    "id": "98"
  },
  {
    "raw_code": "def filter_posts_near(post_number)\n    posts_before = (@limit.to_f / 4).floor\n    posts_before = 1 if posts_before.zero?\n    sort_order = get_sort_order(post_number)\n\n    before_post_ids =\n      @filtered_posts\n        .reverse_order\n        .where(\"posts.sort_order < ?\", sort_order)\n        .limit(posts_before)\n        .pluck(:id)\n\n    post_ids =\n      before_post_ids +\n        @filtered_posts\n          .where(\"posts.sort_order >= ?\", sort_order)\n          .limit(@limit - before_post_ids.length)\n          .pluck(:id)\n\n    if post_ids.length < @limit\n      post_ids =\n        post_ids +\n          @filtered_posts\n            .reverse_order\n            .where(\"posts.sort_order < ?\", sort_order)\n            .offset(before_post_ids.length)\n            .limit(@limit - post_ids.length)\n            .pluck(:id)\n    end",
    "comment": "Filter to all posts near a particular post number",
    "label": "",
    "id": "99"
  },
  {
    "raw_code": "def highest_post_number\n    @highest_post_number ||= @filtered_posts.maximum(:post_number)\n  end",
    "comment": "This is pending a larger refactor, that allows custom orders for now we need to look for the highest_post_number in the stream the cache on topics is not correct if there are deleted posts at the end of the stream (for mods), nor is it correct for filtered streams",
    "label": "",
    "id": "100"
  },
  {
    "raw_code": "def filtered_post_stream\n    @filtered_post_stream ||=\n      begin\n        posts = @filtered_posts\n        columns = [:id]\n\n        if !is_mega_topic?\n          columns << \"(EXTRACT(EPOCH FROM CURRENT_TIMESTAMP - posts.created_at) / 86400)::INT AS days_ago\"\n        end",
    "comment": "Returns an array of [id, days_ago] tuples. `days_ago` is there for the timeline calculations.",
    "label": "",
    "id": "101"
  },
  {
    "raw_code": "def initialize(topic, topic_user, guardian)\n    @guardian = guardian\n    @topic = topic\n    @topic_user = topic_user\n  end",
    "comment": "This module helps us calculate unread post counts",
    "label": "",
    "id": "102"
  },
  {
    "raw_code": "def check_education_message\n    return if @topic&.private_message?\n\n    education_key = creating_topic? ? \"education.new-topic\" : \"education.new-reply\"\n    count = @user.topic_count + @user.post_count\n\n    if count < SiteSetting.educate_until_posts\n      return(\n        {\n          id: \"education\",\n          templateName: \"education\",\n          wait_for_typing: true,\n          body:\n            PrettyText.cook(\n              I18n.t(\n                education_key,\n                education_posts_text:\n                  I18n.t(\"education.until_posts\", count: SiteSetting.educate_until_posts),\n                site_name: SiteSetting.title,\n                base_path: Discourse.base_path,\n              ),\n            ),\n        }\n      )\n    end",
    "comment": "Determines whether to show the user education text",
    "label": "",
    "id": "103"
  },
  {
    "raw_code": "def check_new_user_many_replies\n    return unless replying? && @user.posted_too_much_in_topic?(@details[:topic_id])\n\n    {\n      id: \"too_many_replies\",\n      templateName: \"education\",\n      body:\n        PrettyText.cook(\n          I18n.t(\n            \"education.too_many_replies\",\n            newuser_max_replies_per_topic: SiteSetting.newuser_max_replies_per_topic,\n          ),\n        ),\n    }\n  end",
    "comment": "New users have a limited number of replies in a topic",
    "label": "",
    "id": "104"
  },
  {
    "raw_code": "def self.encode(num)\n    return \"0\" if num == 0\n    return nil if num < 0\n\n    str = \"\"\n    while num > 0\n      # prepend base62 characters\n      str = KEYS[num % BASE] + str\n      num = num / BASE\n    end",
    "comment": "Encodes base10 (decimal) number to base62 string.",
    "label": "",
    "id": "105"
  },
  {
    "raw_code": "def self.decode(str)\n    num = 0\n    i = 0\n    len = str.length - 1\n    # while loop is faster than each_char or other 'idiomatic' way\n    while i < str.length\n      pow = BASE**(len - i)\n      num += KEYS_HASH[str[i]] * pow\n      i += 1\n    end",
    "comment": "Decodes base62 string to a base10 (decimal) number.",
    "label": "",
    "id": "106"
  },
  {
    "raw_code": "def self.filter_allowed_tags(guardian, opts = {})\n    selected_tag_ids = opts[:selected_tags] ? Tag.where_name(opts[:selected_tags]).pluck(:id) : []\n    category = opts[:category]\n    category_has_restricted_tags =\n      category ? (category.tags.count > 0 || category.tag_groups.count > 0) : false\n\n    # If guardian is nil, it means the caller doesn't want tags to be filtered\n    # based on guardian rules. Use the same rules as for staff users.\n    filter_for_non_staff = !guardian.nil? && !guardian.is_staff?\n\n    builder_params = {}\n\n    builder_params[:selected_tag_ids] = selected_tag_ids unless selected_tag_ids.empty?\n\n    sql = +\"WITH #{TAG_GROUP_RESTRICTIONS_SQL}, #{CATEGORY_RESTRICTIONS_SQL}\"\n    if (opts[:for_input] || opts[:for_topic]) && filter_for_non_staff\n      sql << \", #{PERMITTED_TAGS_SQL} \"\n      builder_params[:group_ids] = permitted_group_ids(guardian)\n      sql.gsub!(\"/*and_group_ids*/\", \"AND group_id IN (:group_ids)\")\n    end",
    "comment": "Options: term: a search term to filter tags by name term_type: whether to search by \"starts_with\" or \"contains\" with the term limit: max number of results category: a Category to which the object being tagged belongs for_input: result is for an input field, so only show permitted tags for_topic: results are for tagging a topic selected_tags: an array of tag names that are in the current selection only_tag_names: limit results to tags with these names exclude_synonyms: exclude synonyms from results order_search_results: result should be ordered for name search results order_popularity: order result by topic_count excluded_tag_names: an array of tag names not to include in the results",
    "label": "",
    "id": "107"
  },
  {
    "raw_code": "def self.readonly_tag_names(guardian = nil)\n    return [] if guardian&.is_admin?\n\n    query =\n      Tag.joins(tag_groups: :tag_group_permissions).where(\n        \"tag_group_permissions.permission_type = ?\",\n        TagGroupPermission.permission_types[:readonly],\n      )\n\n    query.pluck(:name)\n  end",
    "comment": "read-only tags for this user",
    "label": "",
    "id": "108"
  },
  {
    "raw_code": "def self.permitted_tag_names(guardian = nil)\n    query =\n      Tag.joins(tag_groups: :tag_group_permissions).where(\n        tag_group_permissions: {\n          group_id: permitted_group_ids(guardian),\n          permission_type: TagGroupPermission.permission_types[:full],\n        },\n      )\n\n    query.pluck(:name).uniq\n  end",
    "comment": "explicit permissions to use these tags",
    "label": "",
    "id": "109"
  },
  {
    "raw_code": "def self.staff_tag_names\n    tag_names = Discourse.cache.read(TAGS_STAFF_CACHE_KEY)\n\n    if !tag_names\n      tag_names =\n        Tag\n          .joins(tag_groups: :tag_group_permissions)\n          .where(\n            tag_group_permissions: {\n              group_id: Group::AUTO_GROUPS[:everyone],\n              permission_type: TagGroupPermission.permission_types[:readonly],\n            },\n          )\n          .pluck(:name)\n      Discourse.cache.write(TAGS_STAFF_CACHE_KEY, tag_names, expires_in: 1.hour)\n    end",
    "comment": "middle level of tag group restrictions",
    "label": "",
    "id": "110"
  },
  {
    "raw_code": "def self.add_or_create_synonyms_by_name(target_tag, synonym_names)\n    tag_names =\n      DiscourseTagging.tags_for_saving(synonym_names, Guardian.new(Discourse.system_user)) || []\n    tag_names -= [target_tag.name]\n    existing = Tag.where_name(tag_names).all\n    target_tag.synonyms << existing\n    (tag_names - target_tag.synonyms.map(&:name)).each do |name|\n      target_tag.synonyms << Tag.create(name: name)\n    end",
    "comment": "Returns true if all were added successfully, or an Array of the tags that failed to be added, with errors on each Tag.",
    "label": "",
    "id": "111"
  },
  {
    "raw_code": "def [](user_id)\n    users[user_id]\n  end",
    "comment": "Lookup a user by id",
    "label": "",
    "id": "112"
  },
  {
    "raw_code": "def self.mobile_device?(user_agent)\n    user_agent =~ /Mobile/ && !(user_agent =~ /iPad/)\n  end",
    "comment": "if the criteria for mobile_device? changes, update the code for `mobileDevice` in `javascripts/discourse/app/lib/mobile.js`",
    "label": "",
    "id": "113"
  },
  {
    "raw_code": "def self.resolve_mobile_view!(user_agent, params, session)\n    return false unless SiteSetting.enable_mobile_theme\n\n    session[:mobile_view] = params[:mobile_view] if params && params.has_key?(:mobile_view)\n    session[:mobile_view] = nil if params && params.has_key?(:mobile_view) &&\n      params[:mobile_view] == \"auto\"\n\n    if session && session[:mobile_view]\n      session[:mobile_view] == \"1\"\n    else\n      mobile_device?(user_agent)\n    end",
    "comment": "we need this as a reusable chunk that is called from the cache",
    "label": "",
    "id": "114"
  },
  {
    "raw_code": "def self.logger(logdev:, type:, customize_event: nil, level: Logger::INFO)\n    logger = self.new(logdev)\n    logger.type = type\n    logger.customize_event = customize_event if customize_event\n    logger.level = level\n    logger\n  end",
    "comment": "Creates a new logger instance.  @param logdev [String, IO, nil] The log device. This can be one of: - A string filepath: entries are written to the file at that path. If the file exists, new entries are appended. - An IO stream (typically +$stdout+, +$stderr+, or an open file): entries are written to the given stream. - nil or File::NULL: no entries are written. @param type [String] The type of log messages. This will add a `type` field to all log messages. @param customize_event [Proc, nil] A proc that customizes the log event before it is written to the log device. The proc is called with a hash of log event data and can be modified in place.  @return [Logger] A new logger instance with the specified log device and type.",
    "label": "",
    "id": "115"
  },
  {
    "raw_code": "def add(*args, &block)\n    add_with_opts(*args, &block)\n  end",
    "comment": ":nodoc:",
    "label": "",
    "id": "116"
  },
  {
    "raw_code": "def add_with_opts(severity, message = nil, progname = nil, opts = {}, &block)\n    return true if @logdev.nil? || severity < @level\n\n    progname = @progname if progname.nil?\n\n    if message.nil?\n      if block_given?\n        message = yield\n      else\n        message = progname\n        progname = @progname\n      end",
    "comment": ":nodoc:",
    "label": "",
    "id": "117"
  },
  {
    "raw_code": "def initialize(user, opts)\n    # TODO: we should reload user in case it is tainted, should take in a user_id as opposed to user\n    # If we don't do this we introduce a rather risky dependency\n    @user = user\n    @spam = false\n    @opts = opts || {}\n\n    opts[:title] = pg_clean_up(opts[:title]) if opts[:title]&.include?(\"\\u0000\")\n    opts[:raw] = pg_clean_up(opts[:raw]) if opts[:raw]&.include?(\"\\u0000\")\n    opts[:visible] = false if (\n      (opts[:visible].nil? && opts[:hidden_reason_id].present?) ||\n        (opts[:embed_url].present? && SiteSetting.embed_unlisted?)\n    )\n\n    opts.delete(:reply_to_post_number) unless opts[:topic_id]\n  end",
    "comment": "Acceptable options:  raw                     - raw text of post image_sizes             - We can pass a list of the sizes of images in the post as a shortcut. invalidate_oneboxes     - Whether to force invalidation of oneboxes in this post acting_user             - The user performing the action might be different than the user who is the post \"author.\" For example when copying posts to a new topic. created_at              - Post creation time (optional) auto_track              - Automatically track this topic if needed (default true) custom_fields           - Custom fields to be added to the post, Hash (default nil) post_type               - Whether this is a regular post or moderator post. no_bump                 - Do not cause this post to bump the topic. cooking_options         - Options for rendering the text cook_method             - Method of cooking the post. :regular - Pass through Markdown parser and strip bad HTML :raw_html - Perform no processing :raw_email - Imported from an email via_email               - Mark this post as arriving via email raw_email               - Full text of arriving email (to store) action_code             - Describes a small_action post (optional) skip_jobs               - Don't enqueue jobs when creation succeeds. This is needed if you wrap `PostCreator` in a transaction, as the sidekiq jobs could dequeue before the commit finishes. If you do this, be sure to call `enqueue_jobs` after the transaction is committed. hidden_reason_id        - Reason for hiding the post (optional) skip_validations        - Do not validate any of the content in the post draft_key               - the key of the draft we are creating (will be deleted on success) advance_draft           - Destroy draft after creating post or topic silent                  - Do not update topic stats and fields like last_post_user_id  When replying to a topic: topic_id              - topic we're replying to reply_to_post_number  - post number we're replying to  When creating a topic: title                 - New topic title archetype             - Topic archetype is_warning            - Is the topic a warning? category              - Category to assign to topic target_usernames      - comma delimited list of usernames for membership (private message) target_group_names    - comma delimited list of groups for membership (private message) created_at            - Topic creation time (optional) pinned_at             - Topic pinned time (optional) pinned_globally       - Is the topic pinned globally (optional) shared_draft          - Is the topic meant to be a shared draft topic_opts            - Options to be overwritten for topic embed_url             - Creates a TopicEmbed for the topic embed_content_sha1    - Sets the content_sha1 of the TopicEmbed ",
    "label": "",
    "id": "118"
  },
  {
    "raw_code": "def stop\n    @mutex.synchronize { @stop_requested = true }\n\n    if @thread\n      @thread.wakeup\n      @thread.join\n      @thread = nil\n    end",
    "comment": "Used for testing to stop the thread. In production, the thread is expected to live for the lifetime of the process.",
    "label": "",
    "id": "119"
  },
  {
    "raw_code": "def self.resize(width, height, opts = {})\n    return if width.blank? || height.blank?\n\n    max_width = (opts[:max_width] || SiteSetting.max_image_width).to_f\n    max_height = (opts[:max_height] || SiteSetting.max_image_height).to_f\n\n    w = width.to_f\n    h = height.to_f\n\n    return w.floor, h.floor if w <= max_width && h <= max_height\n\n    ratio = [max_width / w, max_height / h].min\n    [(w * ratio).floor, (h * ratio).floor]\n  end",
    "comment": "Resize an image to the aspect ratio we want",
    "label": "",
    "id": "120"
  },
  {
    "raw_code": "def ensure_cors!(rules = nil)\n    return unless SiteSetting.s3_install_cors_rule\n    rules = [rules] if !rules.is_a?(Array)\n    existing_rules = fetch_bucket_cors_rules\n\n    new_rules = rules - existing_rules\n    return false if new_rules.empty?\n\n    final_rules = existing_rules + new_rules\n\n    begin\n      s3_resource.client.put_bucket_cors(\n        bucket: @s3_bucket_name,\n        cors_configuration: {\n          cors_rules: final_rules,\n        },\n      )\n    rescue Aws::S3::Errors::AccessDenied\n      Rails.logger.info(\n        \"Could not PutBucketCors rules for #{@s3_bucket_name}, rules: #{final_rules}\",\n      )\n      return false\n    end",
    "comment": "Several places in the application need certain CORS rules to exist inside an S3 bucket so requests to the bucket can be made directly from the browser. The s3:ensure_cors_rules rake task is used to ensure these rules exist for assets, S3 backups, and direct S3 uploads, depending on configuration.",
    "label": "",
    "id": "121"
  },
  {
    "raw_code": "def list_multipart_parts(upload_id:, key:, max_parts: 1000, start_from_part_number: nil)\n    options = { bucket: s3_bucket_name, key: key, upload_id: upload_id, max_parts: max_parts }\n\n    options[:part_number_marker] = start_from_part_number if start_from_part_number.present?\n\n    s3_client.list_parts(options)\n  end",
    "comment": "Important note from the S3 documentation:  This request returns a default and maximum of 1000 parts. You can restrict the number of parts returned by specifying the max_parts argument. If your multipart upload consists of more than 1,000 parts, the response returns an IsTruncated field with the value of true, and a NextPartNumberMarker element.  In subsequent ListParts requests you can include the part_number_marker arg using the NextPartNumberMarker the field value from the previous response to get more parts.  See https://docs.aws.amazon.com/sdk-for-ruby/v3/api/Aws/S3/Client.html#list_parts-instance_method",
    "label": "",
    "id": "122"
  },
  {
    "raw_code": "def presigned_request(\n    key,\n    method:,\n    expires_in: S3Helper::UPLOAD_URL_EXPIRES_AFTER_SECONDS,\n    opts: {}\n  )\n    Aws::S3::Presigner.new(client: s3_client).presigned_request(\n      method,\n      {\n        bucket: s3_bucket_name,\n        key: key,\n        expires_in: expires_in,\n        use_accelerate_endpoint: @s3_options[:use_accelerate_endpoint],\n        use_dualstack_endpoint: @s3_options[:use_dualstack_endpoint],\n      }.merge(opts),\n    )\n  end",
    "comment": "Returns url, headers in a tuple which is needed in some cases.",
    "label": "",
    "id": "123"
  },
  {
    "raw_code": "def self.output_sql_to_stderr!(filter_transactions: false)\n    Rails.logger.warn(\n      \"Stop! This instrumentation is not intended for use in production outside of debugging scenarios. Please be sure you know what you are doing when enabling this instrumentation.\",\n    )\n    @@instrumentation_debug_sql_filter_transactions = filter_transactions\n    @@instrumentation_setup_debug_sql ||=\n      begin\n        MethodProfiler.patch_with_debug_sql(\n          PG::Connection,\n          %i[exec async_exec exec_prepared send_query_prepared query exec_params],\n          :sql,\n        )\n        true\n      end",
    "comment": " This is almost the same as ensure_discourse_instrumentation! but should not be used in production. This logs all SQL queries run and their durations between start and stop.  filter_transactions - When true, we do not record timings of transaction related commits (BEGIN, COMMIT, ROLLBACK)",
    "label": "",
    "id": "124"
  },
  {
    "raw_code": "def [](group_id)\n    group_names[group_id]\n  end",
    "comment": "Lookup a group by id",
    "label": "",
    "id": "125"
  },
  {
    "raw_code": "def self.markdown(text, opts = {})\n    # we use the exact same markdown converter as the client\n    # TODO: use the same extensions on both client and server (in particular the template for mentions)\n    baked = nil\n    text = text || \"\"\n\n    protect do\n      context = v8\n\n      custom_emoji = {}\n      Emoji.custom.map { |e| custom_emoji[e.name] = e.url }\n\n      # note, any additional options added to __optInput here must be\n      # also be added to the buildOptions function in pretty-text.js,\n      # otherwise they will be discarded\n      buffer = +<<~JS\n        __optInput = {};\n        __optInput.siteSettings = #{SiteSetting.client_settings_json};\n        #{\"__optInput.disableEmojis = true\" if opts[:disable_emojis]}\n        __paths = #{paths_json};\n        __optInput.getURL = __getURL;\n        #{\"__optInput.features = #{opts[:features].to_json};\" if opts[:features]}\n        #{\"__optInput.featuresOverride = #{opts[:features_override].to_json};\" if opts[:features_override]}\n        #{\"__optInput.markdownItRules = #{opts[:markdown_it_rules].to_json};\" if opts[:markdown_it_rules]}\n        __optInput.getCurrentUser = __getCurrentUser;\n        __optInput.lookupAvatar = __lookupAvatar;\n        __optInput.lookupPrimaryUserGroup = __lookupPrimaryUserGroup;\n        __optInput.formatUsername = __formatUsername;\n        __optInput.getTopicInfo = __getTopicInfo;\n        __optInput.hashtagLookup = __hashtagLookup;\n        __optInput.customEmoji = #{custom_emoji.to_json};\n        __optInput.customEmojiTranslation = #{Plugin::CustomEmoji.translations.to_json};\n        __optInput.emojiUnicodeReplacer = __emojiUnicodeReplacer;\n        __optInput.emojiDenyList = #{Emoji.denied.to_json};\n        __optInput.lookupUploadUrls = __lookupUploadUrls;\n        __optInput.censoredRegexp = #{WordWatcher.serialized_regexps_for_action(:censor, engine: :js).to_json};\n        __optInput.watchedWordsReplace = #{WordWatcher.regexps_for_action(:replace, engine: :js).to_json};\n        __optInput.watchedWordsLink = #{WordWatcher.regexps_for_action(:link, engine: :js).to_json};\n        __optInput.additionalOptions = #{Site.markdown_additional_options.to_json};\n        __optInput.avatar_sizes = #{SiteSetting.avatar_sizes.to_json};\n      JS\n\n      buffer << \"__optInput.topicId = #{opts[:topic_id].to_i};\\n\" if opts[:topic_id]\n      buffer << \"__optInput.postId = #{opts[:post_id].to_i};\\n\" if opts[:post_id]\n\n      if opts[:force_quote_link]\n        buffer << \"__optInput.forceQuoteLink = #{opts[:force_quote_link]};\\n\"\n      end",
    "comment": "Acceptable options:  disable_emojis    - Disables the emoji markdown engine. features          - A hash where the key is the markdown feature name and the value is a boolean to enable/disable the markdown feature. The hash is merged into the default features set in pretty-text.js which can be used to add new features or disable existing features. features_override - An array of markdown feature names to override the default markdown feature set. Currently used by plugins to customize what features should be enabled when rendering markdown. markdown_it_rules - An array of markdown rule names which will be applied to the markdown-it engine. Currently used by plugins to customize what markdown-it rules should be enabled when rendering markdown. topic_id          - Topic id for the post being cooked. post_id           - Post id for the post being cooked. user_id           - User id for the post being cooked. force_quote_link  - Always create the link to the quoted topic for [quote] bbcode. Normally this only happens if the topic_id provided is different from the [quote topic:X]. hashtag_context   - Defaults to \"topic-composer\" if not supplied. Controls the order of #hashtag lookup results based on registered hashtag contexts from the `#register_hashtag_search_param` plugin API method.",
    "label": "",
    "id": "126"
  },
  {
    "raw_code": "def self.avatar_img(avatar_template, size)\n    protect { v8.eval(<<~JS) }\n        __optInput = {};\n        __optInput.avatar_sizes = #{SiteSetting.avatar_sizes.to_json};\n        __paths = #{paths_json};\n        require(\"discourse/lib/avatar-utils\").avatarImg({size: #{size.inspect}, avatarTemplate: #{avatar_template.inspect}}, __getURL);\n      JS\n  end",
    "comment": "leaving this here, cause it invokes v8, don't want to implement twice",
    "label": "",
    "id": "127"
  },
  {
    "raw_code": "def trusted_spam_flagger?\n    SiteSetting.high_trust_flaggers_auto_hide_posts && @post_action_name == :spam &&\n      @created_by.has_trust_level?(TrustLevel[3]) && @post.user&.trust_level == TrustLevel[0]\n  end",
    "comment": "Special case: If you have TL3 and the user is TL0, and the flag is spam, hide it immediately.",
    "label": "",
    "id": "128"
  },
  {
    "raw_code": "def parse_screenshots_as_theme_fields!(screenshots, theme_importer)\n    updated_theme_fields = []\n    screenshots = Array.wrap(screenshots).take(MAX_THEME_SCREENSHOT_COUNT)\n    screenshots.each do |relative_path|\n      path = theme_importer.real_path(relative_path)\n      next if !path.present?\n\n      screenshot_filename = File.basename(path)\n      screenshot_extension = File.extname(path)\n\n      if !THEME_SCREENSHOT_ALLOWED_FILE_TYPES.include?(screenshot_extension)\n        raise ThemeScreenshotError,\n              I18n.t(\n                \"themes.import_error.screenshot_invalid_type\",\n                file_name: screenshot_filename,\n                accepted_formats: THEME_SCREENSHOT_ALLOWED_FILE_TYPES.join(\",\"),\n              )\n      end",
    "comment": "Screenshots here come from RemoteTheme.extract_theme_info, which in turn parses the theme about.json file, which is where screenshots are defined.",
    "label": "",
    "id": "129"
  },
  {
    "raw_code": "def self.fetch_title(\n    url,\n    max_redirects: nil,\n    initial_https_redirect_ignore_limit: false,\n    headers: {}\n  )\n    fd =\n      FinalDestination.new(\n        url,\n        timeout: CRAWL_TIMEOUT,\n        stop_at_blocked_pages: true,\n        max_redirects: max_redirects,\n        initial_https_redirect_ignore_limit: initial_https_redirect_ignore_limit,\n        headers: headers.merge({ Accept: \"text/html,*/*\" }),\n      )\n\n    current = nil\n    title = nil\n    encoding = nil\n\n    fd.get do |_response, chunk, uri|\n      unless Net::HTTPRedirection === _response\n        throw :done if uri.blank?\n\n        if current\n          current << chunk\n        else\n          current = chunk\n        end",
    "comment": "Fetch the beginning of a HTML document at a url",
    "label": "",
    "id": "130"
  },
  {
    "raw_code": "def allowing_actor_communication\n    (preferences.allowing_actor_communication.map(&:user_id) + users_with_no_preference).uniq\n  end",
    "comment": " Users who have preferences are the only ones initially loaded by the query, so implicitly the leftover users have no preferences that mute, ignore, or disallow PMs from any other user.",
    "label": "",
    "id": "131"
  },
  {
    "raw_code": "def preventing_actor_communication\n    preferences.preventing_actor_communication.map(&:user_id)\n  end",
    "comment": " Any users who are either ignoring, muting, or disallowing PMs from the actor. Ignoring and muting implicitly ignore PMs which is why they fall under this umbrella as well.",
    "label": "",
    "id": "132"
  },
  {
    "raw_code": "def ignoring_or_muting_actor?(user_id)\n    validate_user_id!(user_id)\n    preferences.ignoring_or_muting?(user_id)\n  end",
    "comment": " Whether the user is ignoring or muting the actor, meaning the actor cannot PM or send notifications to this target user.",
    "label": "",
    "id": "133"
  },
  {
    "raw_code": "def disallowing_pms_from_actor?(user_id)\n    validate_user_id!(user_id)\n    preferences.disallowing_pms?(user_id) || ignoring_or_muting_actor?(user_id)\n  end",
    "comment": " Whether the user is disallowing PMs from the actor specifically or in general, meaning the actor cannot send PMs to this target user. Ignoring or muting implicitly disallows PMs, so we need to take into account those preferences here too.",
    "label": "",
    "id": "134"
  },
  {
    "raw_code": "def actor_ignoring?(user_id)\n    validate_user_id!(user_id)\n    actor_preferences[:ignoring].include?(user_id)\n  end",
    "comment": " The actor methods below are more fine-grained than the user ones, since we may want to display more detailed messages to the actor about their preferences than we do when we are informing the actor that they cannot communicate with certain users.  In this spirit, actor_disallowing_pms? is intentionally different from disallowing_pms_from_actor? above.",
    "label": "",
    "id": "135"
  },
  {
    "raw_code": "def self.register_plugin_post_custom_field(field, plugin)\n    plugin_post_custom_fields[field] = plugin\n  end",
    "comment": "Allow plugins to add custom fields to the flag views",
    "label": "",
    "id": "136"
  },
  {
    "raw_code": "def self.each_onebox_link(doc, extra_paths: [])\n    onebox_links = doc.css(\"a.#{ONEBOX_CSS_CLASS}\", *extra_paths)\n    if onebox_links.present?\n      onebox_links.each { |link| yield(link[\"href\"], link) if link[\"href\"].present? }\n    end",
    "comment": "Parse URLs out of HTML, returning the document when finished.",
    "label": "",
    "id": "137"
  },
  {
    "raw_code": "def custom_staff_check(request)\n    true\n  end",
    "comment": "Extensibility point: plugins can overwrite this to add additional checks if they require.",
    "label": "",
    "id": "138"
  },
  {
    "raw_code": "def self.hash_password(password:, salt:, algorithm:)\n    algorithm = algorithm.delete_prefix(\"$\").delete_suffix(\"$\")\n\n    parts = algorithm.split(\"$\")\n    raise InvalidAlgorithmError if parts.length != 2\n\n    algorithm_id, algorithm_params = parts\n\n    algorithm_params = algorithm_params.split(\",\").map { |pair| pair.split(\"=\") }.to_h\n\n    handler = HANDLERS[algorithm_id]\n    if handler.nil?\n      raise UnsupportedAlgorithmError.new \"#{algorithm_id} is not a supported password algorithm\"\n    end",
    "comment": "Algorithm should be specified according to the id/params parts of the PHC string format. https://github.com/P-H-C/phc-string-format/blob/master/phc-sf-spec.md",
    "label": "",
    "id": "139"
  },
  {
    "raw_code": "def self.disabled?\n    @disabled\n  end",
    "comment": "We don't observe rate limits in test mode",
    "label": "",
    "id": "140"
  },
  {
    "raw_code": "def self.execute_command(*command, **args)\n      runner = CommandRunner.new(**args)\n\n      if block_given?\n        if command.present?\n          raise RuntimeError.new(\"Cannot pass command and block to execute_command\")\n        end",
    "comment": "Usage: Discourse::Utils.execute_command(\"pwd\", chdir: 'mydirectory') or with a block Discourse::Utils.execute_command(chdir: 'mydirectory') do |runner| runner.exec(\"pwd\") end",
    "label": "",
    "id": "141"
  },
  {
    "raw_code": "def self.handle_job_exception(ex, context = {}, parent_logger = nil)\n    return if ex.class == Jobs::HandledExceptionWrapper\n\n    context ||= {}\n    parent_logger ||= Sidekiq.default_configuration\n\n    job = context[:job]\n\n    # mini_scheduler direct reporting\n    if Hash === job\n      job_class = job[\"class\"]\n      job_exception_stats[job_class] += 1 if job_class\n    end",
    "comment": "Log an exception.  If your code is in a scheduled job, it is recommended to use the error_context() method in Jobs::Base to pass the job arguments and any other desired context. See app/jobs/base.rb for the error_context function.",
    "label": "",
    "id": "142"
  },
  {
    "raw_code": "def self.os_hostname\n    @os_hostname ||=\n      begin\n        require \"socket\"\n        Socket.gethostname\n      rescue => e\n        warn_exception(e, message: \"Socket.gethostname is not working\")\n        begin\n          `hostname`.strip\n        rescue => e\n          warn_exception(e, message: \"hostname command is not working\")\n          \"unknown_host\"\n        end",
    "comment": "hostname of the server, operating system level called os_hostname so we do no confuse it with current_hostname",
    "label": "",
    "id": "143"
  },
  {
    "raw_code": "def self.current_hostname\n    SiteSetting.force_hostname.presence || RailsMultisite::ConnectionManagement.current_hostname\n  end",
    "comment": "Get the current base URL for the current site",
    "label": "",
    "id": "144"
  },
  {
    "raw_code": "def self.postgres_last_read_only\n    @postgres_last_read_only ||= DistributedCache.new(\"postgres_last_read_only\")\n  end",
    "comment": "Shared between processes",
    "label": "",
    "id": "145"
  },
  {
    "raw_code": "def self.redis_last_read_only\n    @redis_last_read_only ||= {}\n  end",
    "comment": "Per-process",
    "label": "",
    "id": "146"
  },
  {
    "raw_code": "def self.site_contact_user\n    user =\n      User.find_by(\n        username_lower: SiteSetting.site_contact_username.downcase,\n      ) if SiteSetting.site_contact_username.present?\n    user ||= (system_user || User.admins.real.order(:id).first)\n  end",
    "comment": "Either returns the site_contact_username user or the first admin.",
    "label": "",
    "id": "147"
  },
  {
    "raw_code": "def self.before_fork\n    # V8 does not support forking, make sure all contexts are disposed\n    ObjectSpace.each_object(MiniRacer::Context) { |c| c.dispose }\n\n    # get rid of rubbish so we don't share it\n    # longer term we will use compact! here\n    GC.start\n    GC.start\n    GC.start\n  end",
    "comment": "all forking servers must call this before forking, otherwise the forked process might be in a bad state",
    "label": "",
    "id": "148"
  },
  {
    "raw_code": "def self.after_fork\n    # note: some of this reconnecting may no longer be needed per https://github.com/redis/redis-rb/pull/414\n    MessageBus.after_fork\n    SiteSetting.after_fork\n    Discourse.redis.reconnect\n    Rails.cache.reconnect\n    Discourse.cache.reconnect\n    Logster.store.redis.reconnect\n    Sidekiq.redis_pool.reload(&:close)\n\n    # in case v8 was initialized we want to make sure it is nil\n    PrettyText.reset_context\n\n    DiscourseJsProcessor::Transpiler.reset_context if defined?(DiscourseJsProcessor::Transpiler)\n\n    # warm up v8 after fork, that way we do not fork a v8 context\n    # it may cause issues if bg threads in a v8 isolate randomly stop\n    # working due to fork\n    begin\n      # Skip warmup in development mode - it makes boot take ~2s longer\n      PrettyText.cook(\"warm up **pretty text**\") if !Rails.env.development?\n    rescue => e\n      Rails.logger.error(\"Failed to warm up pretty text: #{e}\\n#{e.backtrace.join(\"\\n\")}\")\n    end",
    "comment": "all forking servers must call this after fork, otherwise Discourse will be in a bad state",
    "label": "",
    "id": "149"
  },
  {
    "raw_code": "def self.warn(message, env = nil)\n    append = env ? (+\" \") << env.map { |k, v| \"#{k}: #{v}\" }.join(\" \") : \"\"\n\n    loggers = Rails.logger.broadcasts\n    logster_env = env\n\n    if old_env = Thread.current[Logster::Logger::LOGSTER_ENV]\n      logster_env = Logster::Message.populate_from_env(old_env)\n\n      # a bit awkward by try to keep the new params\n      env.each { |k, v| logster_env[k] = v }\n    end",
    "comment": "you can use Discourse.warn when you want to report custom environment with the error, this helps with grouping",
    "label": "",
    "id": "150"
  },
  {
    "raw_code": "def self.warn_exception(e, message: \"\", env: nil)\n    if Rails.logger.respond_to? :add_with_opts\n      env ||= {}\n      env[:current_db] ||= RailsMultisite::ConnectionManagement.current_db\n\n      # logster\n      Rails.logger.add_with_opts(\n        ::Logger::Severity::WARN,\n        \"#{message} : #{e.class.name} : #{e}\",\n        \"discourse-exception\",\n        backtrace: e.backtrace.join(\"\\n\"),\n        env: env,\n      )\n    else\n      # no logster ... fallback\n      Rails.logger.warn(\"#{message} #{e}\\n#{e.backtrace.join(\"\\n\")}\")\n    end",
    "comment": "report a warning maintaining backtrack for logster",
    "label": "",
    "id": "151"
  },
  {
    "raw_code": "def self.preload_rails!\n    return if @preloaded_rails\n\n    if !Rails.env.development?\n      # Skipped in development because the schema cache gets reset on every code change anyway\n      # Better to rely on the filesystem-based db:schema:cache:dump\n\n      # load up all models and schema\n      (ActiveRecord::Base.connection.tables - %w[schema_migrations versions]).each do |table|\n        begin\n          table.classify.constantize.first\n        rescue StandardError\n          nil\n        end",
    "comment": "this is used to preload as much stuff as possible prior to forking in turn this can conserve large amounts of memory on forking servers",
    "label": "",
    "id": "152"
  },
  {
    "raw_code": "def self.clear_all_theme_cache!\n    ThemeField.force_recompilation!\n    Theme.all.each(&:update_javascript_cache!)\n    Theme.expire_site_cache!\n  end",
    "comment": "warning: this method is very expensive and shouldn't be called in places where performance matters. it's meant to be called manually (e.g. in the rails console) when dealing with an emergency that requires invalidating theme cache",
    "label": "",
    "id": "153"
  },
  {
    "raw_code": "def self.enable_sidekiq_logging\n    @@sidekiq_logging_enabled = true\n  end",
    "comment": "For test environment only",
    "label": "",
    "id": "154"
  },
  {
    "raw_code": "def self.disable_sidekiq_logging\n    @@sidekiq_logging_enabled = false\n  end",
    "comment": "For test environment only",
    "label": "",
    "id": "155"
  },
  {
    "raw_code": "def synchronize\n    result = nil\n\n    @mutex.synchronize do\n      expire_time = get_lock\n\n      begin\n        result = yield\n      ensure\n        current_time = redis.time[0]\n        if current_time > expire_time\n          warn(\n            \"held for too long, expected max: #{@validity} secs, took an extra #{current_time - expire_time} secs\",\n          )\n        end",
    "comment": "NOTE wrapped in mutex to maintain its semantics",
    "label": "",
    "id": "156"
  },
  {
    "raw_code": "def revise!(editor, fields, opts = {})\n    @editor = editor\n    @fields = fields.with_indifferent_access\n    @opts = opts\n\n    @topic_changes = TopicChanges.new(@topic, editor)\n\n    # some normalization\n    @fields[:raw] = cleanup_whitespaces(@fields[:raw]) if @fields.has_key?(:raw)\n    @fields[:user_id] = @fields[:user_id].to_i if @fields.has_key?(:user_id)\n    @fields[:category_id] = @fields[:category_id].to_i if @fields.has_key?(:category_id)\n\n    # always reset edit_reason unless provided, do not set to nil else\n    # previous reasons are lost\n    @fields.delete(:edit_reason) if @fields[:edit_reason].blank?\n\n    Post.plugin_permitted_update_params.each do |field, val|\n      val[:handler].call(@post, @fields[field]) if @fields.key?(field) && val[:plugin].enabled?\n    end",
    "comment": "AVAILABLE OPTIONS: - revised_at: changes the date of the revision - force_new_version: bypass grace period edit window - bypass_rate_limiter: - bypass_bump: do not bump the topic, even if last post - skip_validations: ask ActiveRecord to skip validations - skip_revision: do not create a new PostRevision record - skip_staff_log: skip creating an entry in the staff action log - silent: don't send notifications to user",
    "label": "",
    "id": "157"
  },
  {
    "raw_code": "def self.sync(use_db_s3_config:, s3_client: nil)\n    return if !SiteSetting.s3_install_cors_rule\n    return if !(GlobalSetting.use_s3? || SiteSetting.enable_s3_uploads)\n\n    assets_rules_status = RULE_STATUS_SKIPPED\n    backup_rules_status = RULE_STATUS_SKIPPED\n    direct_upload_rules_status = RULE_STATUS_SKIPPED\n\n    s3_helper = S3Helper.build_from_config(s3_client: s3_client, use_db_s3_config: use_db_s3_config)\n    if !Rails.env.test?\n      puts \"Attempting to apply ASSETS S3 CORS ruleset in bucket #{s3_helper.s3_bucket_name}.\"\n    end",
    "comment": " Used by the s3:ensure_cors_rules rake task to make sure the relevant CORS rules are applied to allow for direct uploads to S3, and in the case of assets rules so there are fonts and other public assets for the site loaded correctly.  The use_db_s3_config param comes from ENV, and if the S3 client is not provided it is initialized by the S3Helper.",
    "label": "",
    "id": "158"
  },
  {
    "raw_code": "def after_initialize\n  end",
    "comment": "Plugins can overwrite this to munge values before formatting",
    "label": "",
    "id": "159"
  },
  {
    "raw_code": "def format\n    result = +\"\"\n    result << @reason if @reason.present?\n    result << \"\\n\\n#{@message}\" if @message.present?\n    result\n  end",
    "comment": "Overwrite this to change formatting",
    "label": "",
    "id": "160"
  },
  {
    "raw_code": "def remove_quote_level_indicators!(line)\n    match_data = line.text.match(/\\A(?<indicators>>+)\\s?(?<text>.*)/)\n\n    if match_data\n      line.text = match_data[:text]\n      line.quote_level = match_data[:indicators].length\n    end",
    "comment": "@param line [Line]",
    "label": "",
    "id": "161"
  },
  {
    "raw_code": "def merge_lines(line, previous_line)\n    return line if previous_line.nil? || line.text.blank?\n    return line if line.text == SIGNATURE_SEPARATOR || previous_line.text == SIGNATURE_SEPARATOR\n    unless line.quote_level == previous_line.quote_level && previous_line.text.end_with?(\" \")\n      return line\n    end",
    "comment": "@param line [Line] @param previous_line [Line] @return [Line]",
    "label": "",
    "id": "162"
  },
  {
    "raw_code": "def classify_line_as_code!(line, previous_line)\n    line.code_block = previous_line.code_block unless previous_line.nil? ||\n      previous_line.valid_code_block?\n    return unless line.text =~ /\\A\\s{0,3}```/\n\n    if line.code_block.present?\n      line.code_block.end_line = line\n    else\n      line.code_block = CodeBlock.new(line)\n    end",
    "comment": "@param line [Line] @param previous_line [Line]",
    "label": "",
    "id": "163"
  },
  {
    "raw_code": "def convert_text(line)\n    text = line.text\n\n    if line.valid_code_block?\n      code_block = line.code_block\n      return code_block.start_line == line || code_block.end_line == line ? text.lstrip : text\n    end",
    "comment": "@param line [Line] @return [string]",
    "label": "",
    "id": "164"
  },
  {
    "raw_code": "def self.clear_system_theme_user_history!\n    return if !Rails.env.test?\n\n    Theme::CORE_THEMES.each_key do |theme_name|\n      UserHistory\n        .where(action: UserHistory.actions[:change_theme_site_setting])\n        .where(\"subject ILIKE :theme_name\", theme_name: \"#{theme_name}:%\")\n        .destroy_all\n    end",
    "comment": "Don't want user history created from theme site setting changes from system themes polluting specs.",
    "label": "",
    "id": "165"
  },
  {
    "raw_code": "def self.events\n    @events ||= Hash.new { |hash, key| hash[key] = Set.new }\n  end",
    "comment": "Defaults to a hash where default values are empty sets.",
    "label": "",
    "id": "166"
  },
  {
    "raw_code": "def self.preload_polymorphic_associations(bookmarks, guardian)\n    Bookmark.registered_bookmarkables.each do |registered_bookmarkable|\n      registered_bookmarkable.perform_preload(bookmarks, guardian)\n    end",
    "comment": "These polymorphic associations are loaded to make the UserBookmarkListSerializer's life easier, which conditionally chooses the bookmark serializer to use based on the type, and we want the associations all loaded ahead of time to make sure we are not doing N+1s.",
    "label": "",
    "id": "167"
  },
  {
    "raw_code": "def initialize(*members)\n    super({})\n\n    if members[0].is_a?(Hash)\n      # hash\n      update Hash[members[0]]\n    else\n      # array\n      options = members.extract_options!\n      start = options.fetch(:start) { 1 }\n      update Hash[members.zip(start..members.count + start)]\n    end",
    "comment": "Public: Initialize an enum.  members - Array of enum members or Hash of enum members. Array of enum members may also contain a hash of options: :start - the number of first enum member. Defaults to 1.  Examples  FRUITS = Enum.new(:apple, :orange, :kiwi) # array FRUITS = Enum.new(:apple, :orange, :kiwi, start: 0) # array FRUITS = Enum.new(apple: 1, orange: 2, kiwi: 3) # hash",
    "label": "",
    "id": "168"
  },
  {
    "raw_code": "def [](id_or_value)\n    fetch(id_or_value) { key(id_or_value) }\n  end",
    "comment": "Public: Access the number/value of member.  ids_or_value - number or value of member.  Returns value if number was provided, and number if value was provided.",
    "label": "",
    "id": "169"
  },
  {
    "raw_code": "def valid?(member)\n    has_key?(member)\n  end",
    "comment": "Public: Check if supplied member is valid.",
    "label": "",
    "id": "170"
  },
  {
    "raw_code": "def only(*keys)\n    dup.tap { |d| d.keep_if { |k| keys.include?(k) } }\n  end",
    "comment": "Public: Create a subset of enum, only include specified keys.",
    "label": "",
    "id": "171"
  },
  {
    "raw_code": "def except(*keys)\n    dup.tap { |d| d.delete_if { |k| keys.include?(k) } }\n  end",
    "comment": "Public: Create a subset of enum, preserve all items but specified ones.",
    "label": "",
    "id": "172"
  },
  {
    "raw_code": "def notify_flag_type_ids\n    notify_flag_types.values\n  end",
    "comment": "flags resulting in mod notifications",
    "label": "",
    "id": "173"
  },
  {
    "raw_code": "def create_for(bookmarkable_id:, bookmarkable_type:, name: nil, reminder_at: nil, options: {})\n    registered_bookmarkable = Bookmark.registered_bookmarkable_from_type(bookmarkable_type)\n\n    if registered_bookmarkable.blank?\n      return add_error(I18n.t(\"bookmarks.errors.invalid_bookmarkable\", type: bookmarkable_type))\n    end",
    "comment": " Creates a bookmark for a registered bookmarkable (see Bookmark.register_bookmarkable and RegisteredBookmarkable for details on this).  Only allows creation of bookmarks for records the user can access via Guardian.  Any ActiveModel validation errors raised by the Bookmark model are hoisted to the instance of this class for further reporting.  Before creation validations, after create callbacks, and after delete callbacks are all RegisteredBookmarkable specific and should be defined there.  @param [Integer] bookmarkable_id   The ID of the ActiveRecord model to attach the bookmark to. @param [String]  bookmarkable_type The class name of the ActiveRecord model to attach the bookmark to. @param [String]  name              A short note for the bookmark, shown on the user bookmark list and on hover of reminder notifications. @param reminder_at                 The datetime when a bookmark reminder should be sent after. Note this is not the exact time a reminder will be sent, as we send reminders on a rolling schedule. See Jobs::BookmarkReminderNotifications @params options                    Additional options when creating a bookmark - auto_delete_preference: See Bookmark.auto_delete_preferences, this is used to determine when to delete a bookmark automatically.",
    "label": "",
    "id": "174"
  },
  {
    "raw_code": "def self.clear_plugin_svg_sprite_cache!\n    @plugin_svgs = nil\n  end",
    "comment": "Just used in tests",
    "label": "",
    "id": "175"
  },
  {
    "raw_code": "def self.raw_svg(name)\n    get_set_cache(\"raw_svg_#{name}\") do\n      symbol = search(name)\n      break \"\" unless symbol\n      symbol = Nokogiri.XML(symbol).children.first\n      symbol.name = \"svg\"\n      <<~HTML\n        <svg class=\"fa d-icon svg-icon svg-node\" aria-hidden=\"true\">#{symbol}</svg>\n      HTML\n    end.html_safe\n  end",
    "comment": "For use in no_ember .html.erb layouts",
    "label": "",
    "id": "176"
  },
  {
    "raw_code": "def self.build(tuples, max_values = 300)\n    result = []\n\n    every = (tuples.size.to_f / max_values).ceil\n\n    last_days_ago = -1\n    tuples.each_with_index do |t, idx|\n      return result unless t.is_a?(Array)\n\n      if idx != tuples.size - 1\n        next unless (idx % every) === 0\n      end",
    "comment": "Given an array of tuples containing (id, days_ago), return at most `max_values` worth of a lookup table to help the front end timeline display dates associated with posts",
    "label": "",
    "id": "177"
  },
  {
    "raw_code": "def method_missing(meth, *args, **kwargs, &block)\n    if @redis.respond_to?(meth)\n      DiscourseRedis.ignore_readonly { @redis.public_send(meth, *args, **kwargs, &block) }\n    else\n      super\n    end",
    "comment": "prefix the key with the namespace",
    "label": "",
    "id": "178"
  },
  {
    "raw_code": "def self.memoize(key, duration = 60 * 60 * 24, redis = Discourse.redis)\n    redis_lock_key = self.redis_lock_key(key)\n    redis_key = self.redis_key(key)\n\n    DistributedMutex.synchronize(redis_lock_key, redis: redis, validity: MAX_WAIT) do\n      result = redis.get(redis_key)\n\n      unless result\n        result = yield\n        redis.setex(redis_key, duration, result)\n      end",
    "comment": "memoize a key across processes and machines",
    "label": "",
    "id": "179"
  },
  {
    "raw_code": "def with_allowed_param_values(new_allowed_param_values)\n    RouteMatcher.new(\n      actions: actions,\n      params: params,\n      methods: methods,\n      formats: formats,\n      aliases: aliases,\n      allowed_param_values: new_allowed_param_values,\n    )\n  end",
    "comment": "Return an identical route matcher, with the allowed_param_values replaced",
    "label": "",
    "id": "180"
  },
  {
    "raw_code": "def self.v8_call(*args, **kwargs)\n      fetch_result_call = kwargs.delete(:fetch_result_call)\n      mutex.synchronize do\n        result = v8.call(*args, **kwargs)\n        result = v8.call(fetch_result_call) if fetch_result_call\n        result\n      end",
    "comment": "Call a method in the global scope of the v8 context. The `fetch_result_call` kwarg provides a workaround for the lack of mini_racer async result support. The first call can perform some async operation, and then `fetch_result_call` will be called to fetch the result.",
    "label": "",
    "id": "181"
  },
  {
    "raw_code": "def parse_allowed_metadata(metadata)\n    return if metadata.blank?\n    metadata.permit(\"sha1-checksum\").to_h\n  end",
    "comment": "don't want people posting arbitrary S3 metadata so we just take the one we need. all of these will be converted to x-amz-meta- metadata fields in S3 so it's best to use dashes in the names for consistency  this metadata is baked into the presigned url and is not altered when sending the PUT from the clientside to the presigned url",
    "label": "",
    "id": "182"
  },
  {
    "raw_code": "def calculate(opts = nil)\n    update_posts_score(opts)\n    update_posts_rank(opts)\n    update_topics_rank(opts)\n  end",
    "comment": "Calculate the score for all posts based on the weightings",
    "label": "",
    "id": "183"
  },
  {
    "raw_code": "def self.reset_custom_public_types\n    @@custom_public_types = []\n  end",
    "comment": "used in tests",
    "label": "",
    "id": "184"
  },
  {
    "raw_code": "def priority_check?(check)\n    check == :access_control_post_should_secure_uploads && access_control_post\n  end",
    "comment": "The access control check is important because that is the truest indicator of whether an upload should be secure or not, and thus should be returned immediately if there is an access control post.",
    "label": "",
    "id": "185"
  },
  {
    "raw_code": "def secure_uploads_disabled_check\n    !SiteSetting.secure_uploads?\n  end",
    "comment": "START PUBLIC CHECKS ####",
    "label": "",
    "id": "186"
  },
  {
    "raw_code": "def login_required_check\n    SiteSetting.login_required? && !SiteSetting.secure_uploads_pm_only?\n  end",
    "comment": "END PUBLIC CHECKS #### --------------------------# START PRIVATE CHECKS ####",
    "label": "",
    "id": "187"
  },
  {
    "raw_code": "def access_control_post_should_secure_uploads_check\n    access_control_post&.should_secure_uploads?\n  end",
    "comment": "Whether the upload should remain secure or not after posting depends on its context, which is based on the post it is linked to via access_control_post_id.  If that post should_secure_uploads? then the upload should also be secure.  This may change to false if the upload was set to secure on upload e.g. in a post composer then it turned out that the post itself was not in a secure context.  A post is with secure uploads if it is a private message or in a read restricted category. See `Post#should_secure_uploads?` for the full definition.",
    "label": "",
    "id": "188"
  },
  {
    "raw_code": "def perform_delete\n    # All posts in the topic must be force deleted if the first is force\n    # deleted (except @post which is destroyed by current instance).\n    if @topic && @post.is_first_post? && permanent?\n      @topic.posts.with_deleted.find_each do |post|\n        PostDestroyer.new(@user, post, @opts).destroy if post.id != @post.id\n      end",
    "comment": "When a post is properly deleted. Well, it's still soft deleted, but it will no longer show up in the topic Permanent option allows to hard delete.",
    "label": "",
    "id": "189"
  },
  {
    "raw_code": "def mark_for_deletion(delete_removed_posts_after = SiteSetting.delete_removed_posts_after)\n    I18n.with_locale(SiteSetting.default_locale) do\n      # don't call revise from within transaction, high risk of deadlock\n      key =\n        (\n          if @post.is_first_post?\n            \"js.topic.deleted_by_author_simple\"\n          else\n            \"js.post.deleted_by_author_simple\"\n          end",
    "comment": "When a user 'deletes' their own post. We just change the text.",
    "label": "",
    "id": "190"
  },
  {
    "raw_code": "def mark_topic_changed\n    # make this as fast as possible, can bypass everything\n    DB.exec(<<~SQL, updated_at: Time.now, id: @post.topic_id)\n      UPDATE topics\n      SET updated_at = :updated_at\n      WHERE id = :id\n    SQL\n  end",
    "comment": "we need topics to change if ever a post in them is deleted or created this ensures users relying on this information can keep unread tracking working as desired",
    "label": "",
    "id": "191"
  },
  {
    "raw_code": "def defer_set(k, v)\n    Scheduler::Defer.later(\"#{@key}_set\") { self[k] = v }\n  end",
    "comment": "Defer setting of the key in the cache for performance critical path to avoid waiting on MessageBus to publish the message which involves writing to Redis.",
    "label": "",
    "id": "192"
  },
  {
    "raw_code": "def self.show_original?(scope)\n    scope&.request&.cookies&.key?(SHOW_ORIGINAL_COOKIE)\n  end",
    "comment": "@param scope [Object] The serializer scope from which the method is called @return [Boolean] if the cookie is set, false otherwise",
    "label": "",
    "id": "193"
  },
  {
    "raw_code": "def self.show_translated_post?(post, scope)\n    SiteSetting.content_localization_enabled && post.raw.present? && post.locale.present? &&\n      !post.in_user_locale? && !show_original?(scope)\n  end",
    "comment": "This method returns true when we should try to show the translated post. @param scope [Object] The serializer scope from which the method is called @param post [Post] The post object @return [Boolean]",
    "label": "",
    "id": "194"
  },
  {
    "raw_code": "def self.show_translated_topic?(topic, scope)\n    SiteSetting.content_localization_enabled && topic.locale.present? && !topic.in_user_locale? &&\n      !show_original?(scope)\n  end",
    "comment": "This method returns true when we should try to show the translated topic. @param scope [Object] The serializer scope from which the method is called @param topic [Topic] The topic record @return [Boolean]",
    "label": "",
    "id": "195"
  },
  {
    "raw_code": "def missing?\n    @parent_post.blank?\n  end",
    "comment": "This algorithm is far from perfect, but it follows the Discourse philosophy of \"catch the obvious cases, leave moderation for the complicated ones\"",
    "label": "",
    "id": "196"
  },
  {
    "raw_code": "def custom_admin_check(request)\n    true\n  end",
    "comment": "Extensibility point: plugins can overwrite this to add additional checks if they require.",
    "label": "",
    "id": "197"
  },
  {
    "raw_code": "def digest\n    @digest ||=\n      begin\n        if is_theme?\n          theme_digest\n        elsif is_color_scheme?\n          color_scheme_digest\n        else\n          default_digest\n        end",
    "comment": "digest encodes the things that trigger a recompile",
    "label": "",
    "id": "198"
  },
  {
    "raw_code": "def plugins_digest\n    assets = []\n    DiscoursePluginRegistry.stylesheets.each { |_, paths| assets += paths.to_a }\n    DiscoursePluginRegistry.mobile_stylesheets.each { |_, paths| assets += paths.to_a }\n    DiscoursePluginRegistry.desktop_stylesheets.each { |_, paths| assets += paths.to_a }\n    Digest::SHA1.hexdigest(assets.sort.join)\n  end",
    "comment": "this protects us from situations where new versions of a plugin removed a file old instances may still be serving CSS and not aware of the change so we could end up poisoning the cache with a bad file that can not be removed",
    "label": "",
    "id": "199"
  },
  {
    "raw_code": "def prepare_unsubscribe_options(controller)\n      controller.instance_variable_set(:@digest_unsubscribe, false)\n      controller.instance_variable_set(:@watched_count, nil)\n      controller.instance_variable_set(:@type, unsubscribe_key.unsubscribe_key_type)\n\n      controller.instance_variable_set(:@user, key_owner)\n\n      controller.instance_variable_set(\n        :@unsubscribed_from_all,\n        key_owner.user_option.unsubscribed_from_all?,\n      )\n    end",
    "comment": "Sets instance variables in the `EmailController#unsubscribe`, which are later available in the view. Don't forget to call super when extending this method.",
    "label": "",
    "id": "200"
  },
  {
    "raw_code": "def unsubscribe(params)\n      updated = false\n\n      if params[:disable_mailing_list]\n        key_owner.user_option.update_columns(mailing_list_mode: false)\n        updated = true\n      end",
    "comment": "Called by the `EmailController#perform_unsubscribe` and defines what unsubscribing means.  Receives the request params and returns a boolean indicating if any preferences were updated.  Don't forget to call super when extending this method.",
    "label": "",
    "id": "201"
  },
  {
    "raw_code": "def execution_flow\n    steps\n      .filter_map\n      .with_index do |step, index|\n        next if @encountered_error\n        @encountered_error = index + 1 if step.failure?\n        \"[#{format(\"%#{steps.size.to_s.size}s\", index + 1)}/#{steps.size}] #{step.inspect}\"\n      end",
    "comment": "Example output: [1/4] [model] channel (0.02 ms)  [2/4] [params] default (0.1 ms)  [3/4] [policy] check_channel_permission  [4/4] [step] change_status @return [String] the steps of the result object with their state",
    "label": "",
    "id": "202"
  },
  {
    "raw_code": "def error\n    steps.detect(&:error?)&.error\n  end",
    "comment": "@return [String, nil] the first available error, if any.",
    "label": "",
    "id": "203"
  },
  {
    "raw_code": "def initialize(service, object, dependencies)\n    @service = service\n    @object = object\n    @dependencies = dependencies\n    @actions = {}\n  end",
    "comment": "@!visibility private",
    "label": "",
    "id": "204"
  },
  {
    "raw_code": "def self.call(service, dependencies = {}, &block)\n    new(service, block.binding.eval(\"self\"), dependencies).call(&block)\n  end",
    "comment": "@param service [Class] a class including {Service::Base} @param dependencies [Hash] dependencies to be provided to the service @param block [Proc] a block containing the steps to match on @return [void]",
    "label": "",
    "id": "205"
  },
  {
    "raw_code": "def call(&block)\n    instance_exec(result, &block)\n    # Always have `on_failure` as the last action\n    (\n      actions\n        .except(:on_failure)\n        .merge(actions.slice(:on_failure))\n        .detect { |name, (condition, _)| condition.call } || [-> {}]\n    ).flatten.last.call\n  end",
    "comment": "@!visibility private",
    "label": "",
    "id": "206"
  },
  {
    "raw_code": "def initialize(context = nil)\n        @context = context\n        super\n      end",
    "comment": "@!visibility private",
    "label": "",
    "id": "207"
  },
  {
    "raw_code": "def success?\n        !failure?\n      end",
    "comment": "@return [Boolean] returns +true+ if the context is set as successful (default)",
    "label": "",
    "id": "208"
  },
  {
    "raw_code": "def failure?\n        @failure || false\n      end",
    "comment": "@return [Boolean] returns +true+ if the context is set as failed @see #fail! @see #fail",
    "label": "",
    "id": "209"
  },
  {
    "raw_code": "def fail!(context = {})\n        self.fail(context)\n        raise Failure, self\n      end",
    "comment": "Marks the context as failed. @param context [Hash, Context] the context to merge into the current one @example context.fail!(\"failure\": \"something went wrong\") @return [Context]",
    "label": "",
    "id": "210"
  },
  {
    "raw_code": "def fail(context = {})\n        store.merge!(context.symbolize_keys)\n        @failure = true\n        self\n      end",
    "comment": "Marks the context as failed without raising an exception. @param context [Hash, Context] the context to merge into the current one @example context.fail(\"failure\": \"something went wrong\") @return [Context]",
    "label": "",
    "id": "211"
  },
  {
    "raw_code": "def initialize(initial_context = {})\n      @context =\n        Context.build(\n          initial_context\n            .compact\n            .reverse_merge(params: {})\n            .merge(__steps__: self.class.steps, __service_class__: self.class),\n        )\n      initialize_params\n    end",
    "comment": "@!scope class @!method model(name = :model, step_name = :\"fetch_#{name}\", optional: false) @param name [Symbol] name of the model @param step_name [Symbol] name of the method to call for this step @param optional [Boolean] if +true+, then the step wont fail if its return value is falsy. Evaluates arbitrary code to build or fetch a model (typically from the DB). If the step returns a falsy value, then the step will fail.  It stores the resulting model in +context[:model]+ by default (can be customized by providing the +name+ argument).  @example model :channel  private  def fetch_channel(channel_id:) Chat::Channel.find_by(id: channel_id) end @!scope class @!method policy(name = :default, class_name: nil) @param name [Symbol] name for this policy @param class_name [Class] a policy object (should inherit from +PolicyBase+) Performs checks related to the state of the system. If the step doesnt return a truthy value, then the policy will fail.  When using a policy object, there is no need to define a method on the service for the policy step. The policy object `#call` method will be called and if the result isnt truthy, a `#reason` method is expected to be implemented to explain the failure.  Policy objects are usually useful for more complex logic.  @example Without a policy object policy :no_direct_message_channel  private  def no_direct_message_channel(channel:) !channel.direct_message_channel? end  @example With a policy object # in the service object policy :no_direct_message_channel, class_name: NoDirectMessageChannelPolicy  # in the policy object File class NoDirectMessageChannelPolicy < PolicyBase def call !context.channel.direct_message_channel? end  def reason \"Direct message channels arent supported\" end end @!scope class @!method params(name = :default, default_values_from: nil, &block) @param name [Symbol] name for this contract @param default_values_from [Symbol] name of the model to get default values from @param block [Proc] a block containing validations Checks the validity of the input parameters. Implements ActiveModel::Validations and ActiveModel::Attributes.  It stores the resulting contract in +context[:params]+ by default (can be customized by providing the +name+ argument).  @example params do attribute :name validates :name, presence: true end @!scope class @!method step(name) @param name [Symbol] the name of this step Runs arbitrary code. To mark a step as failed, a call to {#fail!} needs to be made explicitly.  @example step :update_channel  private  def update_channel(channel:, params_to_edit:) channel.update!(params_to_edit) end @example using {#fail!} in a step step :save_channel  private  def save_channel(channel:) fail!(\"something went wrong\") if !channel.save end @!scope class @!method transaction(&block) @param block [Proc] a block containing steps to be run inside a transaction Runs steps inside a DB transaction.  @example transaction do step :prevents_slug_collision step :soft_delete_channel step :log_channel_deletion end @!scope class @!method options(&block) @param block [Proc] a block containing options definition This is used to define options allowing to parameterize the service behavior. The resulting options are available in `context[:options]`.  @example options do attribute :my_option, :boolean, default: false end @!visibility private",
    "label": "",
    "id": "212"
  },
  {
    "raw_code": "def run\n      run!\n    rescue Failure => exception\n      raise if context.object_id != exception.context.object_id\n    end",
    "comment": "@!visibility private",
    "label": "",
    "id": "213"
  },
  {
    "raw_code": "def run!\n      self.class.steps.each { |step| step.call(self, context) }\n    end",
    "comment": "@!visibility private",
    "label": "",
    "id": "214"
  },
  {
    "raw_code": "def fail!(message)\n      step_name = caller_locations(1, 1)[0].base_label\n      context[\"result.step.#{step_name}\"].fail(error: message)\n      context.fail!\n    end",
    "comment": "@!visibility private",
    "label": "",
    "id": "215"
  },
  {
    "raw_code": "def initialize(request, cookie)\n        @request = request\n        @cookie = cookie\n      end",
    "comment": ":nodoc:",
    "label": "",
    "id": "216"
  },
  {
    "raw_code": "def rate_limit_key\n        raise NotImplementedError\n      end",
    "comment": "This method is meant to be implemented in subclasses.  @return [String] The key used to identify the rate limiter.",
    "label": "",
    "id": "217"
  },
  {
    "raw_code": "def error_code_identifier\n        self.class.name.underscore.split(\"/\").last\n      end",
    "comment": ":nodoc:",
    "label": "",
    "id": "218"
  },
  {
    "raw_code": "def active?\n        raise NotImplementedError\n      end",
    "comment": "This method is meant to be implemented in subclasses.  @return [Boolean] Indicates if the rate limiter should be used for the request.",
    "label": "",
    "id": "219"
  },
  {
    "raw_code": "def rate_limit_globally?\n        raise NotImplementedError\n      end",
    "comment": "This method is meant to be implemented in subclasses.  @return [Boolean] Indicates whether the rate limit applies globally across all sites in the cluster or just for the current site.",
    "label": "",
    "id": "220"
  },
  {
    "raw_code": "def spawn_thread\n      thread = Thread.new { thread_loop }\n      thread.abort_on_exception = true\n      @threads << thread\n    end",
    "comment": "Outside of constructor usage this is called from a synchronized block we are already synchronized",
    "label": "",
    "id": "221"
  },
  {
    "raw_code": "def async=(val)\n      @async = val\n    end",
    "comment": "for test and sidekiq",
    "label": "",
    "id": "222"
  },
  {
    "raw_code": "def stopped?\n      !@thread&.alive?\n    end",
    "comment": "test only",
    "label": "",
    "id": "223"
  },
  {
    "raw_code": "def do_work(non_block = false)\n      db, job, desc, finish = @queue.shift(block: !non_block).values_at(:db, :job, :desc, :finish)\n\n      return if finish\n\n      start = Process.clock_gettime(Process::CLOCK_MONOTONIC)\n      db ||= RailsMultisite::ConnectionManagement::DEFAULT\n\n      RailsMultisite::ConnectionManagement.with_connection(db) do\n        begin\n          warning_job =\n            @reactor.queue(@timeout) do\n              Rails.logger.error \"'#{desc}' is still running after #{@timeout} seconds on db #{db}, this process may need to be restarted!\"\n            end if !non_block\n          job.call\n        rescue => ex\n          @stats_mutex.synchronize do\n            stats = @stats[desc]\n            stats[:errors] += 1 if stats\n          end",
    "comment": "using non_block to match Ruby #deq",
    "label": "",
    "id": "224"
  },
  {
    "raw_code": "def self.compile_key_builder\n      method = +\"def self.__compiled_key_builder(h)\\n  \\\"\"\n      cache_key_segments.each do |k, v|\n        raise \"Invalid key name\" unless k =~ /\\A[a-z]+\\z/\n        raise \"Invalid method name\" unless v =~ /\\Akey_[a-z_\\?]+\\z/\n        method << \"|#{k}=#\\{h.#{v}}\"\n      end",
    "comment": "Compile a string builder method that will be called to create an anonymous cache key",
    "label": "",
    "id": "225"
  },
  {
    "raw_code": "def is_mobile=(val)\n        @is_mobile = val ? :true : :false\n      end",
    "comment": "rubocop:disable Lint/BooleanSymbol",
    "label": "",
    "id": "226"
  },
  {
    "raw_code": "def key_locale\n        if locale = Discourse.anonymous_locale(@request)\n          locale\n        else\n          \"\" # No need to key, it is the same for all anon users\n        end",
    "comment": "rubocop:enable Lint/BooleanSymbol",
    "label": "",
    "id": "227"
  },
  {
    "raw_code": "def is_crawler?\n        @is_crawler ||=\n          begin\n            if @env[DISCOURSE_RENDER] == \"crawler\" ||\n                 CrawlerDetection.crawler?(@user_agent, @env[\"HTTP_VIA\"])\n              :true\n            else\n              if @user_agent.downcase.include?(\"discourse\") &&\n                   !@user_agent.downcase.include?(\"mobile\")\n                :true\n              else\n                :false\n              end",
    "comment": "rubocop:disable Lint/BooleanSymbol",
    "label": "",
    "id": "228"
  },
  {
    "raw_code": "def key_is_modern_mobile_device?\n        MobileDetection.modern_mobile_device?(@user_agent) if @user_agent\n      end",
    "comment": "rubocop:enable Lint/BooleanSymbol",
    "label": "",
    "id": "229"
  },
  {
    "raw_code": "def cache(result, env = {})\n        return result if GlobalSetting.anon_cache_store_threshold == 0\n\n        status, headers, response = result\n\n        if status == 200 && cache_duration\n          if GlobalSetting.anon_cache_store_threshold > 1\n            count =\n              REDIS_STORE_SCRIPT.eval(Discourse.redis, [cache_key_count], [cache_duration.to_i])\n\n            # technically lua will cast for us, but might as well be\n            # prudent here, hence the to_i\n            if count.to_i < GlobalSetting.anon_cache_store_threshold\n              headers[\"X-Discourse-Cached\"] = \"skip\"\n              return status, headers, response\n            end",
    "comment": "NOTE in an ideal world cache still serves out cached content except for one magic worker that fills it up, this avoids a herd killing you, we can probably do this using a job or redis tricks but coordinating this is tricky",
    "label": "",
    "id": "230"
  },
  {
    "raw_code": "def self.register_detailed_request_logger(callback)\n    MethodProfiler.ensure_discourse_instrumentation!\n    (@@detailed_request_loggers ||= []) << callback\n  end",
    "comment": "register callbacks for detailed request loggers called on every request example:  Middleware::RequestTracker.detailed_request_logger(->|env, data| do # do stuff with env and data end",
    "label": "",
    "id": "231"
  },
  {
    "raw_code": "def self.unregister_ip_skipper\n    @@ip_skipper = nil\n  end",
    "comment": "used for testing",
    "label": "",
    "id": "232"
  },
  {
    "raw_code": "def self.register_ip_skipper(&blk)\n    raise \"IP skipper is already registered!\" if @@ip_skipper\n    @@ip_skipper = blk\n  end",
    "comment": "Register a custom `ip_skipper`, a function that will skip rate limiting for any IP that returns true.  For example, if you never wanted to rate limit 1.2.3.4  ``` Middleware::RequestTracker.register_ip_skipper do |ip| ip == \"1.2.3.4\" end ```",
    "label": "",
    "id": "233"
  },
  {
    "raw_code": "def write_entries(entries, base_path, path, zipfile)\n      entries.each do |e|\n        zipfile_path = path == \"\" ? e : File.join(path, e)\n        disk_file_path = File.join(base_path, zipfile_path)\n\n        if File.directory? disk_file_path\n          recursively_deflate_directory(disk_file_path, zipfile, base_path, zipfile_path)\n        else\n          put_into_archive(disk_file_path, zipfile, zipfile_path)\n        end",
    "comment": "A helper method to make the recursion work.",
    "label": "",
    "id": "234"
  },
  {
    "raw_code": "def archive(uid)\n        thread_id = thread_id_from_uid(uid)\n        emails_to_archive = emails_in_thread(thread_id)\n        emails_to_archive.each do |email|\n          labels = email[\"LABELS\"]\n          new_labels = labels.reject { |l| l == \"\\\\Inbox\" }\n          store(email[\"UID\"], \"LABELS\", labels, new_labels)\n        end",
    "comment": "All emails in the thread must be archived in Gmail for the thread to get removed from the inbox",
    "label": "",
    "id": "235"
  },
  {
    "raw_code": "def unarchive(uid)\n        thread_id = thread_id_from_uid(uid)\n        emails_to_unarchive = emails_in_thread(thread_id)\n        emails_to_unarchive.each do |email|\n          labels = email[\"LABELS\"]\n          new_labels = labels.dup\n          new_labels << \"\\\\Inbox\" if !new_labels.include?(\"\\\\Inbox\")\n          store(email[\"UID\"], \"LABELS\", labels, new_labels)\n        end",
    "comment": "Though Gmail considers the email thread unarchived if the first email has the \\\\Inbox label applied, we want to do this to all emails in the thread to be consistent with archive behaviour.",
    "label": "",
    "id": "236"
  },
  {
    "raw_code": "def filter_mailboxes(mailboxes_with_attributes)\n        mailboxes_with_attributes\n          .reject { |mb| (mb.attr & %i[Drafts Sent Junk Flagged Trash]).any? }\n          .map(&:name)\n      end",
    "comment": "Some mailboxes are just not useful or advisable to sync with. This is used for the dropdown in the UI where we allow the user to select the IMAP mailbox to sync with.",
    "label": "",
    "id": "237"
  },
  {
    "raw_code": "def trash_mailbox\n        Discourse\n          .cache\n          .fetch(\"imap_trash_mailbox_#{account_digest}\", expires_in: 30.minutes) do\n            list_mailboxes(:Trash).first\n          end",
    "comment": "Look for the special Trash XLIST attribute.",
    "label": "",
    "id": "238"
  },
  {
    "raw_code": "def spam_mailbox\n        Discourse\n          .cache\n          .fetch(\"imap_spam_mailbox_#{account_digest}\", expires_in: 30.minutes) do\n            list_mailboxes(:Junk).first\n          end",
    "comment": "Look for the special Junk XLIST attribute.",
    "label": "",
    "id": "239"
  },
  {
    "raw_code": "def open_trash_mailbox(write: false)\n        open_mailbox_before_trash = @open_mailbox_name\n        open_mailbox_before_trash_write = @open_mailbox_write\n\n        trash_uid_validity = open_mailbox(trash_mailbox, write: write)[:uid_validity]\n\n        yield(trash_uid_validity) if block_given?\n\n        open_mailbox(open_mailbox_before_trash, write: open_mailbox_before_trash_write)\n        trash_uid_validity\n      end",
    "comment": "open the trash mailbox for inspection or writing. after the yield we close the trash and reopen the original mailbox to continue operations. the normal open_mailbox call can be made if more extensive trash ops need to be done.",
    "label": "",
    "id": "240"
  },
  {
    "raw_code": "def open_spam_mailbox(write: false)\n        open_mailbox_before_spam = @open_mailbox_name\n        open_mailbox_before_spam_write = @open_mailbox_write\n\n        spam_uid_validity = open_mailbox(spam_mailbox, write: write)[:uid_validity]\n\n        yield(spam_uid_validity) if block_given?\n\n        open_mailbox(open_mailbox_before_spam, write: open_mailbox_before_spam_write)\n        spam_uid_validity\n      end",
    "comment": "open the spam mailbox for inspection or writing. after the yield we close the spam and reopen the original mailbox to continue operations. the normal open_mailbox call can be made if more extensive spam ops need to be done.",
    "label": "",
    "id": "241"
  },
  {
    "raw_code": "def default_rate_limiter\n      return @rate_limiter if @rate_limiter.present?\n\n      limit_key = \"create_#{self.class.name.underscore}\"\n      max_setting =\n        if user && user.new_user? && SiteSetting.has_setting?(\"rate_limit_new_user_#{limit_key}\")\n          SiteSetting.get(\"rate_limit_new_user_#{limit_key}\")\n        else\n          SiteSetting.get(\"rate_limit_#{limit_key}\")\n        end",
    "comment": "Over write to define your own rate limiter",
    "label": "",
    "id": "242"
  },
  {
    "raw_code": "def disable_rate_limits!\n      @rate_limits_disabled = true\n    end",
    "comment": "For the lifetime of this instance, don't enforce rate limits.",
    "label": "",
    "id": "243"
  },
  {
    "raw_code": "def validate_user_presence\n      flags = auth_data[32].unpack(\"b*\")[0].split(\"\")\n      # bit 0 - user presence\n      return if flags[0] == \"1\"\n      raise(UserPresenceError, I18n.t(\"webauthn.validation.user_presence_error\"))\n    end",
    "comment": "flags per specification https://www.w3.org/TR/webauthn-2/#sctn-authenticator-data bit 0 - user presence bit 1 - reserved for future use bit 2 - user verification bit 3-5 - reserved for future use bit 6 - attested credential data bit 7 - extension data",
    "label": "",
    "id": "244"
  },
  {
    "raw_code": "def client_data_json\n      @client_data_json ||= Base64.decode64(@params[:clientData])\n    end",
    "comment": "https://w3c.github.io/webauthn/#sctn-registering-a-new-credential Let JSONtext be the result of running UTF-8 decode on the value of response.clientDataJSON.",
    "label": "",
    "id": "245"
  },
  {
    "raw_code": "def client_data\n      @client_data ||= JSON.parse(client_data_json)\n    end",
    "comment": "Let C, the client data claimed as collected during the credential creation, be the result of running an implementation-specific JSON parser on JSONtext.",
    "label": "",
    "id": "246"
  },
  {
    "raw_code": "def authenticate_security_key\n      # Steps 1-5 of this authentication flow are in the frontend at lib/webauthn.js\n      if @params.blank? || (!@params.is_a?(Hash) && !@params.is_a?(ActionController::Parameters))\n        raise(\n          MalformedPublicKeyCredentialError,\n          I18n.t(\"webauthn.validation.malformed_public_key_credential_error\"),\n        )\n      end",
    "comment": " See https://w3c.github.io/webauthn/#sctn-verifying-assertion for the steps followed here. Memoized methods are called in their place in the step flow to make the process clearer.",
    "label": "",
    "id": "247"
  },
  {
    "raw_code": "def register_security_key\n      # 4. Verify that the value of C.type is webauthn.create.\n      validate_webauthn_type(::DiscourseWebauthn::ACCEPTABLE_REGISTRATION_TYPE)\n\n      # 5. Verify that the value of C.challenge equals the base64url encoding of options.challenge.\n      validate_challenge\n\n      # 6. Verify that the value of C.origin matches the Relying Party's origin.\n      validate_origin\n\n      # 7. Verify that the value of C.tokenBinding.status matches the state of Token Binding for the TLS\n      #    connection over which the assertion was obtained. If Token Binding was used on that TLS connection,\n      #    also verify that C.tokenBinding.id matches the base64url encoding of the Token Binding ID for the connection.\n      #    Not using this right now.\n\n      # 8. Let hash be the result of computing a hash over response.clientDataJSON using SHA-256.\n      client_data_hash\n\n      # 9. Perform CBOR decoding on the attestationObject field of the AuthenticatorAttestationResponse\n      #    structure to obtain the attestation statement format fmt, the authenticator data authData,\n      #    and the attestation statement attStmt.\n      attestation\n\n      # 10. Verify that the rpIdHash in authData is the SHA-256 hash of the RP ID expected by the Relying Party.\n      # check the SHA256 hash of the rpId is the same as the authData bytes 0..31\n      validate_rp_id_hash\n\n      # 11. Verify that the User Present bit of the flags in authData is set.\n      # https://blog.bigbinary.com/2011/07/20/ruby-pack-unpack.html\n      #\n      validate_user_presence\n\n      #\n      # 12. If user verification is required for this registration, verify that\n      #     the User Verified bit of the flags in authData is set.\n      validate_user_verification if @factor_type == UserSecurityKey.factor_types[:first_factor]\n\n      # 13. Verify that the \"alg\" parameter in the credential public key in authData matches the alg\n      #     attribute of one of the items in options.pubKeyCredParams.\n      #     https://w3c.github.io/webauthn/#table-attestedCredentialData\n      #     See https://www.iana.org/assignments/cose/cose.xhtml#algorithms for supported algorithm\n      #     codes.\n      credential_public_key, credential_public_key_bytes, credential_id =\n        extract_public_key_and_credential_from_attestation(auth_data)\n      if ::DiscourseWebauthn::SUPPORTED_ALGORITHMS.exclude?(credential_public_key.alg)\n        raise(\n          UnsupportedPublicKeyAlgorithmError,\n          I18n.t(\"webauthn.validation.unsupported_public_key_algorithm_error\"),\n        )\n      end",
    "comment": " See https://w3c.github.io/webauthn/#sctn-registering-a-new-credential for the registration steps followed here. Memoized methods are called in their place in the step flow to make the process clearer.",
    "label": "",
    "id": "248"
  },
  {
    "raw_code": "def self.stats\n    Stat.all_stats\n  end",
    "comment": "This method returns Core stats + stats registered by plugins",
    "label": "",
    "id": "249"
  },
  {
    "raw_code": "def register_anonymous_cache_key(key, &block)\n    key_method = \"key_#{key}\"\n    add_to_class(Middleware::AnonymousCache::Helper, key_method, &block)\n    Middleware::AnonymousCache.cache_key_segments[key] = key_method\n    Middleware::AnonymousCache.compile_key_builder\n  end",
    "comment": "Keys can only be lowercase letters Example usage: plugin.register_anonymous_cache_key :onlylowercase do @request.cookies[\"cookie_name\"].present? ? \"1\" : \"0\" end",
    "label": "",
    "id": "250"
  },
  {
    "raw_code": "def add_report(name, &block)\n    reloadable_patch { |plugin| Report.add_report(name, &block) }\n  end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "251"
  },
  {
    "raw_code": "def replace_flags(settings: ::FlagSettings.new, score_type_names: [])\n    Discourse.deprecate(\n      \"replace flags should not be used as flags were moved to the database. Instead, a flag record should be added to the database. Alternatively, soon, the admin will be able to do this in the admin panel.\",\n    )\n    next_flag_id = ReviewableScore.types.values.max + 1\n\n    yield(settings, next_flag_id) if block_given?\n\n    reloadable_patch do |plugin|\n      ::PostActionType.replace_flag_settings(settings)\n      ::ReviewableScore.reload_types\n      ::ReviewableScore.add_new_types(score_type_names)\n    end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "252"
  },
  {
    "raw_code": "def add_filter_custom_filter(name, &block)\n    DiscoursePluginRegistry.register_custom_filter_mapping({ name => block }, self)\n  end",
    "comment": "Allows to define custom filter utilizing the user's input. Ensure proper input sanitization before using it in a query.  Example usage: add_filter_custom_filter(\"word_count\") do |scope, value, guardian| scope.where(word_count: value) if guardian.admin? end",
    "label": "",
    "id": "253"
  },
  {
    "raw_code": "def register_custom_filter_by_status(status, &block)\n    TopicsFilter.add_filter_by_status(status, &block)\n  end",
    "comment": "Allows to define custom \"status:\" filter. Example usage: register_custom_filter_by_status(\"foobar\") do |scope| scope.where(\"word_count = 42\") end",
    "label": "",
    "id": "254"
  },
  {
    "raw_code": "def register_search_advanced_order(trigger, &block)\n    Search.advanced_order(trigger, &block)\n  end",
    "comment": "Allows to define custom search order. Example usage: Search.advanced_order(:chars) do |posts| posts.reorder(\"(SELECT LENGTH(raw) FROM posts WHERE posts.topic_id = subquery.topic_id) DESC\") end",
    "label": "",
    "id": "255"
  },
  {
    "raw_code": "def register_search_advanced_filter(trigger, &block)\n    Search.advanced_filter(trigger, &block)\n  end",
    "comment": "Allows to define custom search filters. Example usage: Search.advanced_filter(/^min_chars:(\\d+)$/) do |posts, match| posts.where(\"(SELECT LENGTH(p2.raw) FROM posts p2 WHERE p2.id = posts.id) >= ?\", match.to_i) end",
    "label": "",
    "id": "256"
  },
  {
    "raw_code": "def register_topic_view_posts_filter(trigger, &block)\n    TopicView.add_custom_filter(trigger, &block)\n  end",
    "comment": "Allows to define TopicView posts filters. Example usage: TopicView.advanced_filter do |posts, opts| posts.where(wiki: true) end",
    "label": "",
    "id": "257"
  },
  {
    "raw_code": "def register_topic_list_preload_user_ids(&block)\n    TopicList.on_preload_user_ids(&block)\n  end",
    "comment": "Allows to add more user IDs to the list of preloaded users. This can be useful to efficiently change the list of posters or participants. Example usage: register_topic_list_preload_user_ids do |topics, user_ids, topic_list| user_ids << Discourse::SYSTEM_USER_ID end",
    "label": "",
    "id": "258"
  },
  {
    "raw_code": "def register_search_topic_eager_load(tables = nil, &block)\n    Search.custom_topic_eager_load(tables, &block)\n  end",
    "comment": "Allow to eager load additional tables in Search. Useful to avoid N+1 performance problems. Example usage: register_search_topic_eager_load do |opts| %i(example_table) end OR register_search_topic_eager_load(%i(example_table))",
    "label": "",
    "id": "259"
  },
  {
    "raw_code": "def register_topic_thumbnail_size(size)\n    if !(size.kind_of?(Array) && size.length == 2)\n      raise ArgumentError.new(\"Topic thumbnail dimension is not valid\")\n    end",
    "comment": "Request a new size for topic thumbnails Will respect plugin enabled setting is enabled Size should be an array with two elements [max_width, max_height]",
    "label": "",
    "id": "260"
  },
  {
    "raw_code": "def register_site_categories_callback(&block)\n    Site.add_categories_callbacks(&block)\n  end",
    "comment": "Register a callback to add custom payload to Site#categories Example usage: register_site_categories_callback do |categories| categories.each do |category| category[:some_field] = 'test' end end",
    "label": "",
    "id": "261"
  },
  {
    "raw_code": "def register_category_update_param_with_callback(param_name, &callback)\n    reloadable_patch do |plugin|\n      DiscoursePluginRegistry.category_update_param_with_callback[param_name] = {\n        plugin: plugin,\n        callback: callback,\n      }\n    end",
    "comment": "Add a category parameter that includes both controller param permission and transactional callback. This allows plugins to extend category updates with custom logic that runs within the same database transaction.  The callback block receives the category instance and the parameter value. If the callback raises an exception, the entire category update will be rolled back.  Example usage: register_category_update_param_with_callback(:doc_index_topic_id) do |category, value| DocCategories::CategoryIndexManager.new(category).assign!(value) end ",
    "label": "",
    "id": "262"
  },
  {
    "raw_code": "def register_preloaded_category_custom_fields(field)\n    Site.preloaded_category_custom_fields << field\n  end",
    "comment": "Registers a category custom field to be loaded when rendering a category list Example usage: register_preloaded_category_custom_fields(\"custom_field\")",
    "label": "",
    "id": "263"
  },
  {
    "raw_code": "def add_body_class(class_name)\n    reloadable_patch { |plugin| ::ApplicationHelper.extra_body_classes << class_name }\n  end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "264"
  },
  {
    "raw_code": "def add_to_class(class_name, attr, &block)\n    reloadable_patch do |plugin|\n      klass =\n        begin\n          class_name.to_s.classify.constantize\n        rescue StandardError\n          class_name.to_s.constantize\n        end",
    "comment": "Extend a class but check that the plugin is enabled for class methods use `add_class_method`",
    "label": "",
    "id": "265"
  },
  {
    "raw_code": "def add_class_method(klass_name, attr, &block)\n    reloadable_patch do |plugin|\n      klass =\n        begin\n          klass_name.to_s.classify.constantize\n        rescue StandardError\n          klass_name.to_s.constantize\n        end",
    "comment": "Adds a class method to a class, respecting if plugin is enabled",
    "label": "",
    "id": "266"
  },
  {
    "raw_code": "def topic_view_post_custom_fields_allowlister(&block)\n    reloadable_patch do |plugin|\n      ::TopicView.add_post_custom_fields_allowlister do |user, topic|\n        plugin.enabled? ? block.call(user, topic) : []\n      end",
    "comment": "Add a post_custom_fields_allowlister block to the TopicView, respecting if the plugin is enabled",
    "label": "",
    "id": "267"
  },
  {
    "raw_code": "def add_post_revision_notifier_recipients(&block)\n    reloadable_patch do |plugin|\n      ::PostActionNotifier.add_post_revision_notifier_recipients do |post_revision|\n        plugin.enabled? ? block.call(post_revision) : []\n      end",
    "comment": "Allows to add additional user_ids to the list of people notified when doing a post revision",
    "label": "",
    "id": "268"
  },
  {
    "raw_code": "def add_preloaded_group_custom_field(field)\n    reloadable_patch { |plugin| ::Group.preloaded_custom_field_names << field }\n  end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "269"
  },
  {
    "raw_code": "def add_preloaded_topic_list_custom_field(field)\n    reloadable_patch { |plugin| ::TopicList.preloaded_custom_fields << field }\n  end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "270"
  },
  {
    "raw_code": "def add_permitted_post_create_param(name, type = :string)\n    reloadable_patch do |plugin|\n      ::Post.plugin_permitted_create_params[name] = { plugin: plugin, type: type }\n    end",
    "comment": "Add a permitted_create_param to Post, respecting if the plugin is enabled",
    "label": "",
    "id": "271"
  },
  {
    "raw_code": "def add_permitted_post_update_param(attribute, &block)\n    reloadable_patch do |plugin|\n      ::Post.plugin_permitted_update_params[attribute] = { plugin: plugin, handler: block }\n    end",
    "comment": "Add a permitted_update_param to Post, respecting if the plugin is enabled",
    "label": "",
    "id": "272"
  },
  {
    "raw_code": "def register_group_param(param)\n    DiscoursePluginRegistry.register_group_param(param, self)\n  end",
    "comment": "Add a permitted_param to Group, respecting if the plugin is enabled Used in GroupsController#update and Admin::GroupsController#create",
    "label": "",
    "id": "273"
  },
  {
    "raw_code": "def register_groups_callback_for_users_search_controller_action(callback, &block)\n    if DiscoursePluginRegistry.groups_callback_for_users_search_controller_action.key?(callback)\n      raise \"groups_callback_for_users_search_controller_action callback already registered\"\n    end",
    "comment": "Add a custom callback for search to Group Callback is called in UsersController#search_users Block takes groups and optional current_user For example: plugin.register_groups_callback_for_users_search_controller_action(:admins_filter) do |groups, user| groups.where(name: \"admins\") end",
    "label": "",
    "id": "274"
  },
  {
    "raw_code": "def validate(klass, name, &block)\n    klass = klass.to_s.classify.constantize\n    klass.public_send(:define_method, name, &block)\n\n    plugin = self\n    klass.validate(name, if: -> { plugin.enabled? })\n  end",
    "comment": "Add validation method but check that the plugin is enabled",
    "label": "",
    "id": "275"
  },
  {
    "raw_code": "def generate_automatic_assets!\n    paths = []\n    assets = []\n\n    automatic_assets.each do |path, contents|\n      write_asset(path, contents)\n      paths << path\n      assets << [path, nil, directory_name]\n    end",
    "comment": "will make sure all the assets this plugin needs are registered",
    "label": "",
    "id": "276"
  },
  {
    "raw_code": "def on(event_name, &block)\n    DiscourseEvent.on(event_name) { |*args, **kwargs| block.call(*args, **kwargs) if enabled? }\n  end",
    "comment": "A proxy to `DiscourseEvent.on` which does nothing if the plugin is disabled",
    "label": "",
    "id": "277"
  },
  {
    "raw_code": "def on_enabled_change(&block)\n    event_proc =\n      Proc.new do |setting_name, old_value, new_value|\n        block.call(old_value, new_value) if setting_name == @enabled_site_setting\n      end",
    "comment": "A proxy to `DiscourseEvent.on(:site_setting_changed)` triggered when the plugin enabled setting specified by `enabled_site_setting` value is changed, including when the plugin is turned off.  It is useful when the plugin needs to perform tasks like properly clearing caches when enabled/disabled note it will not be triggered when a plugin is installed/uninstalled by adding/removing its code",
    "label": "",
    "id": "278"
  },
  {
    "raw_code": "def register_category_custom_field_type(name, type, max_length: nil)\n    reloadable_patch do |plugin|\n      Category.register_custom_field_type(name, type, max_length: max_length)\n    end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "279"
  },
  {
    "raw_code": "def register_topic_custom_field_type(name, type, max_length: nil)\n    reloadable_patch do |plugin|\n      ::Topic.register_custom_field_type(name, type, max_length: max_length)\n    end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "280"
  },
  {
    "raw_code": "def register_post_custom_field_type(name, type, max_length: nil)\n    reloadable_patch do |plugin|\n      ::Post.register_custom_field_type(name, type, max_length: max_length)\n    end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "281"
  },
  {
    "raw_code": "def register_group_custom_field_type(name, type, max_length: nil)\n    reloadable_patch do |plugin|\n      ::Group.register_custom_field_type(name, type, max_length: max_length)\n    end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "282"
  },
  {
    "raw_code": "def register_user_custom_field_type(name, type, max_length: nil)\n    reloadable_patch do |plugin|\n      ::User.register_custom_field_type(name, type, max_length: max_length)\n    end",
    "comment": "Applies to all sites in a multisite environment. Ignores plugin.enabled?",
    "label": "",
    "id": "283"
  },
  {
    "raw_code": "def register_asset_filter(&blk)\n    asset_filters << blk\n  end",
    "comment": "Register a block to run when adding css and js assets Two arguments will be passed: (type, request) Type is :css or :js. `request` is an instance of Rack::Request When using this, make sure to consider the effect on AnonymousCache",
    "label": "",
    "id": "284"
  },
  {
    "raw_code": "def register_locale(locale, opts = {})\n    locales << [locale, opts]\n  end",
    "comment": "@option opts [String] :name @option opts [String] :nativeName @option opts [String] :fallbackLocale @option opts [Hash] :plural",
    "label": "",
    "id": "285"
  },
  {
    "raw_code": "def activate!\n    self.instance_eval File.read(path), path\n    if auto_assets = generate_automatic_assets!\n      assets.concat(auto_assets)\n    end",
    "comment": "note, we need to be able to parse separately to activation. this allows us to present information about a plugin in the UI prior to activations",
    "label": "",
    "id": "286"
  },
  {
    "raw_code": "def gem(name, version, opts = {})\n    PluginGem.load(path, name, version, opts)\n  end",
    "comment": "shotgun approach to gem loading, in future we need to hack bundler to at least determine dependencies do not clash before loading  Additionally we want to support multiple ruby versions correctly and so on  This is a very rough initial implementation",
    "label": "",
    "id": "287"
  },
  {
    "raw_code": "def register_site_setting_area(area)\n    DiscoursePluginRegistry.site_setting_areas << area\n  end",
    "comment": "Site setting areas are a way to group site settings below the setting category level. This is useful for creating focused config areas that update a small selection of settings, and otherwise grouping related settings in the UI.",
    "label": "",
    "id": "288"
  },
  {
    "raw_code": "def add_custom_reviewable_filter(filter)\n    reloadable_patch { Reviewable.add_custom_filter(filter) }\n  end",
    "comment": "Receives an array with two elements: 1. A symbol that represents the name of the value to filter. 2. A Proc that takes the existing ActiveRecord::Relation and the value received from the front-end.",
    "label": "",
    "id": "289"
  },
  {
    "raw_code": "def add_api_key_scope(resource, action)\n    DiscoursePluginRegistry.register_api_key_scope_mapping({ resource => action }, self)\n  end",
    "comment": "Register a new API key scope.  Example: add_api_key_scope(:groups, { delete: { actions: %w[groups#add_members], params: %i[id] } })  This scope lets you add members to a group. Additionally, you can specify which group ids are allowed. The delete action is added to the groups resource.",
    "label": "",
    "id": "290"
  },
  {
    "raw_code": "def add_user_api_key_scope(scope_name, matcher_parameters)\n    raise ArgumentError.new(\"scope_name must be a symbol\") if !scope_name.is_a?(Symbol)\n    matcher_parameters = [matcher_parameters] if !matcher_parameters.is_a?(Array)\n\n    prefixed_scope_name = :\"#{(name || directory_name).parameterize}:#{scope_name}\"\n    DiscoursePluginRegistry.register_user_api_key_scope_mapping(\n      { prefixed_scope_name => matcher_parameters&.map { |m| RouteMatcher.new(**m) } },\n      self,\n    )\n  end",
    "comment": "Register a new UserApiKey scope, and its allowed routes. Scope will be prefixed with the (parameterized) plugin name followed by a colon.  For example, if discourse-awesome-plugin registered this:  add_user_api_key_scope(:read_my_route, methods: :get, actions: \"mycontroller#myaction\", formats: :ics, params: :testparam )  The scope registered would be `discourse-awesome-plugin:read_my_route`  Multiple matchers can be attached by supplying an array of parameter hashes  See UserApiKeyScope::SCOPES for more examples And lib/route_matcher.rb for the route matching logic",
    "label": "",
    "id": "291"
  },
  {
    "raw_code": "def add_api_parameter_route(methods: nil, actions: nil, formats: nil)\n    DiscoursePluginRegistry.register_api_parameter_route(\n      RouteMatcher.new(methods: methods, actions: actions, formats: formats),\n      self,\n    )\n  end",
    "comment": "Register a route which can be authenticated using an api key or user api key in a query parameter rather than a header. For example:  add_api_parameter_route( methods: :get, actions: \"users#bookmarks\", formats: :ics )  See Auth::DefaultCurrentUserProvider::PARAMETER_API_PATTERNS for more examples and Auth::DefaultCurrentUserProvider#api_parameter_allowed? for implementation",
    "label": "",
    "id": "292"
  },
  {
    "raw_code": "def register_demon_process(demon_class)\n    raise \"Not a demon class\" if !demon_class.ancestors.include?(Demon::Base)\n    DiscoursePluginRegistry.demon_processes << demon_class\n  end",
    "comment": "Register a new demon process to be forked by the Unicorn master. The demon_class should inherit from Demon::Base. With great power comes great responsibility - this method should be used with extreme caution. See `config/unicorn.conf.rb`.",
    "label": "",
    "id": "293"
  },
  {
    "raw_code": "def register_presence_channel_prefix(prefix, &block)\n    DiscoursePluginRegistry.register_presence_channel_prefix([prefix, block], self)\n  end",
    "comment": "Register a new PresenceChannel prefix. See {PresenceChannel.register_prefix} for usage instructions",
    "label": "",
    "id": "294"
  },
  {
    "raw_code": "def register_email_notification_filter(&block)\n    DiscoursePluginRegistry.register_email_notification_filter(block, self)\n  end",
    "comment": "Registers a new email notification filter. Notification is passed into block, and if all filters return `true`, the email notification will be sent.",
    "label": "",
    "id": "295"
  },
  {
    "raw_code": "def register_push_notification_filter(&block)\n    DiscoursePluginRegistry.register_push_notification_filter(block, self)\n  end",
    "comment": "Registers a new push notification filter. User and notification payload are passed into block, and if all filters return `true`, the push notification will be sent.",
    "label": "",
    "id": "296"
  },
  {
    "raw_code": "def add_reviewable_score_link(reason, setting_name)\n    DiscoursePluginRegistry.register_reviewable_score_link(\n      { reason: reason.to_sym, setting: setting_name },\n      self,\n    )\n  end",
    "comment": "Register a ReviewableScore setting_name associated with a reason. We'll use this to build a site setting link and add it to the reason's translation.  If your plugin has a reason translation looking like this:  my_plugin_reason: \"This is the reason this post was flagged. See %{link}.\"  And you associate the reason with a setting:  add_reviewable_score_link(:my_plugin_reason, 'a_plugin_setting')  We'll generate the following link and attach it to the translation:  <a href=\"/admin/site_settings/category/all_results?filter=a_plugin_setting\"> a plugin setting </a>",
    "label": "",
    "id": "297"
  },
  {
    "raw_code": "def register_notification_consolidation_plan(plan)\n    if !plan.class.ancestors.include?(Notifications::ConsolidationPlan)\n      raise ArgumentError.new(\"Not a consolidation plan\")\n    end",
    "comment": "If your plugin creates notifications, and you'd like to consolidate/collapse similar ones, you're in the right place. This method receives a plan object, which must be an instance of `Notifications::ConsolidateNotifications`.  Instead of using `Notification#create!`, you should use `Notification#consolidate_or_save!`, which will automatically pick your plan and apply it, updating an already consolidated notification, consolidating multiple ones, or creating a regular one.  The rule object is quite complex. We strongly recommend you write tests to ensure your plugin consolidates notifications correctly.  - Threshold and time window consolidation plan: https://github.com/discourse/discourse/blob/main/app/services/notifications/consolidate_notifications.rb - Create a new notification and delete previous versions plan: https://github.com/discourse/discourse/blob/main/app/services/notifications/delete_previous_notifications.rb - Base plans: https://github.com/discourse/discourse/blob/main/app/services/notifications/consolidation_planner.rb",
    "label": "",
    "id": "298"
  },
  {
    "raw_code": "def add_topic_static_page(page, options = {}, &blk)\n    StaticController::CUSTOM_PAGES[page] = blk ? { topic_id: blk } : options\n  end",
    "comment": "Allows customizing existing topic-backed static pages, like: faq, tos, privacy (see: StaticController) The block passed to this method has to return a SiteSetting name that contains a topic id.  add_topic_static_page(\"faq\") do |controller| current_user&.locale == \"pl\" ? \"polish_faq_topic_id\" : \"faq_topic_id\" end  You can also add new pages in a plugin, but remember to add a route, for example:  get \"contact\" => \"static#show\", id: \"contact\"",
    "label": "",
    "id": "299"
  },
  {
    "raw_code": "def register_email_unsubscriber(type, unsubscriber)\n    core_types = [UnsubscribeKey::ALL_TYPE, UnsubscribeKey::DIGEST_TYPE, UnsubscribeKey::TOPIC_TYPE]\n    raise ArgumentError.new(\"Type already exists\") if core_types.include?(type)\n    if !unsubscriber.ancestors.include?(EmailControllerHelper::BaseEmailUnsubscriber)\n      raise ArgumentError.new(\"Not an email unsubscriber\")\n    end",
    "comment": "Let plugin define custom unsubscribe keys, set custom instance variables on the `EmailController#unsubscribe` action, and describe what unsubscribing for that key does.  The method receives a class that inherits from `Email::BaseEmailUnsubscriber`. Take a look at it to know how to implement your child class.  In conjunction with this, you'll have to:  - Register a new connector under app/views/connectors/unsubscribe_options. We'll include the HTML inside the unsubscribe form, so you can add your fields using the instance variables you set in the controller previously. When the form is submitted, it sends the updated preferences to `EmailController#perform_unsubscribe`.  - Your code is responsible for creating the custom key by calling `UnsubscribeKey#create_key_for`.",
    "label": "",
    "id": "300"
  },
  {
    "raw_code": "def register_stat(name, expose_via_api: false, &block)\n    # We do not want to register and display the same group multiple times.\n    return if DiscoursePluginRegistry.stats.any? { |stat| stat.name == name }\n\n    stat = Stat.new(name, expose_via_api: expose_via_api, &block)\n    DiscoursePluginRegistry.register_stat(stat, self)\n  end",
    "comment": "Allows the plugin to export additional site stats via the About class which will be shown on the /about route. The stats returned by the block should be in the following format (these four keys are _required_):  { last_day: 1, 7_days: 10, 30_days: 100, count: 1000 }  Only keys above will be shown on the /about page in the UI, but all stats will be shown on the /about.json route. For example take this usage:  register_stat(\"chat_messages\") do { last_day: 1, \"7_days\" => 10, \"30_days\" => 100, count: 1000, previous_30_days: 150 } end  In the UI we will show a table like this:  | 24h | 7 days | 30 days | all time| Chat Messages | 1   | 10     | 100     | 1000    |  But the JSON will be like this:  { \"chat_messages_last_day\": 1, \"chat_messages_7_days\": 10, \"chat_messages_30_days\": 100, \"chat_messages_count\": 1000, }",
    "label": "",
    "id": "301"
  },
  {
    "raw_code": "def register_hashtag_data_source(klass)\n    DiscoursePluginRegistry.register_hashtag_autocomplete_data_source(klass, self)\n  end",
    "comment": " Used to register data sources for HashtagAutocompleteService to look up results based on a #hashtag string.  @param {Class} klass - Must be a class that implements methods with the following signatures:  Roughly corresponding to a model, this is used as a unique key for the datasource and is also used when allowing different contexts to search for and lookup these types. The `category` and `tag` types are registered by default. def self.type end  The FontAwesome icon to use for the data source in the search results and cooked markdown. def self.icon end  @param {Guardian} guardian - Current user's guardian, used for permission-based filtering @param {Array} slugs - An array of strings that represent slugs to search this type for, e.g. category slugs. @returns {Hash} A hash with the slug as the key and the URL of the record as the value. def self.lookup(guardian, slugs) end  @param {Guardian} guardian - Current user's guardian, used for permission-based filtering @param {String} term - The search term used to filter results @param {Integer} limit - The number of search results that should be returned by the query @returns {Array} An Array of HashtagAutocompleteService::HashtagItem def self.search(guardian, term, limit) end  @param {Array} search_results - An array of HashtagAutocompleteService::HashtagItem to sort @param {String} term - The search term which was used, which may help with sorting. @returns {Array} An Array of HashtagAutocompleteService::HashtagItem def self.search_sort(search_results, term) end  @param {Guardian} guardian - Current user's guardian, used for permission-based filtering @param {Integer} limit - The number of search results that should be returned by the query @returns {Array} An Array of HashtagAutocompleteService::HashtagItem def self.search_without_term(guardian, limit) end",
    "label": "",
    "id": "302"
  },
  {
    "raw_code": "def register_hashtag_type_priority_for_context(type, context, priority)\n    DiscoursePluginRegistry.register_hashtag_autocomplete_contextual_type_priority(\n      { type: type, context: context, priority: priority },\n      self,\n    )\n  end",
    "comment": " Used to set up the priority ordering of hashtag autocomplete results by type using HashtagAutocompleteService.  @param {String} type - Roughly corresponding to a model, can only be registered once per context. The `category` and `tag` types are registered for the `topic-composer` context by default in that priority order. @param {String} context - The context in which the hashtag lookup or search is happening in. For example, the Discourse composer context is `topic-composer`. Different contexts may want to have different priority orderings for certain types of hashtag result. @param {Integer} priority - A number value for ordering type results when hashtag searches or lookups occur. Priority is ordered by DESCENDING order.",
    "label": "",
    "id": "303"
  },
  {
    "raw_code": "def register_user_destroyer_on_content_deletion_callback(callback)\n    DiscoursePluginRegistry.register_user_destroyer_on_content_deletion_callback(callback, self)\n  end",
    "comment": " Register a block that will be called when the UserDestroyer runs with the :delete_posts opt set to true. It's important to note that the block will execute before any other :delete_posts actions, it allows us to manipulate flags before agreeing with them. For example, discourse-akismet makes use of this  @param {Block} callback to be called with the user, guardian, and the destroyer opts as arguments",
    "label": "",
    "id": "304"
  },
  {
    "raw_code": "def register_bookmarkable(klass)\n    return if Bookmark.registered_bookmarkable_from_type(klass.model.name).present?\n    DiscoursePluginRegistry.register_bookmarkable(RegisteredBookmarkable.new(klass), self)\n  end",
    "comment": " Register a class that implements [BaseBookmarkable], which represents another [ActiveRecord::Model] that may be bookmarked via the [Bookmark] model's polymorphic association. The class handles create and destroy hooks, querying, and reminders among other things.",
    "label": "",
    "id": "305"
  },
  {
    "raw_code": "def register_summarization_strategy(strategy)\n    Discourse.deprecate(\n      \"register_summarization_strategy is deprecated. Summarization code is now moved to Discourse AI\",\n    )\n    if !strategy.class.ancestors.include?(Summarization::Base)\n      raise ArgumentError.new(\"Not a valid summarization strategy\")\n    end",
    "comment": " Register an object that inherits from [Summarization::Base], which provides a way to summarize content. Staff can select which strategy to use through the `summarization_strategy` setting.",
    "label": "",
    "id": "306"
  },
  {
    "raw_code": "def register_post_action_notify_user_handler(handler)\n    DiscoursePluginRegistry.register_post_action_notify_user_handler(handler, self)\n  end",
    "comment": " Register a block that will be called when PostActionCreator is going to notify a user of a post action. If any of these handlers returns false the default PostCreator call will be skipped.",
    "label": "",
    "id": "307"
  },
  {
    "raw_code": "def register_post_stripper(&block)\n    DiscoursePluginRegistry.register_post_stripper({ block: block }, self)\n  end",
    "comment": "We strip posts before detecting mentions, oneboxes, attachments etc. We strip those elements that shouldn't be detected. For example, a mention inside a quote should be ignored, so we strip it off. Using this API plugins can register their own post strippers.",
    "label": "",
    "id": "308"
  },
  {
    "raw_code": "def add_request_rate_limiter(\n    identifier:,\n    key:,\n    activate_when:,\n    global: false,\n    after: nil,\n    before: nil\n  )\n    raise ArgumentError, \"only one of `after` or `before` can be provided\" if after && before\n\n    stack = Middleware::RequestTracker.rate_limiters_stack\n\n    if (reference_klass = after || before) && !stack.include?(reference_klass)\n      raise ArgumentError, \"#{reference_klass} is not a valid value. Must be one of #{stack}\"\n    end",
    "comment": "This is an experimental API and may be changed or removed in the future without deprecation.  Adds a custom rate limiter to the request rate limiters stack. Only one rate limiter is used per request and the first rate limiter in the stack that is active is used. By default the rate limiters stack contains the following rate limiters:  `RequestTracker::RateLimiters::User` - Rate limits authenticated requests based on the user's id `RequestTracker::RateLimiters::IP` - Rate limits requests based on the IP address  @param identifier [Symbol] A unique identifier for the rate limiter.  @param key [Proc] A lambda/proc that defines the `rate_limit_key`. - Receives `request` (An instance of `Rack::Request`) as argument. - Should return a string representing the rate limit key.  @param activate_when [Proc] A lambda/proc that defines when the rate limiter should be used for a request. - Receives `request` (An instance of `Rack::Request`) as argument. - Should return `true` if the rate limiter is active, otherwise `false`.  @param global [Boolean] Whether the rate limiter applies globally across all sites. Defaults to `false`. - Ignored if `klass` is provided.  @param after [Class, nil] The rate limiter class after which the new rate limiter should be added.  @param before [Class, nil] The rate limiter class before which the new rate limiter should be added.  @example Adding a rate limiter that rate limits all requests based on the country of the IP address  add_request_rate_limiter( identifier: :country, key: ->(request) { \"country/#{DiscourseIpInfo.get(request.ip)[:country]}\" }, activate_when: ->(request) { DiscourseIpInfo.get(request.ip)[:country].present? }, )",
    "label": "",
    "id": "309"
  },
  {
    "raw_code": "def register_topic_preloader_associations(fields, &condition)\n    DiscoursePluginRegistry.register_topic_preloader_association({ fields:, condition: }, self)\n  end",
    "comment": "This method allows plugins to preload topic associations when loading topics that make use of topic_list.  @param fields [Symbol, Array<Symbol>, Hash] The topic associations to preload.  @example register_topic_preloader_associations(:first_post) register_topic_preloader_associations([:first_post, :topic_embeds]) register_topic_preloader_associations({ first_post: :uploads }) register_topic_preloader_associations({ first_post: :uploads }) do SiteSetting.some_setting_enabled? end  @return [void]",
    "label": "",
    "id": "310"
  },
  {
    "raw_code": "def register_category_list_topics_preloader_associations(associations)\n    DiscoursePluginRegistry.register_category_list_topics_preloader_association(associations, self)\n  end",
    "comment": " Allows plugins to preload topic associations when loading categories with topics.  @param fields [Array<Symbol>] The topic associations to preload.  @example Preload custom topic associations  register_category_list_topics_preloader_associations(%i[some_topic_association some_other_topic_association]) ",
    "label": "",
    "id": "311"
  },
  {
    "raw_code": "def commit_session?(request, session, options)\n    super(request, session, options) && session_has_changed?(request, session)\n  end",
    "comment": "By default, Rack/Rails will include the session cookie in every response, even if its content hasn't changed. This makes race conditions very likely when multiple requests are made in parallel",
    "label": "",
    "id": "312"
  },
  {
    "raw_code": "def display_name\n    name\n  end",
    "comment": "Used in error messages and for display purposes",
    "label": "",
    "id": "313"
  },
  {
    "raw_code": "def provider_url\n    nil\n  end",
    "comment": "Used in /my/preferences/account to link to the provider's website",
    "label": "",
    "id": "314"
  },
  {
    "raw_code": "def after_authenticate(auth_options, existing_account: nil)\n    raise NotImplementedError\n  end",
    "comment": "run once the user has completed authentication on the third party system. Should return an instance of Auth::Result. If the user has requested to connect an existing account then `existing_account` will be set",
    "label": "",
    "id": "315"
  },
  {
    "raw_code": "def after_create_account(user, auth)\n    # not required\n  end",
    "comment": "can be used to hook in after the authentication process to ensure records exist for the provider in the db this MUST be implemented for authenticators that do not trust email",
    "label": "",
    "id": "316"
  },
  {
    "raw_code": "def register_middleware(omniauth)\n    raise NotImplementedError\n  end",
    "comment": "hook used for registering omniauth middleware, without this we can not authenticate",
    "label": "",
    "id": "317"
  },
  {
    "raw_code": "def description_for_user(user)\n    \"\"\n  end",
    "comment": "return a string describing the connected account for a given user (typically email address). Used to list connected accounts under the user's preferences. Empty string indicates not connected",
    "label": "",
    "id": "318"
  },
  {
    "raw_code": "def description_for_auth_hash(user)\n    \"\"\n  end",
    "comment": "return a string describing the connected account for a given OmniAuth::AuthHash. Used in the confirmation screen when connecting accounts",
    "label": "",
    "id": "319"
  },
  {
    "raw_code": "def can_revoke?\n    false\n  end",
    "comment": "can authorisation for this provider be revoked?",
    "label": "",
    "id": "320"
  },
  {
    "raw_code": "def can_connect_existing_user?\n    false\n  end",
    "comment": "can existing discourse users connect this provider to their accounts",
    "label": "",
    "id": "321"
  },
  {
    "raw_code": "def revoke(user, skip_remote: false)\n    raise NotImplementedError\n  end",
    "comment": "optionally implement the ability for users to revoke their link with this authenticator. should ideally contact the third party to fully revoke permissions. If this fails, return :remote_failed. skip remote if skip_remote == true",
    "label": "",
    "id": "322"
  },
  {
    "raw_code": "def provides_groups?\n    false\n  end",
    "comment": "provider has implemented user group membership (or equivalent) request",
    "label": "",
    "id": "323"
  },
  {
    "raw_code": "def primary_email_verified?(_auth_token)\n    true\n  end",
    "comment": "LinkedIn doesn't let users login to websites unless they verify their e-mail address, so whatever e-mail we get from LinkedIn must be verified.",
    "label": "",
    "id": "324"
  },
  {
    "raw_code": "def primary_email_verified?(auth_token)\n    true\n  end",
    "comment": "the `info` block above only picks the email from Discord API if it's verified",
    "label": "",
    "id": "325"
  },
  {
    "raw_code": "def initialize(env)\n    @env = env\n    @request = Rack::Request.new(env)\n    @user_token = env[USER_TOKEN_KEY]\n  end",
    "comment": "do all current user initialization here",
    "label": "",
    "id": "326"
  },
  {
    "raw_code": "def current_user\n    return @env[CURRENT_USER_KEY] if @env.key?(CURRENT_USER_KEY)\n\n    # bypass if we have the shared session header\n    if shared_key = @env[\"HTTP_X_SHARED_SESSION_KEY\"]\n      uid = Discourse.redis.get(\"shared_session_key_#{shared_key}\")\n      user = nil\n      user = User.find_by(id: uid.to_i) if uid\n      @env[CURRENT_USER_KEY] = user\n      return user\n    end",
    "comment": "our current user, return nil if none is found",
    "label": "",
    "id": "327"
  },
  {
    "raw_code": "def make_developer_admin(user)\n    if user.active? && !user.admin && Rails.configuration.respond_to?(:developer_emails) &&\n         Rails.configuration.developer_emails.include?(user.email)\n      user.admin = true\n      user.save\n      Group.refresh_automatic_groups!(:staff, :admins)\n    end",
    "comment": "This is also used to set the first admin of the site via the finish installation & register -> user account activation for signup flow, since all admin emails are stored in DISCOURSE_DEVELOPER_EMAILS for self-hosters.",
    "label": "",
    "id": "328"
  },
  {
    "raw_code": "def is_api?\n    current_user\n    !!(@env[API_KEY_ENV])\n  end",
    "comment": "api has special rights return true if api was detected",
    "label": "",
    "id": "329"
  },
  {
    "raw_code": "def api_parameter_allowed?\n    parameter_api_patterns.any? { |p| p.match?(env: @env) }\n  end",
    "comment": "By default we only allow headers for sending API credentials However, in some scenarios it is essential to send them via url parameters so we need to add some exceptions",
    "label": "",
    "id": "330"
  },
  {
    "raw_code": "def match_by_email\n    true\n  end",
    "comment": "These three methods are designed to be overridden by child classes",
    "label": "",
    "id": "331"
  },
  {
    "raw_code": "def match_by_username\n    false\n  end",
    "comment": "Depending on the authenticator, this could be insecure, so it's disabled by default",
    "label": "",
    "id": "332"
  },
  {
    "raw_code": "def primary_email_verified?(auth_token)\n    true\n  end",
    "comment": "twitter doesn't return unverfied email addresses in the API https://developer.twitter.com/en/docs/twitter-api/v1/accounts-and-users/manage-account-settings/api-reference/get-account-verify_credentials",
    "label": "",
    "id": "333"
  },
  {
    "raw_code": "def primary_email_verified?(auth_token)\n    true\n  end",
    "comment": "the omniauth-github gem only picks up the primary email if it's verified: https://github.com/omniauth/omniauth-github/blob/0ac46b59ccdabd4cbe5be4a665df269355081915/lib/omniauth/strategies/github.rb#L58-L61",
    "label": "",
    "id": "334"
  },
  {
    "raw_code": "def initialize(env)\n    raise NotImplementedError\n  end",
    "comment": "do all current user initialization here",
    "label": "",
    "id": "335"
  },
  {
    "raw_code": "def current_user\n    raise NotImplementedError\n  end",
    "comment": "our current user, return nil if none is found",
    "label": "",
    "id": "336"
  },
  {
    "raw_code": "def log_on_user(user, session, cookie_jar, opts = {})\n    raise NotImplementedError\n  end",
    "comment": "log on a user and set cookies and session etc.",
    "label": "",
    "id": "337"
  },
  {
    "raw_code": "def refresh_session(user, session, cookie_jar)\n  end",
    "comment": "optional interface to be called to refresh cookies etc if needed",
    "label": "",
    "id": "338"
  },
  {
    "raw_code": "def start_impersonating_user(user)\n  end",
    "comment": "Optional interface for implementing impersonation.",
    "label": "",
    "id": "339"
  },
  {
    "raw_code": "def stop_impersonating_user\n  end",
    "comment": "Optional interface for implementing impersonation.",
    "label": "",
    "id": "340"
  },
  {
    "raw_code": "def is_api?\n    raise NotImplementedError\n  end",
    "comment": "api has special rights return true if api was detected",
    "label": "",
    "id": "341"
  },
  {
    "raw_code": "def has_auth_cookie?\n    raise NotImplementedError\n  end",
    "comment": "we may need to know very early on in the middleware if an auth token exists, to optimise caching",
    "label": "",
    "id": "342"
  },
  {
    "raw_code": "def primary_email_verified?(auth_token)\n    true\n  end",
    "comment": "facebook doesn't return unverified email addresses so it's safe to assume whatever email we get from them is verified https://developers.facebook.com/docs/graph-api/reference/user/",
    "label": "",
    "id": "343"
  },
  {
    "raw_code": "def store_file(file, path, opts = {})\n      path = path.dup\n\n      filename = opts[:filename].presence || File.basename(path)\n      # cache file locally when needed\n      cache_file(file, File.basename(path)) if opts[:cache_locally]\n\n      options = {\n        cache_control: \"max-age=31556952, public, immutable\",\n        content_type:\n          opts[:content_type].presence || MiniMime.lookup_by_filename(filename)&.content_type,\n      }.merge(default_s3_options(secure: opts[:private]))\n\n      # Only add a \"content disposition: attachment\" header for svgs\n      # see https://github.com/discourse/discourse/commit/31e31ef44973dc4daaee2f010d71588ea5873b53.\n      # Adding this header for all files would break the ability to view attachments in the browser\n      options[:content_disposition] = ActionDispatch::Http::ContentDisposition.format(\n        disposition: FileHelper.is_svg?(filename) ? \"attachment\" : \"inline\",\n        filename: filename,\n      )\n\n      path.prepend(File.join(upload_path, \"/\")) if Rails.configuration.multisite\n\n      # if this fails, it will throw an exception\n      if opts[:move_existing] && opts[:existing_external_upload_key]\n        original_path = opts[:existing_external_upload_key]\n        options[:apply_metadata_to_destination] = true\n        path, etag = s3_helper.copy(original_path, path, options: options)\n        delete_file(original_path)\n      else\n        path, etag = s3_helper.upload(file, path, options)\n      end",
    "comment": "File is an actual Tempfile on disk  An existing_external_upload_key is given for cases where move_existing is specified. This is an object already uploaded directly to S3 that we are now moving to its final resting place with the correct sha and key.  options - filename - content_type - cache_locally - move_existing - private - existing_external_upload_key",
    "label": "",
    "id": "344"
  },
  {
    "raw_code": "def download_safe(*, **)\n      download(*, **, print_deprecation: false)\n    rescue StandardError\n      nil\n    end",
    "comment": "TODO: Remove when #download becomes the canonical safe version.",
    "label": "",
    "id": "345"
  },
  {
    "raw_code": "def self.log_potential_flaky_tests(failed_examples)\n        return if failed_examples.empty?\n\n        File.open(PATH, \"w\") do |file|\n          file.puts(\n            failed_examples.map { |failed_example| FailedExample.new(failed_example).to_h }.to_json,\n          )\n        end",
    "comment": "This method should only be called by a formatter registered with `TurboTests::Runner` and logs the failed examples to `PATH`. See `FailedExample#to_h` for the details of each example that is logged.  @param [Array<TurboTests::FakeExample>] failed_examples",
    "label": "",
    "id": "346"
  },
  {
    "raw_code": "def self.remove_example(failed_examples)\n        flaky_tests =\n          JSON\n            .parse(File.read(PATH))\n            .reject do |failed_example|\n              failed_examples.any? do |example|\n                failed_example[\"location_rerun_argument\"] == example.location_rerun_argument\n              end",
    "comment": "This method should only be called by a formatter registered with `RSpec::Core::Formatters.register` and removes the given examples from the log file at `PATH` by matching the `location_rerun_argument` of each example.  @param [Array<RSpec::Core::Example>] failed_examples",
    "label": "",
    "id": "347"
  },
  {
    "raw_code": "def initialize(failed_example)\n        @failed_example = failed_example\n        @failed_example_notification = failed_example.notification\n      end",
    "comment": "@param [TurboTests::FakeExample] failed_example",
    "label": "",
    "id": "348"
  },
  {
    "raw_code": "def message_lines\n        lines = @failed_example_notification.message_lines.join(\"\\n\")\n\n        # Strip ANSI color codes from the message lines as we are likely running in a terminal where `RSpec.color` is enabled\n        lines.gsub!(/\\e\\[[0-9;]*m/, \"\")\n        lines.strip!\n\n        lines\n      end",
    "comment": "See https://www.rubydoc.info/gems/rspec-core/RSpec%2FCore%2FNotifications%2FFailedExampleNotification:message_lines",
    "label": "",
    "id": "349"
  },
  {
    "raw_code": "def description\n        @failed_example_notification.description\n      end",
    "comment": "See https://www.rubydoc.info/gems/rspec-core/RSpec%2FCore%2FNotifications%2FFailedExampleNotification:description",
    "label": "",
    "id": "350"
  },
  {
    "raw_code": "def backtrace\n        @failed_example_notification.formatted_backtrace\n      end",
    "comment": "See https://www.rubydoc.info/gems/rspec-core/RSpec%2FCore%2FNotifications%2FFailedExampleNotification:formatted_backtrace",
    "label": "",
    "id": "351"
  },
  {
    "raw_code": "def failure_screenshot_path\n        @failed_example_notification.message_lines.each do |message_line|\n          if message_line.strip.start_with?(SCREENSHOT_PREFIX)\n            return message_line.split(SCREENSHOT_PREFIX).last.chomp\n          end",
    "comment": "Unfortunately this has to be parsed from the output because `ActionDispatch` is just printing the path instead of properly adding the screenshot to the test metadata.",
    "label": "",
    "id": "352"
  },
  {
    "raw_code": "def t(key, opts)\n      key = \"js.\" + key\n      return I18n.t(key) if opts.blank?\n      str = I18n.t(key, Hash[opts.entries].symbolize_keys).dup\n      opts.each { |k, v| str.gsub!(\"{{#{k}}}\", v.to_s) }\n      str\n    end",
    "comment": "functions here are available to v8",
    "label": "",
    "id": "353"
  },
  {
    "raw_code": "def format_username(username)\n      username\n    end",
    "comment": "Overwrite this in a plugin to change how markdown can format usernames on the server side",
    "label": "",
    "id": "354"
  },
  {
    "raw_code": "def self.common_actions\n      {\n        approve: Action.new(:approve, \"thumbs-up\", \"reviewables.actions.approve.title\"),\n        reject: Action.new(:reject, \"thumbs-down\", \"reviewables.actions.reject.title\"),\n        delete: Action.new(:delete, \"trash-can\", \"reviewables.actions.delete.title\"),\n      }\n    end",
    "comment": "Add common actions here to make them easier for reviewables to re-use. If it's a one off, add it manually.",
    "label": "",
    "id": "355"
  },
  {
    "raw_code": "def table_exists?\n    @table_exists ||= {}\n    @table_exists[current_site] ||= ActiveRecord::Base.connection.table_exists?(@model.table_name)\n  end",
    "comment": "table is not in the db yet, initial migration, etc",
    "label": "",
    "id": "356"
  },
  {
    "raw_code": "def set_regardless_of_locale(name, value)\n    name = name.to_sym\n    if name == :default_locale || @site_setting.has_setting?(name)\n      @defaults.each { |_, hash| hash.delete(name) }\n      @defaults[DEFAULT_LOCALE.to_sym][name] = value\n      value, type = @site_setting.type_supervisor.to_db_value(name, value)\n      @defaults[SiteSetting.default_locale.to_sym] ||= {}\n      @defaults[SiteSetting.default_locale.to_sym][\n        name\n      ] = @site_setting.type_supervisor.to_rb_value(name, value, type)\n    else\n      raise ArgumentError.new(\"No setting named '#{name}' exists\")\n    end",
    "comment": "Used to override site settings in dev/test env",
    "label": "",
    "id": "357"
  },
  {
    "raw_code": "def remap_uploads\n      log \"Remapping uploads...\"\n\n      was_multisite = BackupMetadata.value_for(\"multisite\") == \"t\"\n      upload_path = \"/#{Discourse.store.upload_path}/\"\n      uploads_folder = was_multisite ? \"/\" : upload_path\n\n      if (old_base_url = BackupMetadata.value_for(\"base_url\")) && old_base_url != Discourse.base_url\n        remap(old_base_url, Discourse.base_url)\n      end",
    "comment": "Remaps upload URLs depending on old and new configuration. URLs of uploads differ a little bit between local uploads and uploads stored on S3. Multisites are another reason why URLs can be different.  Examples: * regular site, local storage /uploads/default/original/1X/63b76551662ccea1a594e161c37dd35188d77657.jpeg  * regular site, S3 //bucket-name.s3.dualstack.us-west-2.amazonaws.com/original/1X/63b76551662ccea1a594e161c37dd35188d77657.jpeg  * multisite, local storage /uploads/<site-name>/original/1X/63b76551662ccea1a594e161c37dd35188d77657.jpeg  * multisite, S3 //bucket-name.s3.dualstack.us-west-2.amazonaws.com/uploads/<site-name>/original/1X/63b76551662ccea1a594e161c37dd35188d77657.jpeg",
    "label": "",
    "id": "358"
  },
  {
    "raw_code": "def extract_metadata\n      metadata_path = File.join(@tmp_directory, METADATA_FILE) if @tmp_directory.present?\n\n      if metadata_path.present? && File.exist?(metadata_path)\n        metadata = load_metadata_file(metadata_path)\n      elsif @filename =~ /-#{BackupRestore::VERSION_PREFIX}(\\d{14})/\n        metadata = { version: Regexp.last_match[1].to_i }\n      else\n        raise MetaDataError.new(\"Migration version is missing from the filename.\")\n      end",
    "comment": "Tries to extract the backup version from an existing metadata file (used in Discourse < v1.6) or from the filename.",
    "label": "",
    "id": "359"
  },
  {
    "raw_code": "def self.create(opts = {})\n      case opts[:location] || SiteSetting.backup_location\n      when BackupLocationSiteSetting::LOCAL\n        require \"backup_restore/local_backup_store\"\n        BackupRestore::LocalBackupStore.new(opts)\n      when BackupLocationSiteSetting::S3\n        require \"backup_restore/s3_backup_store\"\n        BackupRestore::S3BackupStore.new(opts)\n      end",
    "comment": "@return [BackupStore]",
    "label": "",
    "id": "360"
  },
  {
    "raw_code": "def files\n      @files ||= unsorted_files.sort_by { |file| -file.last_modified.to_i }\n    end",
    "comment": "@return [Array<BackupFile>]",
    "label": "",
    "id": "361"
  },
  {
    "raw_code": "def latest_file\n      files.first\n    end",
    "comment": "@return [BackupFile]",
    "label": "",
    "id": "362"
  },
  {
    "raw_code": "def file(filename, include_download_source: false)\n      fail NotImplementedError\n    end",
    "comment": "@return [BackupFile]",
    "label": "",
    "id": "363"
  },
  {
    "raw_code": "def unsorted_files\n      fail NotImplementedError\n    end",
    "comment": "@return [Array<BackupFile>]",
    "label": "",
    "id": "364"
  },
  {
    "raw_code": "def sed_command\n      unwanted_sql = [\n        \"DROP SCHEMA\", # Discourse <= v1.5\n        \"CREATE SCHEMA\", # PostgreSQL 11+\n        \"COMMENT ON SCHEMA\", # PostgreSQL 11+\n        \"SET default_table_access_method\", # PostgreSQL 12\n        \"\\\\\\\\restrict\",\n        \"\\\\\\\\unrestrict\",\n      ].join(\"|\")\n\n      command = \"sed -E '/^(#{unwanted_sql})/d' #{@db_dump_path}\"\n      if BackupRestore.postgresql_major_version < 11\n        command = \"#{command} | sed -E 's/^(CREATE TRIGGER.+EXECUTE) FUNCTION/\\\\1 PROCEDURE/'\"\n      end",
    "comment": "Removes unwanted SQL added by certain versions of pg_dump and modifies the dump so that it works on the current version of PostgreSQL.",
    "label": "",
    "id": "365"
  },
  {
    "raw_code": "def start(opts = {})\n    end",
    "comment": "used when starting the runner - preloading happens here",
    "label": "",
    "id": "366"
  },
  {
    "raw_code": "def running?\n      true\n    end",
    "comment": "indicates whether tests are running",
    "label": "",
    "id": "367"
  },
  {
    "raw_code": "def run(specs)\n    end",
    "comment": "launch a batch of specs/tests",
    "label": "",
    "id": "368"
  },
  {
    "raw_code": "def reload\n    end",
    "comment": "used when we need to reload the whole application",
    "label": "",
    "id": "369"
  },
  {
    "raw_code": "def abort\n    end",
    "comment": "used to abort the current run",
    "label": "",
    "id": "370"
  },
  {
    "raw_code": "def stop\n    end",
    "comment": "used to stop the runner",
    "label": "",
    "id": "371"
  },
  {
    "raw_code": "def thread_loop\n    puts \"@@@@@@@@@@@@ thread_loop\" if @debug\n    @mutex.synchronize do\n      current = @queue.first\n      last_failed = false\n      last_failed = process_spec(current) if current\n      # stop & wait for the queue to have at least one item or when there's been a failure\n      if @debug\n        puts \"@@@@@@@@@@@@ waiting because...\"\n        puts \"@@@@@@@@@@@@ ...current spec has failed\" if last_failed\n        puts \"@@@@@@@@@@@@ ...queue is empty\" if @queue.length == 0\n      end",
    "comment": "the main loop, will run the specs in the queue till one fails or the queue is empty",
    "label": "",
    "id": "372"
  },
  {
    "raw_code": "def process_spec(current)\n    puts \"@@@@@@@@@@@@ process_spec --> #{current}\" if @debug\n    has_failed = false\n    # retrieve the instance of the runner\n    runner = current[2]\n    # actually run the spec (blocking call)\n    result = runner.run(current[1]).to_i\n\n    if result == 0\n      puts \"@@@@@@@@@@@@ success\" if @debug\n      # remove the spec from the queue\n      @queue.shift\n    else\n      puts \"@@@@@@@@@@@@ failure\" if @debug\n      has_failed = true\n      if result > 0\n        focus_on_failed_tests(current)\n        ensure_all_specs_will_run(runner) if @auto_run_all\n      end",
    "comment": "will actually run the spec and check whether the spec has failed or not",
    "label": "",
    "id": "373"
  },
  {
    "raw_code": "def reverse_symlink(file)\n    resolved = file\n    @reverse_map ||= reverse_symlink_map\n    @reverse_map.each do |location, discourse_location|\n      resolved = discourse_location + file[location.length..-1] if file.start_with?(location)\n    end",
    "comment": "plugins can be symlinked, try to figure out which plugin this is",
    "label": "",
    "id": "374"
  },
  {
    "raw_code": "def failed_specs\n      specs = []\n      path = \"./tmp/rspec_result\"\n      specs = File.readlines(path) if File.exist?(path)\n      specs\n    end",
    "comment": "reload(%r{app/helpers/.+\\.rb})",
    "label": "",
    "id": "375"
  },
  {
    "raw_code": "def overrides_disabled\n      @overrides_enabled = false\n      yield\n    ensure\n      @overrides_enabled = true\n    end",
    "comment": "In some environments such as migrations we don't want to use overrides. Use this to disable them over a block of ruby code",
    "label": "",
    "id": "376"
  },
  {
    "raw_code": "def include!(name, options = {})\n      unique_values =\n        if hash = options[:hash]\n          if @options[:hash] == hash\n            @options[:unique_values] ||= {}\n          else\n            {}\n          end",
    "comment": "This method is copied over verbatim from the AMS version, except for silently ignoring associations that cannot be embedded without a root instead of raising an exception.",
    "label": "",
    "id": "377"
  },
  {
    "raw_code": "def from_described_class\n        # Mark the method double so it knows to check caller context\n        @method_double.from_described_class_only = true\n\n        self\n      end",
    "comment": "Only apply the stub if called from the described class  @return [MessageExpectation] self, to support chaining @example allow(Process).to receive(:clock_gettime).from_described_class.and_return(123.45)",
    "label": "",
    "id": "378"
  },
  {
    "raw_code": "def proxy_method_invoked(obj, *args, &block)\n        # If this method has from_described_class_only expectations, check the caller\n        if @from_described_class_only && !should_apply_stub?\n          return original_implementation_callable.call(*args, &block)\n        end",
    "comment": "Override proxy_method_invoked to check caller context before processing expectations",
    "label": "",
    "id": "379"
  },
  {
    "raw_code": "def disallow_raw_sql!(args, permit: nil)\n        # we may consider moving to https://github.com/rails/rails/pull/33330\n        # once all frozen string hints are in place\n        BLANK_ARRAY\n      end",
    "comment": "this patch just allows everything in Rails 6+",
    "label": "",
    "id": "380"
  },
  {
    "raw_code": "def changing_upload_security?(upload)\n    !upload.new_record? &&\n      upload.changed_attributes.keys.all? do |attribute|\n        %w[secure security_last_changed_at security_last_changed_reason].include?(attribute)\n      end",
    "comment": "this should only be run on existing records, and covers cases of upload.update_secure_status being run outside of the creation flow, where some cases e.g. have exemptions on the extension enforcement",
    "label": "",
    "id": "381"
  },
  {
    "raw_code": "def valid_regex?(val)\n    r = Regexp.new(val)\n    matches = r.match(LOREM)\n    matches.nil? || matches[0].length < (LOREM.length - 10)\n  rescue StandardError\n    false\n  end",
    "comment": "Check that string is a valid regex, and that it doesn't match most of the lorem string.",
    "label": "",
    "id": "382"
  },
  {
    "raw_code": "def can_create_group?\n    is_admin? || (SiteSetting.moderators_manage_categories_and_groups && is_moderator?)\n  end",
    "comment": "Creating Method",
    "label": "",
    "id": "383"
  },
  {
    "raw_code": "def can_edit_group?(group)\n    !group.automatic &&\n      (can_admin_group?(group) || group.users.where(\"group_users.owner\").include?(user))\n  end",
    "comment": "Edit authority for groups means membership changes only. Automatic groups are not represented in the GROUP_USERS table and thus do not allow membership changes.",
    "label": "",
    "id": "384"
  },
  {
    "raw_code": "def can_create_topic?(parent)\n    is_staff? ||\n      (\n        user && user.in_any_groups?(SiteSetting.create_topic_allowed_groups_map) &&\n          can_create_post?(parent) && Category.topic_create_allowed(self).any?\n      )\n  end",
    "comment": "Creating Methods",
    "label": "",
    "id": "385"
  },
  {
    "raw_code": "def can_edit_topic?(topic)\n    return false if Discourse.static_doc_topic_ids.include?(topic.id) && !is_admin?\n    return false unless can_see?(topic)\n\n    first_post = topic.first_post\n\n    return false if first_post&.locked? && !is_staff?\n\n    return true if is_admin?\n    return true if is_moderator? && can_create_post?(topic)\n    return true if is_category_group_moderator?(topic.category)\n\n    # can't edit topics in secured categories where you don't have permission to create topics\n    # except for a tiny edge case where the topic is uncategorized and you are trying\n    # to fix it but uncategorized is disabled\n    if (\n         SiteSetting.allow_uncategorized_topics ||\n           topic.category_id != SiteSetting.uncategorized_category_id\n       )\n      return false if !can_create_topic_on_category?(topic.category)\n    end",
    "comment": "Editing Method",
    "label": "",
    "id": "386"
  },
  {
    "raw_code": "def can_see_topic_ids(topic_ids: [], hide_deleted: true)\n    topic_ids = topic_ids.compact\n\n    return topic_ids if is_admin? && !SiteSetting.suppress_secured_categories_from_admin\n    return [] if topic_ids.blank?\n\n    default_scope = Topic.unscoped.where(id: topic_ids)\n\n    # When `hide_deleted` is `true`, hide deleted topics if user is not staff or category moderator\n    if hide_deleted && !is_staff?\n      if category_group_moderation_allowed?\n        default_scope = default_scope.where(<<~SQL)\n          (\n            deleted_at IS NULL OR\n            (\n              deleted_at IS NOT NULL\n              AND topics.category_id IN (#{category_group_moderator_scope.select(:id).to_sql})\n            )\n          )\n        SQL\n      else\n        default_scope = default_scope.where(\"deleted_at IS NULL\")\n      end",
    "comment": "Accepts an array of `Topic#id` and returns an array of `Topic#id` which the user can see.",
    "label": "",
    "id": "387"
  },
  {
    "raw_code": "def can_create_category?(parent = nil)\n    is_admin? || (SiteSetting.moderators_manage_categories_and_groups && is_moderator?)\n  end",
    "comment": "Creating Method",
    "label": "",
    "id": "388"
  },
  {
    "raw_code": "def can_edit_category?(category)\n    is_admin? ||\n      (\n        SiteSetting.moderators_manage_categories_and_groups && is_moderator? &&\n          can_see_category?(category)\n      )\n  end",
    "comment": "Editing Method",
    "label": "",
    "id": "389"
  },
  {
    "raw_code": "def allowed_category_ids\n    @allowed_category_ids ||=\n      begin\n        unrestricted = Category.where(read_restricted: false).pluck(:id)\n        unrestricted.concat(secure_category_ids)\n      end",
    "comment": "all allowed category ids",
    "label": "",
    "id": "390"
  },
  {
    "raw_code": "def ensure_can_see!(obj)\n    raise Discourse::InvalidAccess.new(\"Can't see #{obj}\") unless can_see?(obj)\n  end",
    "comment": "Make sure we can see the object. Will raise a NotFound if it's nil",
    "label": "",
    "id": "391"
  },
  {
    "raw_code": "def post_can_act?(post, action_key, opts: {}, can_see_post: nil)\n    return false if !(can_see_post.nil? && can_see_post?(post)) && !can_see_post\n\n    # no warnings except for staff\n    if action_key == :notify_user &&\n         (\n           post.user.blank? ||\n             (!is_staff? && opts[:is_warning].present? && opts[:is_warning] == \"true\")\n         )\n      return false\n    end",
    "comment": "Can the user act on the post in a particular way. taken_actions = the list of actions the user has already taken",
    "label": "",
    "id": "392"
  },
  {
    "raw_code": "def can_see_post_actors?(topic, post_action_type_id)\n    return true if is_admin?\n    return false unless topic\n\n    post_action_type_view = PostActionTypeView.new\n    type_symbol = post_action_type_view.types[post_action_type_id]\n\n    return false if type_symbol == :bookmark\n    return false if type_symbol == :notify_user && !is_moderator?\n\n    return can_see_flags?(topic) if post_action_type_view.is_flag?(type_symbol)\n\n    true\n  end",
    "comment": "Can we see who acted on a post in a particular way?",
    "label": "",
    "id": "393"
  },
  {
    "raw_code": "def to_html\n      fail NoMethodError, \"Engines need to implement this method\"\n    end",
    "comment": "raises error if not defined in onebox engine. This is the output method for an engine.",
    "label": "",
    "id": "394"
  },
  {
    "raw_code": "def placeholder_html\n      to_html\n    end",
    "comment": "Some oneboxes create iframes or other complicated controls. If you're using a live editor with HTML preview, rendering those complicated controls can be slow or cause flickering.  This method allows engines to produce a placeholder such as static image frame of a video.  By default it just calls `to_html` unless implemented.",
    "label": "",
    "id": "395"
  },
  {
    "raw_code": "def raw\n      fail NoMethodError, \"Engines need to implement this method\"\n    end",
    "comment": "raises error if not defined in onebox engine in each onebox, uses either Nokogiri or StandardEmbed to get raw HTML from url",
    "label": "",
    "id": "396"
  },
  {
    "raw_code": "def data\n      fail NoMethodError, \"Engines need this method defined\"\n    end",
    "comment": "raises error if not defined in onebox engine in each onebox, returns hash of desired onebox content",
    "label": "",
    "id": "397"
  },
  {
    "raw_code": "def onebox_name\n        name.split(\"::\").last.downcase.gsub(/onebox/, \"\")\n      end",
    "comment": "calculates a name for onebox using the class name of engine",
    "label": "",
    "id": "398"
  },
  {
    "raw_code": "def self.fetch_html_doc(url, headers = nil)\n      response =\n        (\n          begin\n            fetch_response(url, headers:, raise_error_when_response_too_large: false)\n          rescue StandardError\n            nil\n          end",
    "comment": "Fetches the HTML response body for a URL.  Note that the size of the response body is capped at `Onebox.options.max_download_kb`. When the limit has been reached, this method will return the response body that has been downloaded up to the limit.",
    "label": "",
    "id": "399"
  },
  {
    "raw_code": "def self.uri_encode(url)\n      return \"\" unless url\n\n      uri = Addressable::URI.parse(url)\n\n      encoded_uri =\n        Addressable::URI.new(\n          scheme:\n            Addressable::URI.encode_component(\n              uri.scheme,\n              Addressable::URI::CharacterClasses::SCHEME,\n            ),\n          authority:\n            Addressable::URI.encode_component(\n              uri.authority,\n              Addressable::URI::CharacterClasses::AUTHORITY,\n            ),\n          path:\n            Addressable::URI.encode_component(\n              uri.path,\n              Addressable::URI::CharacterClasses::PATH + \"\\\\%\",\n            ),\n          query:\n            Addressable::URI.encode_component(\n              uri.query,\n              \"a-zA-Z0-9\\\\-\\\\.\\\\_\\\\~\\\\$\\\\&\\\\*\\\\,\\\\=\\\\:\\\\@\\\\?\\\\%\",\n            ),\n          fragment:\n            Addressable::URI.encode_component(\n              uri.fragment,\n              \"a-zA-Z0-9\\\\-\\\\.\\\\_\\\\~\\\\!\\\\$\\\\&\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\;\\\\=\\\\:\\\\/\\\\?\\\\%\",\n            ),\n        )\n\n      encoded_uri.to_s\n    end",
    "comment": "Percent-encodes a URI string per RFC3986 - https://tools.ietf.org/html/rfc3986",
    "label": "",
    "id": "400"
  },
  {
    "raw_code": "def self.priority\n        1\n      end",
    "comment": "This engine should have priority over AllowlistedGenericOnebox.",
    "label": "",
    "id": "401"
  },
  {
    "raw_code": "def url\n        \"https://hacker-news.firebaseio.com/v0/item/#{match[:item_id]}.json\"\n      end",
    "comment": "This is their official API: https://blog.ycombinator.com/hacker-news-api/",
    "label": "",
    "id": "402"
  },
  {
    "raw_code": "def self.default_html_providers\n        %w[Flickr Meetup]\n      end",
    "comment": "Often using the `html` attribute is not what we want, like for some blogs that include the entire page HTML. However for some providers like Flickr it allows us to return gifv and galleries.",
    "label": "",
    "id": "403"
  },
  {
    "raw_code": "def self.rewrites\n        @rewrites ||= https_hosts.dup\n      end",
    "comment": "A re-written URL converts http:// -> https://",
    "label": "",
    "id": "404"
  },
  {
    "raw_code": "def http_params\n        {}\n      end",
    "comment": "Overwrite for any custom headers",
    "label": "",
    "id": "405"
  },
  {
    "raw_code": "def video_id\n        match = uri.path.match(%r{/v_show/id_([a-zA-Z0-9_=\\-]+)(\\.html)?.*})\n        match && match[1]\n      rescue StandardError\n        nil\n      end",
    "comment": "Try to get the video ID. Works for URLs of the form: * http://v.youku.com/v_show/id_XNjM3MzAxNzc2.html * http://v.youku.com/v_show/id_XMTQ5MjgyMjMyOA==.html?from=y1.3-tech-index3-232-10183.89969-89963.3-1",
    "label": "",
    "id": "406"
  },
  {
    "raw_code": "def removeLeadingIndentation(str)\n          min_space = 100\n          a_lines = str.lines\n          a_lines.each do |l|\n            l = l.chomp(\"\\n\") # remove new line\n            m = l.match(/\\A[ ]*/) # find leading spaces 0 or more\n            if m.nil? || l.size == m[0].size || l.size == 0\n              next # SKIP no match or line is only spaces\n            else # no match | only spaces in line | empty line\n              m_str_length = m[0].size\n              if m_str_length <= 1 # minimum space is 1 or nothing we can break we found our minimum\n                min_space = m_str_length\n                break #stop iteration\n              end",
    "comment": "minimize/compact leading indentation while preserving overall indentation",
    "label": "",
    "id": "407"
  },
  {
    "raw_code": "def load_translations(*filenames)\n        unless filenames.empty?\n          self.class.sort_locale_files(filenames.flatten).each { |filename| load_file(filename) }\n        end",
    "comment": "force explicit loading",
    "label": "",
    "id": "408"
  },
  {
    "raw_code": "def lookup(locale, key, scope = [], options = {})\n        existing_translations = super(locale, key, scope, options)\n        return existing_translations if scope.is_a?(Array) && scope.include?(:models)\n\n        overrides = options.dig(:overrides, locale)\n        key = key.to_s\n\n        if overrides\n          if options[:count]\n            if !existing_translations\n              I18n.fallbacks[locale]\n                .drop(1)\n                .each do |fallback|\n                  existing_translations = super(fallback, key, scope, options)\n                  break if existing_translations.present?\n                end",
    "comment": "Support interpolation and pluralization of overrides by first looking up the original translations before applying our overrides.",
    "label": "",
    "id": "409"
  },
  {
    "raw_code": "def plugin_styles\n      @@plugin_callbacks.each { |block| block.call(@fragment, @opts) }\n    end",
    "comment": "this method is reserved for styles specific to plugin",
    "label": "",
    "id": "410"
  },
  {
    "raw_code": "def generate_or_use_existing(post_ids)\n        post_ids = Array.wrap(post_ids)\n        return [] if post_ids.empty?\n\n        DB.exec(<<~SQL, host: host)\n          UPDATE posts\n          SET outbound_message_id = 'discourse/post/' || posts.id || '@' || :host\n          WHERE outbound_message_id IS NULL AND posts.id IN (#{post_ids.join(\",\")});\n        SQL\n\n        DB.query_single(<<~SQL)\n          SELECT '<' || posts.outbound_message_id || '>'\n          FROM posts\n          WHERE posts.id IN (#{post_ids.join(\",\")})\n          ORDER BY posts.created_at ASC;\n        SQL\n      end",
    "comment": " The outbound_message_id may be present because either:  * The post was created via incoming email and Email::Receiver, and references a Message-ID generated by an external email client or service. * At least one email has been sent because of the post being created to inform interested parties via email.  If it is blank then we should assume Discourse was the originator of the post, and generate a Message-ID to be used from now on using our discourse/post/POST_ID@HOST format.",
    "label": "",
    "id": "411"
  },
  {
    "raw_code": "def find_post_from_message_ids(message_ids)\n        message_ids = message_ids.map { |message_id| message_id_clean(message_id) }\n\n        post_ids =\n          message_ids\n            .map { |message_id| message_id[message_id_discourse_regexp, 1] }\n            .compact\n            .map(&:to_i)\n\n        post_ids << Post.where(outbound_message_id: message_ids).pluck(:id)\n        post_ids << EmailLog.where(message_id: message_ids).pluck(:post_id)\n        post_ids << IncomingEmail.where(message_id: message_ids).pluck(:post_id)\n\n        post_ids.flatten!\n        post_ids.compact!\n        post_ids.uniq!\n\n        return if post_ids.empty?\n\n        Post.where(id: post_ids).order(:created_at).last\n      end",
    "comment": " Uses extracted Message-IDs from both the In-Reply-To and References headers from an incoming email.",
    "label": "",
    "id": "412"
  },
  {
    "raw_code": "def fix_parts_after_attachments!\n      has_attachments = @message.attachments.present?\n      has_alternative_renderings = @message.html_part.present? && @message.text_part.present?\n\n      if has_attachments && has_alternative_renderings\n        @message.content_type = \"multipart/mixed; boundary=\\\"#{@message.body.boundary}\\\"\"\n\n        html_part = @message.html_part\n        @message.html_part = nil\n        @message.parts.reject! { |p| p.content_type.start_with?(\"text/html\") }\n\n        text_part = @message.text_part\n        @message.text_part = nil\n        @message.parts.reject! { |p| p.content_type.start_with?(\"text/plain\") }\n\n        content =\n          Mail::Part.new do\n            content_type \"multipart/alternative\"\n\n            # we have to re-specify the charset and give the part the decoded body\n            # here otherwise the parts will get encoded with US-ASCII which makes\n            # a bunch of characters not render correctly in the email\n            part content_type: \"text/html; charset=utf-8\", body: html_part.body.decoded\n            part content_type: \"text/plain; charset=utf-8\", body: text_part.body.decoded\n          end",
    "comment": " Two behaviors in the mail gem collide:  1. Attachments are added as extra parts at the top level, 2. When there are both text and html parts, the content type is set to 'multipart/alternative'.  Since attachments aren't alternative renderings, for emails that contain attachments and both html and text parts, some coercing is necessary.  When there are alternative rendering and attachments, this method causes the top level to be 'multipart/mixed' and puts the html and text parts into a nested 'multipart/alternative' part.  Due to mail gem magic, @message.text_part and @message.html_part still refer to the same objects.  Most imporantly, we need to specify the boundary for the multipart/mixed part of the email, otherwise we can end up with an email that appears to be empty with the entire body attached as a single attachment, and some mail parsers consider the entire email as a preamble/epilogue.  c.f. https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html",
    "label": "",
    "id": "413"
  },
  {
    "raw_code": "def add_identification_field_headers(topic, post)\n      @message.header[\"Message-ID\"] = Email::MessageIdService.generate_or_use_existing(\n        post.id,\n      ).first\n\n      if post.post_number > 1\n        op_message_id = Email::MessageIdService.generate_or_use_existing(topic.first_post.id).first\n\n        ##\n        # Whenever we reply to a post directly _or_ quote a post, a PostReply\n        # record is made, with the reply_post_id referencing the newly created\n        # post, and the post_id referencing the post that was quoted or replied to.\n        referenced_posts =\n          Post\n            .joins(\"INNER JOIN post_replies ON post_replies.post_id = posts.id \")\n            .where(\"post_replies.reply_post_id = ?\", post.id)\n            .order(id: :desc)\n            .to_a\n\n        ##\n        # No referenced posts means that we are just creating a new post not\n        # referring to anything, and as such we should just fall back to using\n        # the OP.\n        if referenced_posts.empty?\n          @message.header[\"In-Reply-To\"] = op_message_id\n          @message.header[\"References\"] = op_message_id\n        else\n          ##\n          # When referencing _multiple_ posts then we just choose the most recent one\n          # to use for References so we have a single parent to work with, but\n          # every directly replied to post can go into In-Reply-To.\n          #\n          # We want to make sure all of the outbound_message_ids are already filled here.\n          in_reply_to_message_ids =\n            MessageIdService.generate_or_use_existing(referenced_posts.map(&:id))\n          @message.header[\"In-Reply-To\"] = in_reply_to_message_ids\n          most_recent_post_message_id = in_reply_to_message_ids.last\n\n          ##\n          # The RFC specifically states that the content of the parent's References\n          # field (in our case a tree of replies based on the PostReply table in\n          # addition to the OP post's Message-ID) first, _then_ the parent's\n          # Message-ID (in our case the outbound_message_id of the post we are replying to).\n          #\n          # This creates a thread from the OP all the way down to the most recent post we\n          # are replying to.\n          reply_tree = referenced_post_reply_tree(referenced_posts.first)\n          parent_message_ids = MessageIdService.generate_or_use_existing(reply_tree.values.flatten)\n\n          @message.header[\"References\"] = [\n            op_message_id,\n            parent_message_ids,\n            most_recent_post_message_id,\n          ].flatten.uniq\n        end",
    "comment": " When sending an email for the first post (OP) of the topic, we do not set References or In-Reply-To headers, since there is nothing yet to reference. This counts as the first email in the thread.  Once set, the post's `outbound_message_id` should _always_ be used when sending emails relating to a particular post to maintain threading. This will either be:  a) A Message-ID generated in an external main client or service which is recorded when creating a post from an IncomingEmail via Email::Receiver b) A Message-ID generated by Discourse and recorded when sending an email for a newly created post, which is created and saved here to the outbound_message_id column on the Post.  The RFC that covers using \"Identification Fields\", which are References, In-Reply-To, Message-ID, et. al. can be in the RFC link below. It's a good idea to read this beginning in the area immediately after these quotes, at least to understand the 3 main headers:  > The \"Message-ID:\" field provides a unique message identifier that > refers to a particular version of a particular message.  The > uniqueness of the message identifier is guaranteed by the host that > generates it.  > ...  > The \"In-Reply-To:\" field may be used to identify the message (or > messages) to which the new message is a reply, while the \"References:\" > field may be used to identify a \"thread\" of conversation.  https://www.rfc-editor.org/rfc/rfc5322.html#section-3.6.4  It is a long read, but to understand the decision making process for this threading logic you can take a look at:  https://meta.discourse.org/t/discourse-email-messages-are-incorrectly-threaded/233499",
    "label": "",
    "id": "414"
  },
  {
    "raw_code": "def poll_mailbox(process_cb)\n      raise NotImplementedError\n    end",
    "comment": "To be implemented by concrete classes. This function takes as input a function that processes the incoming email. The function passed as argument should take as an argument the MIME string of the email. An example of function to pass is `process_popmail` in `app/jobs/scheduled/poll_mailbox.rb`",
    "label": "",
    "id": "415"
  },
  {
    "raw_code": "def enabled?\n      true\n    end",
    "comment": "Child class can override this",
    "label": "",
    "id": "416"
  },
  {
    "raw_code": "def up\n    result = DB.query <<~SQL\n      SELECT character_maximum_length\n      FROM information_schema.columns\n      WHERE table_schema='public'\n      AND table_name = 'posts'\n      AND column_name IN ('action_code', 'edit_reason')\n    SQL\n\n    # No need to continue if the schema is already correct\n    return if result.all? { |r| r.character_maximum_length.nil? }\n\n    execute \"DROP VIEW badge_posts\"\n\n    execute \"ALTER TABLE posts ALTER COLUMN action_code TYPE varchar\"\n    execute \"ALTER TABLE posts ALTER COLUMN edit_reason TYPE varchar\"\n\n    # we must recreate this view every time we amend posts\n    # p.* is auto expanded and persisted into the view definition\n    # at create time\n    execute <<~SQL\n      CREATE VIEW badge_posts AS\n      SELECT p.*\n      FROM posts p\n      JOIN topics t ON t.id = p.topic_id\n      JOIN categories c ON c.id = t.category_id\n      WHERE c.allow_badges AND\n            p.deleted_at IS NULL AND\n            t.deleted_at IS NULL AND\n            NOT c.read_restricted AND\n            t.visible AND\n            p.post_type IN (1,2,3)\n    SQL\n  end",
    "comment": "In the past, rails changed the default behavior for varchar columns This only affects older discourse installations This migration removes the character limits from posts columns, so that they match modern behavior  To modify the posts table schema we need to recreate the badge_posts view This should be done in a transaction",
    "label": "",
    "id": "417"
  },
  {
    "raw_code": "def up\n    execute <<~SQL\n      CREATE INDEX CONCURRENTLY IF NOT EXISTS \"index_topics_on_pinned_until\"\n      ON \"topics\" (\"pinned_until\")\n      WHERE pinned_until IS NOT NULL\n    SQL\n  end",
    "comment": "Dropping to raw SQL here due to an ActiveRecord bug which prevents using `algorithm: :concurrently` and `if_not_exists: true` https://github.com/rails/rails/pull/41490",
    "label": "",
    "id": "418"
  },
  {
    "raw_code": "def up\n    sql = <<SQL\n    DELETE FROM topic_allowed_users tu\n    USING topic_allowed_groups tg\n    JOIN group_users gu ON gu.group_id = tg.group_id\n    WHERE tu.user_id = gu.user_id AND tg.topic_id = tu.topic_id\nSQL\n\n    execute sql\n  end",
    "comment": "historically we added admins automatically to a message if they responded, despite them being in the group the message is targeted at this causes inbox bloat for pretty much no reason",
    "label": "",
    "id": "419"
  },
  {
    "raw_code": "def migrate_redis_keys\n    return if Rails.env.test?\n\n    temp_keys = Discourse.redis.keys(\"temporary_key:*\")\n    if temp_keys.present?\n      temp_keys.map! do |key|\n        user_id = Discourse.redis.get(key).to_i\n        ttl = Discourse.redis.ttl(key).to_i\n\n        if ttl > 0\n          ttl = \"'#{ttl.seconds.ago.strftime(\"%Y-%m-%d %H:%M:%S\")}'\"\n        else\n          ttl = \"CURRENT_TIMESTAMP\"\n        end",
    "comment": "It is slightly odd to migrate from redis to postgres; I imagine a lot could fail, so if anything does we just rescue",
    "label": "",
    "id": "420"
  },
  {
    "raw_code": "def up\n    add_column :topics, :bookmark_count, :int\n    add_column :topics, :off_topic_count, :int\n    add_column :topics, :illegal_count, :int\n    add_column :topics, :inappropriate_count, :int\n    add_column :topics, :notify_user_count, :int\n  end",
    "comment": "This really sucks big time, we have no use for these columns yet can not remove them if we remove them then sites will be down during migration",
    "label": "",
    "id": "421"
  },
  {
    "raw_code": "def up\n    execute <<~SQL\n      INSERT INTO user_custom_fields (\n        user_id,\n        name,\n        value,\n        created_at,\n        updated_at\n      ) SELECT\n          REPLACE(key, 'notes:', '')::int,\n          'user_notes_count',\n          json_array_length(value::json),\n          now(),\n          now()\n          FROM plugin_store_rows\n          WHERE plugin_name = 'user_notes'\n          AND key LIKE 'notes:%'\n      ON CONFLICT (name, user_id) WHERE name::text = 'user_notes_count'::text\n      DO NOTHING\n    SQL\n  end",
    "comment": "This corrects an error in the previous migration (now fixed)",
    "label": "",
    "id": "422"
  },
  {
    "raw_code": "def refund_subscription(subscription_id)\n        subscription = ::Stripe::Subscription.retrieve(subscription_id)\n        invoice = ::Stripe::Invoice.retrieve(subscription[:latest_invoice]) if subscription[\n          :latest_invoice\n        ]\n        payment_intent = invoice[:payment_intent] if invoice[:payment_intent]\n        refund = ::Stripe::Refund.create({ payment_intent: payment_intent })\n      end",
    "comment": "this will only refund the most recent subscription payment",
    "label": "",
    "id": "423"
  },
  {
    "raw_code": "def serialize_option(option, user)\n  PollOptionSerializer.new(\n    option,\n    root: false,\n    scope: {\n      can_see_results: poll.can_see_results?(user),\n    },\n  )\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "424"
  },
  {
    "raw_code": "def request_phase\n    fail!(\n      :third_party_only,\n      StandardError.new(\"LTI authentication can only be initiated by the identity provider\"),\n    )\n  end",
    "comment": "LTI authentication is only supported as a \"third party initiated login\" i.e. all authentication must be started by the 'platform'",
    "label": "",
    "id": "425"
  },
  {
    "raw_code": "def removed?(sha)\n      commit = @client.commit(@repo.name, sha)\n      return true if commit.commit.nil?\n      found =\n        @client.commits(@repo.name, until: commit.commit.committer.date, page: 1, per_page: 1).first\n      commit.sha != found.sha\n    end",
    "comment": "detect if a force push happened and commit is lost",
    "label": "",
    "id": "426"
  },
  {
    "raw_code": "def primary_email_verified?(auth_token)\n    true\n  end",
    "comment": "apple requires email verification to create an account so we can assume email is verified",
    "label": "",
    "id": "427"
  },
  {
    "raw_code": "def self.update_title(thread_id:, guardian:, title:)\n      new.update(thread_id:, guardian:, title:)\n    end",
    "comment": "Updates the title of a specified chat thread.  @param title [String] The new title for the chat thread. @param thread_id [Integer] The ID of the chat thread to be updated. @param guardian [Guardian] The guardian object representing the user's permissions. @return [Chat::Thread] The updated thread object with the new title.  @example Updating the title of a chat thread ChatSDK::Thread.update_title(title: \"New Thread Title\", thread_id: 1, guardian: Guardian.new) ",
    "label": "",
    "id": "428"
  },
  {
    "raw_code": "def self.messages(...)\n      new.messages(...)\n    end",
    "comment": "Retrieves messages from a specified thread.  @param thread_id [Integer] The ID of the chat thread from which to fetch messages. @param guardian [Guardian] The guardian object representing the user's permissions. @return [Array<Chat::Message>] An array of message objects from the specified thread.  @example Fetching messages from a thread with additional parameters ChatSDK::Thread.messages(thread_id: 1, guardian: Guardian.new) ",
    "label": "",
    "id": "429"
  },
  {
    "raw_code": "def self.first_messages(thread_id:, guardian:, page_size: 10)\n      new.messages(\n        thread_id:,\n        guardian:,\n        page_size:,\n        direction: \"future\",\n        fetch_from_first_message: true,\n      )\n    end",
    "comment": "Fetches the first messages from a specified chat thread, starting from the first available message.  @param thread_id [Integer] The ID of the chat thread from which to fetch messages. @param guardian [Guardian] The guardian object representing the user's permissions. @param page_size [Integer] (optional) The number of messages to fetch, defaults to 10. @return [Array<Chat::Message>] An array of message objects representing the first messages in the thread.  @example Fetching the first 15 messages from a thread ChatSDK::Thread.first_messages(thread_id: 1, guardian: Guardian.new, page_size: 15) ",
    "label": "",
    "id": "430"
  },
  {
    "raw_code": "def self.last_messages(thread_id:, guardian:, page_size: 10)\n      new.messages(\n        thread_id:,\n        guardian:,\n        page_size:,\n        direction: \"past\",\n        fetch_from_last_message: true,\n      )\n    end",
    "comment": "Fetches the last messages from a specified chat thread, starting from the last available message.  @param thread_id [Integer] The ID of the chat thread from which to fetch messages. @param guardian [Guardian] The guardian object representing the user's permissions. @param page_size [Integer] (optional) The number of messages to fetch, defaults to 10. @return [Array<Chat::Message>] An array of message objects representing the last messages in the thread.  @example Fetching the last 20 messages from a thread ChatSDK::Thread.last_messages(thread_id: 2, guardian: Guardian.new, page_size: 20) ",
    "label": "",
    "id": "431"
  },
  {
    "raw_code": "def self.create(...)\n      new.create(...)\n    end",
    "comment": "Creates a new message in a chat channel.  @param raw [String] The content of the message. @param channel_id [Integer] The ID of the chat channel. @param guardian [Guardian] The user's guardian object, for policy enforcement. @param in_reply_to_id [Integer, nil] The ID of the message this is in reply to (optional). @param thread_id [Integer, nil] The ID of the thread this message belongs to (optional). @param upload_ids [Array<Integer>, nil] The IDs of any uploads associated with the message (optional). @param streaming [Boolean] Whether the message is part of a streaming operation (default: false). @param enforce_membership [Boolean] Allows to ensure the guardian will be allowed in the channel (default: false). @yield [helper, message] Offers a block with a helper and the message for streaming operations. @yieldparam helper [Helper] The helper object for streaming operations. @yieldparam message [Message] The newly created message object. @return [Chat::Message] The created message object.  @example Creating a simple message ChatSDK::Message.create(raw: \"Hello, world!\", channel_id: 1, guardian: Guardian.new)  @example Creating a message with a block for streaming ChatSDK::Message.create_with_stream(raw: \"Streaming message\", channel_id: 1, guardian: Guardian.new) do |helper, message| helper.stream(raw: \"Continuation of the message\") end",
    "label": "",
    "id": "432"
  },
  {
    "raw_code": "def self.create_with_stream(**params, &block)\n      self.create(**params, streaming: true, strip_whitespaces: false, &block)\n    end",
    "comment": "Creates a new message with streaming enabled by default.  This method is a convenience wrapper around `create` with `streaming: true` set by default. It supports all the same parameters and block usage as `create`.  @see #create",
    "label": "",
    "id": "433"
  },
  {
    "raw_code": "def self.stream(...)\n      new.stream(...)\n    end",
    "comment": "Streams to a specific chat message.  @param raw [String] text to append to the existing message. @param message_id [Integer] the ID of the message to stream. @param guardian [Guardian] an instance of the guardian class, representing the user's permissions. @return [Chat::Message] The message object. @example Streaming a message ChatSDK::Message.stream(message_id: 42, guardian: guardian, raw: \"text\")",
    "label": "",
    "id": "434"
  },
  {
    "raw_code": "def self.start_stream(...)\n      new.start_stream(...)\n    end",
    "comment": "Starts streaming for a specific chat message.  @param message_id [Integer] the ID of the message for which streaming should be stopped. @param guardian [Guardian] an instance of the guardian class, representing the user's permissions. @return [Chat::Message] The message object. @example Starting the streaming of a message ChatSDK::Message.start_stream(message_id: 42, guardian: guardian)",
    "label": "",
    "id": "435"
  },
  {
    "raw_code": "def self.stop_stream(...)\n      new.stop_stream(...)\n    end",
    "comment": "Stops streaming for a specific chat message.  @param message_id [Integer] the ID of the message for which streaming should be stopped. @param guardian [Guardian] an instance of the guardian class, representing the user's permissions. @return [Chat::Message] The message object. @example Stopping the streaming of a message ChatSDK::Message.stop_stream(message_id: 42, guardian: guardian)",
    "label": "",
    "id": "436"
  },
  {
    "raw_code": "def self.messages(...)\n      new.messages(...)\n    end",
    "comment": "Retrieves messages from a specified channel.  @param channel_id [Integer] The ID of the chat channel from which to fetch messages. @param guardian [Guardian] The guardian object representing the user's permissions. @return [Array<ChMessage>] An array of message objects from the specified channel.  @example Fetching messages from a channel with additional parameters ChatSDK::Channel.messages(channel_id: 1, guardian: Guardian.new)  @raise [RuntimeError] Raises an \"Unexpected error\" if the message retrieval fails for an unspecified reason. @raise [RuntimeError] Raises \"Guardian can't view channel\" if the user's permissions are insufficient to view the channel. @raise [RuntimeError] Raises \"Target message doesn't exist\" if the specified target message cannot be found in the channel.",
    "label": "",
    "id": "437"
  },
  {
    "raw_code": "def self.start_reply(...)\n      new.start_reply(...)\n    end",
    "comment": "Initiates a reply in a specified channel or thread.  @param channel_id [Integer] The ID of the channel where the reply is started. @param thread_id [Integer, nil] (optional) The ID of the thread within the channel where the reply is started. @param guardian [Guardian] The guardian object representing the user's permissions. @return [String] The client ID associated with the initiated reply.  @example Starting a reply in a channel ChatSDK::Channel.start_reply(channel_id: 1, guardian: Guardian.new)  @example Starting a reply in a specific thread ChatSDK::Channel.start_reply(channel_id: 1, thread_id: 34, guardian: Guardian.new)  @raise [RuntimeError] Raises an error if the specified channel or thread is not found.",
    "label": "",
    "id": "438"
  },
  {
    "raw_code": "def self.stop_reply(...)\n      new.stop_reply(...)\n    end",
    "comment": "Ends an ongoing reply in a specified channel or thread.  @param channel_id [Integer] The ID of the channel where the reply is being stopped. @param thread_id [Integer, nil] (optional) The ID of the thread within the channel where the reply is being stopped. @param client_id [String] The client ID associated with the reply to stop. @param guardian [Guardian] The guardian object representing the user's permissions.  @example Stopping a reply in a channel ChatSDK::Channel.stop_reply(channel_id: 1, client_id: \"abc123\", guardian: Guardian.new)  @example Stopping a reply in a specific thread ChatSDK::Channel.stop_reply(channel_id: 1, thread_id: 34, client_id: \"abc123\", guardian: Guardian.new)  @raise [RuntimeError] Raises an error if the specified channel or thread is not found.",
    "label": "",
    "id": "439"
  },
  {
    "raw_code": "def can_edit_chat_channel?(channel)\n      if channel.direct_message_channel?\n        is_staff? || channel.chatable.user_can_access?(@user)\n      elsif channel.category_channel?\n        is_staff?\n      end",
    "comment": "Channel status intentionally has no bearing on whether the channel name and description can be edited.",
    "label": "",
    "id": "440"
  },
  {
    "raw_code": "def can_edit_thread?(thread)\n      is_staff? || thread.original_message_user_id == @user.id\n    end",
    "comment": "The only part of the thread that can be changed is the title so this isn't too dangerous, if we end up wanting to change more things in future we may want to re-evaluate to be staff-only here.",
    "label": "",
    "id": "441"
  },
  {
    "raw_code": "def can_modify_channel_message?(chat_channel)\n      return chat_channel.open? || chat_channel.closed? if is_staff?\n      chat_channel.open?\n    end",
    "comment": "This is intentionally identical to can_create_channel_message, we may want to have different conditions here in future.",
    "label": "",
    "id": "442"
  },
  {
    "raw_code": "def notify_new\n      to_notify, inaccessible, all_mentioned_user_ids = list_users_to_notify\n\n      all_mentioned_user_ids.each do |member_id|\n        Chat::Publisher.publish_new_mention(member_id, @chat_channel.id, @chat_message.id)\n      end",
    "comment": "Public API",
    "label": "",
    "id": "443"
  },
  {
    "raw_code": "def filter_users_ignoring_or_muting_creator(to_notify, inaccessible, already_covered_ids)\n      screen_targets = already_covered_ids.concat(inaccessible[:welcome_to_join].map(&:id))\n\n      return if screen_targets.blank?\n\n      screener = UserCommScreener.new(acting_user: @user, target_user_ids: screen_targets)\n      to_notify.each do |key, user_ids|\n        to_notify[key] = user_ids.reject { |user_id| screener.ignoring_or_muting_actor?(user_id) }\n      end",
    "comment": "Filters out users from global, here, group, and direct mentions that are ignoring or muting the creator of the message, so they will not receive a notification via the Jobs::Chat::NotifyMentioned job and are not prompted for invitation by the creator.",
    "label": "",
    "id": "444"
  },
  {
    "raw_code": "def self.update_settings\n      if SiteSetting.secure_uploads && SiteSetting.chat_allow_uploads &&\n           !GlobalSetting.allow_unsecure_chat_uploads\n        SiteSetting.chat_allow_uploads = false\n        StaffActionLogger.new(Discourse.system_user).log_site_setting_change(\n          \"chat_allow_uploads\",\n          true,\n          false,\n          context: \"Disabled because secure_uploads is enabled\",\n        )\n      end",
    "comment": " At this point in time, secure uploads is not compatible with chat, so if it is enabled then chat uploads must be disabled to avoid undesirable behaviour.  The env var DISCOURSE_ALLOW_UNSECURE_CHAT_UPLOADS can be set to keep it enabled, but this is strongly advised against.",
    "label": "",
    "id": "445"
  },
  {
    "raw_code": "def process_legacy_attachments(attachments)\n        text = CGI.unescape(attachments[0][:fallback])\n        process_text(text)\n      end",
    "comment": "TODO: This is quite hacky and is only here to support a single attachment for our OpsGenie integration. In future we would want to iterate through this attachments array and extract things properly.  See https://api.slack.com/reference/messaging/attachments for more details on what fields are here.",
    "label": "",
    "id": "446"
  },
  {
    "raw_code": "def create_destination_messages_in_channel(destination_channel, moved_thread_ids)\n      insert_messages = <<-SQL\n        INSERT INTO chat_messages (\n          chat_channel_id, user_id, last_editor_id, message, cooked, cooked_version, thread_id, created_at, updated_at\n        )\n        SELECT :destination_channel_id, user_id, last_editor_id, message, cooked, cooked_version, :new_thread_id, CLOCK_TIMESTAMP(), CLOCK_TIMESTAMP()\n        FROM chat_messages\n        WHERE id = :source_message_id\n        RETURNING id\n      SQL\n\n      moved_message_ids =\n        @source_messages.map do |source_message|\n          new_thread_id = moved_thread_ids[source_message.thread_id]\n\n          new_message_id =\n            DB.query_single(\n              insert_messages,\n              {\n                destination_channel_id: destination_channel.id,\n                new_thread_id: new_thread_id,\n                source_message_id: source_message.id,\n              },\n            ).first\n\n          new_message_id\n        end",
    "comment": " We purposefully omit in_reply_to_id when creating the messages in the new channel, because it could be pointing to a message that has not been moved.",
    "label": "",
    "id": "447"
  },
  {
    "raw_code": "def reactions\n      @reactions ||= DB.query(<<~SQL, @messages.map(&:id))\n    SELECT emoji, STRING_AGG(DISTINCT users.username, ',') AS usernames, chat_message_id\n    FROM chat_message_reactions\n    INNER JOIN users on users.id = chat_message_reactions.user_id\n    WHERE chat_message_id IN (?)\n    GROUP BY emoji, chat_message_id\n    ORDER BY chat_message_id, emoji\n    SQL\n    end",
    "comment": " Queries reactions and returns them in this format  emoji   |  usernames  |  chat_message_id ---------------------------------------- +1      | foo,bar,baz | 102 heart   | foo         | 102 sob     | bar,baz     | 103",
    "label": "",
    "id": "448"
  },
  {
    "raw_code": "def self.prepended(base)\n      if base.ignored_columns\n        base.ignored_columns = base.ignored_columns + %i[last_emailed_for_chat chat_isolated]\n      else\n        base.ignored_columns = %i[last_emailed_for_chat chat_isolated]\n      end",
    "comment": "TODO: remove last_emailed_for_chat and chat_isolated in 2023",
    "label": "",
    "id": "449"
  },
  {
    "raw_code": "def create_post_from_batch(chat_messages, batch_thread_ranges)\n      create_post(\n        Chat::TranscriptService.new(\n          chat_channel,\n          chat_channel_archive.archived_by,\n          messages_or_ids: chat_messages,\n          thread_ranges: batch_thread_ranges,\n          opts: {\n            no_link: true,\n            include_reactions: true,\n          },\n        ).generate_markdown,\n      ) { delete_message_batch(chat_messages.map(&:id)) }\n    end",
    "comment": "It's used to call the TranscriptService, which will generate the markdown for a given set of messages.",
    "label": "",
    "id": "450"
  },
  {
    "raw_code": "def calculate_thread_ranges(message_chunk, thread, thread_om, post_last_message)\n      ranges = {}\n      thread_size = thread.size - 1\n      last_thread_index = 0\n      iterations = (message_chunk.size.to_f / (ARCHIVED_MESSAGES_PER_POST - 1)).ceil\n\n      iterations.times do |index|\n        if last_thread_index != thread_size\n          if index == 0\n            thread_index = thread.index(post_last_message)\n          else\n            next_post_last_message =\n              message_chunk[(ARCHIVED_MESSAGES_PER_POST * (index + 1)) - index]\n            if next_post_last_message&.thread_id == post_last_message&.thread_id\n              thread_index = last_thread_index + ARCHIVED_MESSAGES_PER_POST - 1\n            else\n              thread_index = thread_size\n            end",
    "comment": "Message batches can be greater than the maximum number of messages per post if we also include threads. This is used to calculate all the ranges when we split the threads that are included in the batch.",
    "label": "",
    "id": "451"
  },
  {
    "raw_code": "def up\n    chat_allow_uploads_value =\n      DB.query_single(\"SELECT value FROM site_settings WHERE name = 'chat_allow_uploads'\").first\n\n    # nil means it is true, since the default value is true\n    chat_uploads_enabled = chat_allow_uploads_value == \"t\" || chat_allow_uploads_value.nil?\n\n    secure_media_enabled =\n      DB.query_single(\"SELECT value FROM site_settings WHERE name = 'secure_media'\").first == \"t\"\n    secure_uploads_enabled =\n      DB.query_single(\"SELECT value FROM site_settings WHERE name = 'secure_uploads'\").first == \"t\"\n\n    if (secure_media_enabled || secure_uploads_enabled) && chat_uploads_enabled &&\n         !GlobalSetting.allow_unsecure_chat_uploads\n      if chat_allow_uploads_value.nil?\n        DB.exec(\n          \"\n          INSERT INTO site_settings(name, data_type, value, created_at, updated_at)\n          VALUES('chat_allow_uploads', 5, 'f', NOW(), NOW())\n        \",\n        )\n      else\n        DB.exec(\"UPDATE site_settings SET value = 'f' WHERE name = 'chat_allow_uploads'\")\n      end",
    "comment": " At this point in time, secure media is not compatible with chat, so if it is enabled then chat uploads must be disabled to avoid undesirable behaviour.  The env var DISCOURSE_ALLOW_UNSECURE_CHAT_UPLOADS can be set to keep it enabled, but this is strongly advised against.",
    "label": "",
    "id": "452"
  },
  {
    "raw_code": "def self.call(thread_ids:)\n      return {} if thread_ids.blank?\n\n      # We only want enough data for BasicUserSerializer, since the participants\n      # are just showing username & avatar.\n      thread_participant_stats = DB.query(<<~SQL, thread_ids: thread_ids)\n        SELECT thread_participant_stats.*, users.username, users.name, users.uploaded_avatar_id FROM (\n          SELECT chat_messages.thread_id, chat_messages.user_id, COUNT(*) AS message_count,\n            ROW_NUMBER() OVER (PARTITION BY chat_messages.thread_id ORDER BY COUNT(*) DESC) AS row_number\n          FROM chat_messages\n          INNER JOIN chat_threads ON chat_threads.id = chat_messages.thread_id\n          INNER JOIN user_chat_thread_memberships ON user_chat_thread_memberships.thread_id = chat_threads.id\n            AND user_chat_thread_memberships.user_id = chat_messages.user_id\n          WHERE chat_messages.thread_id IN (:thread_ids)\n          AND chat_messages.deleted_at IS NULL\n          GROUP BY chat_messages.thread_id, chat_messages.user_id\n        ) AS thread_participant_stats\n        INNER JOIN users ON users.id = thread_participant_stats.user_id\n        ORDER BY thread_participant_stats.thread_id ASC, thread_participant_stats.message_count DESC, thread_participant_stats.user_id ASC\n      SQL\n\n      most_recent_participants = DB.query(<<~SQL, thread_ids: thread_ids)\n        SELECT DISTINCT ON (thread_id) chat_messages.thread_id, chat_messages.user_id,\n          users.username, users.name, users.uploaded_avatar_id\n        FROM chat_messages\n        INNER JOIN chat_threads ON chat_threads.id = chat_messages.thread_id\n        INNER JOIN user_chat_thread_memberships ON user_chat_thread_memberships.thread_id = chat_threads.id\n          AND user_chat_thread_memberships.user_id = chat_messages.user_id\n        INNER JOIN users ON users.id = chat_messages.user_id\n        WHERE chat_messages.thread_id IN (:thread_ids)\n        AND chat_messages.deleted_at IS NULL\n        ORDER BY chat_messages.thread_id ASC, chat_messages.created_at DESC\n      SQL\n      most_recent_participants =\n        most_recent_participants.reduce({}) do |hash, mrm|\n          hash[mrm.thread_id] = {\n            id: mrm.user_id,\n            username: mrm.username,\n            name: mrm.name,\n            uploaded_avatar_id: mrm.uploaded_avatar_id,\n          }\n          hash\n        end",
    "comment": "@param thread_ids [Array<Integer>] The IDs of the threads to query. @param preview [Boolean] Determines the number of participants to return. @return [Hash<Integer, Hash>] A hash of thread IDs to participant data.",
    "label": "",
    "id": "453"
  },
  {
    "raw_code": "def self.call(channel_ids:, user_id:, include_missing_memberships: false, include_read: true)\n      sql = <<~SQL\n        SELECT (\n          SELECT COUNT(*) AS unread_count\n          FROM chat_messages\n          INNER JOIN chat_channels ON chat_channels.id = chat_messages.chat_channel_id\n          INNER JOIN user_chat_channel_memberships ON user_chat_channel_memberships.chat_channel_id = chat_channels.id\n          LEFT JOIN chat_threads ON chat_threads.id = chat_messages.thread_id\n          WHERE chat_channels.id = memberships.chat_channel_id\n          AND user_chat_channel_memberships.user_id = :user_id\n          AND chat_messages.id > COALESCE(user_chat_channel_memberships.last_read_message_id, 0)\n          AND chat_messages.deleted_at IS NULL\n          AND (chat_messages.thread_id IS NULL OR chat_messages.id = chat_threads.original_message_id)\n          AND NOT user_chat_channel_memberships.muted\n        ) AS unread_count,\n        (\n          SELECT COUNT(*) AS mention_count\n          FROM notifications\n          INNER JOIN user_chat_channel_memberships AS uccm ON uccm.user_id = :user_id\n          INNER JOIN chat_messages ON (data::json->>'chat_message_id')::bigint = chat_messages.id\n          LEFT JOIN chat_threads ON chat_threads.id = chat_messages.thread_id\n          LEFT JOIN user_chat_thread_memberships AS uctm ON uctm.thread_id = chat_messages.thread_id AND uctm.user_id = :user_id\n          WHERE NOT read\n          AND uccm.chat_channel_id = memberships.chat_channel_id\n          AND notifications.user_id = :user_id\n          AND notifications.notification_type = :notification_type_mention\n          AND (data::json->>'chat_channel_id')::bigint = memberships.chat_channel_id\n          AND (((chat_messages.thread_id IS NULL OR chat_messages.id = chat_threads.original_message_id) AND chat_messages.id > COALESCE(uccm.last_read_message_id, 0))\n          OR (chat_messages.thread_id IS NOT NULL AND uctm.id IS NOT NULL AND chat_messages.id > COALESCE(uctm.last_read_message_id, 0)))\n        ) AS mention_count,\n        (\n          SELECT COUNT(*) AS watched_threads_unread_count\n          FROM chat_messages\n          INNER JOIN chat_channels ON chat_channels.id = chat_messages.chat_channel_id\n          INNER JOIN chat_threads ON chat_threads.id = chat_messages.thread_id AND chat_threads.channel_id = chat_messages.chat_channel_id\n          INNER JOIN user_chat_thread_memberships ON user_chat_thread_memberships.thread_id = chat_threads.id\n          WHERE chat_messages.chat_channel_id = memberships.chat_channel_id\n          AND chat_messages.thread_id = user_chat_thread_memberships.thread_id\n          AND chat_messages.user_id != :user_id\n          AND chat_messages.deleted_at IS NULL\n          AND chat_messages.thread_id IS NOT NULL\n          AND chat_messages.id != chat_threads.original_message_id\n          AND chat_messages.id > COALESCE(user_chat_thread_memberships.last_read_message_id, 0)\n          AND user_chat_thread_memberships.user_id = :user_id\n          AND user_chat_thread_memberships.notification_level = :watching_level\n          AND (chat_channels.threading_enabled OR chat_threads.force = true)\n        ) AS watched_threads_unread_count,\n        memberships.chat_channel_id AS channel_id\n        FROM user_chat_channel_memberships AS memberships\n        WHERE memberships.user_id = :user_id AND memberships.chat_channel_id IN (:channel_ids)\n        GROUP BY memberships.chat_channel_id\n        #{include_missing_memberships ? \"\" : \"LIMIT :limit\"}\n      SQL\n\n      sql = <<~SQL if !include_read\n        SELECT * FROM (\n          #{sql}\n        ) AS channel_tracking\n        WHERE (unread_count > 0 OR mention_count > 0 OR watched_threads_unread_count > 0)\n      SQL\n\n      sql += <<~SQL if include_missing_memberships && include_read\n        UNION ALL\n        SELECT 0 AS unread_count, 0 AS mention_count, 0 AS watched_threads_unread_count, chat_channels.id AS channel_id\n        FROM chat_channels\n        LEFT JOIN user_chat_channel_memberships ON user_chat_channel_memberships.chat_channel_id = chat_channels.id\n          AND user_chat_channel_memberships.user_id = :user_id\n        WHERE chat_channels.id IN (:channel_ids) AND user_chat_channel_memberships.id IS NULL\n        GROUP BY chat_channels.id\n        LIMIT :limit\n      SQL\n\n      DB.query(\n        sql,\n        channel_ids: channel_ids,\n        user_id: user_id,\n        notification_type_mention: ::Notification.types[:chat_mention],\n        watching_level: ::Chat::UserChatThreadMembership.notification_levels[:watching],\n        limit: MAX_CHANNELS,\n      )\n    end",
    "comment": " @param channel_ids [Array<Integer>] The IDs of the channels to count. @param user_id [Integer] The ID of the user to count for. @param include_missing_memberships [Boolean] Whether to include channels that the user is not a member of. These counts will always be 0. @param include_read [Boolean] Whether to include channels that the user is a member of where they have read all the messages. This overrides include_missing_memberships.",
    "label": "",
    "id": "454"
  },
  {
    "raw_code": "def self.call(\n      channel:,\n      guardian:,\n      thread_id: nil,\n      target_message_id: nil,\n      include_thread_messages: false,\n      page_size: PAST_MESSAGE_LIMIT + FUTURE_MESSAGE_LIMIT,\n      direction: nil,\n      target_date: nil,\n      include_target_message_id: false\n    )\n      messages = base_query(channel: channel)\n      messages = messages.with_deleted if guardian.can_moderate_chat?(channel.chatable)\n      if thread_id.present?\n        include_thread_messages = true\n        messages = messages.where(thread_id: thread_id)\n      end",
    "comment": "@param channel [Chat::Channel] The channel to query messages within. @param guardian [Guardian] The guardian to use for permission checks. @param thread_id [Integer] (optional) The thread ID to filter messages by. @param target_message_id [Integer] (optional) The message ID to query around. It is assumed that the caller already checked if this exists. @param target_date [String] (optional) The date to query around. @param include_thread_messages [Boolean] (optional) Whether to include messages that are linked to a thread. @param page_size [Integer] (optional) The number of messages to fetch when not using the target_message_id param. @param direction [String] (optional) The direction to fetch messages in when not using the target_message_id param. Must be valid. If not provided, only the latest messages for the channel are loaded. @param include_target_message_id [Boolean] (optional) Specifies whether the target message specified by target_message_id should be included in the results. This parameter modifies the behavior when querying messages: - When true and the direction is set to \"past\", the query will include messages up to and including the target message. - When true and the direction is set to \"future\", the query will include messages starting from and including the target message. - When false, the query will exclude the target message, fetching only those messages strictly before or after it, depending on the direction.",
    "label": "",
    "id": "455"
  },
  {
    "raw_code": "def self.call(\n      channel_ids: nil,\n      thread_ids: nil,\n      user_id:,\n      include_missing_memberships: false,\n      include_read: true\n    )\n      return [] if channel_ids.blank? && thread_ids.blank?\n\n      sql = <<~SQL\n        SELECT (\n          SELECT COUNT(*) AS unread_count\n          FROM chat_messages\n          INNER JOIN chat_channels ON chat_channels.id = chat_messages.chat_channel_id\n          INNER JOIN chat_threads ON chat_threads.id = chat_messages.thread_id AND chat_threads.channel_id = chat_messages.chat_channel_id\n          INNER JOIN user_chat_thread_memberships ON user_chat_thread_memberships.thread_id = chat_threads.id\n          INNER JOIN user_chat_channel_memberships ON user_chat_channel_memberships.chat_channel_id = chat_messages.chat_channel_id\n          INNER JOIN chat_messages AS original_message ON original_message.id = chat_threads.original_message_id\n          WHERE chat_messages.thread_id = memberships.thread_id\n          AND chat_messages.user_id != :user_id\n          AND user_chat_thread_memberships.user_id = :user_id\n          AND chat_messages.id > COALESCE(user_chat_thread_memberships.last_read_message_id, 0)\n          AND chat_messages.deleted_at IS NULL\n          AND chat_messages.thread_id IS NOT NULL\n          AND chat_messages.id != chat_threads.original_message_id\n          AND (chat_channels.threading_enabled OR chat_threads.force = true)\n          AND user_chat_thread_memberships.notification_level = :tracking_level\n          AND original_message.deleted_at IS NULL\n          AND user_chat_channel_memberships.muted = false\n          AND user_chat_channel_memberships.user_id = :user_id\n        ) AS unread_count,\n        (\n          SELECT COUNT(*) AS mention_count\n          FROM notifications\n          INNER JOIN chat_messages ON chat_messages.id = (data::json->>'chat_message_id')::bigint\n          INNER JOIN chat_channels ON chat_channels.id = chat_messages.chat_channel_id\n          INNER JOIN user_chat_channel_memberships AS uccm ON uccm.chat_channel_id = chat_messages.chat_channel_id\n          INNER JOIN user_chat_thread_memberships AS uctm ON uctm.thread_id = chat_messages.thread_id AND uctm.user_id = :user_id\n          WHERE NOT read\n          AND notifications.user_id = :user_id\n          AND notifications.notification_type = :notification_type_mention\n          AND uccm.user_id = :user_id\n          AND chat_channels.threading_enabled\n          AND chat_messages.deleted_at IS NULL\n          AND chat_messages.thread_id = memberships.thread_id\n          AND (uctm.id IS NOT NULL AND chat_messages.id > COALESCE(uctm.last_read_message_id, 0))\n          AND NOT uccm.muted\n        ) AS mention_count,\n        (\n          SELECT COUNT(*) AS watched_threads_unread_count\n          FROM chat_messages\n          INNER JOIN chat_channels ON chat_channels.id = chat_messages.chat_channel_id\n          INNER JOIN chat_threads ON chat_threads.id = chat_messages.thread_id AND chat_threads.channel_id = chat_messages.chat_channel_id\n          INNER JOIN user_chat_thread_memberships ON user_chat_thread_memberships.thread_id = chat_threads.id\n          INNER JOIN user_chat_channel_memberships ON user_chat_channel_memberships.chat_channel_id = chat_messages.chat_channel_id\n          INNER JOIN chat_messages AS original_message ON original_message.id = chat_threads.original_message_id\n          WHERE chat_messages.thread_id = memberships.thread_id\n          AND chat_messages.user_id != :user_id\n          AND user_chat_thread_memberships.user_id = :user_id\n          AND chat_messages.id > COALESCE(user_chat_thread_memberships.last_read_message_id, 0)\n          AND chat_messages.deleted_at IS NULL\n          AND chat_messages.thread_id IS NOT NULL\n          AND chat_messages.id != chat_threads.original_message_id\n          AND (chat_channels.threading_enabled OR chat_threads.force = true)\n          AND user_chat_thread_memberships.notification_level = :watching_level\n          AND original_message.deleted_at IS NULL\n          AND user_chat_channel_memberships.user_id = :user_id\n          AND NOT user_chat_channel_memberships.muted\n        ) AS watched_threads_unread_count,\n        chat_threads.channel_id,\n        memberships.thread_id\n        FROM user_chat_thread_memberships AS memberships\n        INNER JOIN chat_threads ON chat_threads.id = memberships.thread_id\n        WHERE memberships.user_id = :user_id\n        #{channel_ids.present? ? \"AND chat_threads.channel_id IN (:channel_ids)\" : \"\"}\n        #{thread_ids.present? ? \"AND chat_threads.id IN (:thread_ids)\" : \"\"}\n        GROUP BY memberships.thread_id, chat_threads.channel_id\n        #{include_missing_memberships ? \"\" : \"LIMIT :limit\"}\n      SQL\n\n      sql = <<~SQL if !include_read\n          SELECT * FROM (\n            #{sql}\n          ) AS thread_tracking\n          WHERE (unread_count > 0 OR mention_count > 0 OR watched_threads_unread_count > 0)\n        SQL\n\n      sql += <<~SQL if include_missing_memberships && include_read\n        UNION ALL\n        SELECT 0 AS unread_count, 0 AS mention_count, 0 AS watched_threads_unread_count, chat_threads.channel_id, chat_threads.id AS thread_id\n        FROM chat_channels\n        INNER JOIN chat_threads ON chat_threads.channel_id = chat_channels.id\n        LEFT JOIN user_chat_thread_memberships ON user_chat_thread_memberships.thread_id = chat_threads.id\n          AND user_chat_thread_memberships.user_id = :user_id\n        WHERE user_chat_thread_memberships.id IS NULL\n        #{channel_ids.present? ? \"AND chat_threads.channel_id IN (:channel_ids)\" : \"\"}\n        #{thread_ids.present? ? \"AND chat_threads.id IN (:thread_ids)\" : \"\"}\n        GROUP BY chat_threads.id\n        LIMIT :limit\n      SQL\n\n      DB.query(\n        sql,\n        channel_ids: channel_ids,\n        thread_ids: thread_ids,\n        user_id: user_id,\n        notification_type: ::Notification.types[:chat_mention],\n        limit: MAX_THREADS,\n        tracking_level: ::Chat::UserChatThreadMembership.notification_levels[:tracking],\n        watching_level: ::Chat::UserChatThreadMembership.notification_levels[:watching],\n        notification_type_mention: ::Notification.types[:chat_mention],\n      )\n    end",
    "comment": " @param channel_ids [Array<Integer>] (Optional) The IDs of the channels to count threads for. If only this is provided, all threads across the channels provided will be counted. @param thread_ids [Array<Integer>] (Optional) The IDs of the threads to count. If this is used in tandem with channel_ids, it will just further filter the results of the thread counts from those channels. @param user_id [Integer] The ID of the user to count for. @param include_missing_memberships [Boolean] Whether to include threads that the user is not a member of. These counts will always be 0. @param include_read [Boolean] Whether to include threads that the user is a member of where they have read all the messages. This overrides include_missing_memberships.",
    "label": "",
    "id": "456"
  },
  {
    "raw_code": "def create_message_slack_compatible\n      debug_payload\n\n      # See note in validate_payload on why this is needed\n      attachments =\n        if params[:payload].present?\n          payload = params[:payload]\n          if String === payload\n            payload = JSON.parse(payload)\n            payload.deep_symbolize_keys!\n          end",
    "comment": "See https://api.slack.com/reference/messaging/payload for the slack message payload format. For now we only support the text param, which we preprocess lightly to remove the slack-isms in the formatting.",
    "label": "",
    "id": "457"
  },
  {
    "raw_code": "def validate_payload\n      params.require(:key)\n\n      if !params[:text] && !params[:payload] && !params[:attachments]\n        raise Discourse::InvalidParameters\n      end",
    "comment": "The webhook POST body can be in 3 different formats:  * { text: \"message text\" }, which is the most basic method, and also mirrors Slack payloads * { attachments: [ text: \"message text\" ] }, which is a variant of Slack payloads using legacy attachments * { payload: \"<JSON STRING>\", attachments: null, text: null }, where JSON STRING can look like the `attachments` example above (along with other attributes), which is fired by OpsGenie",
    "label": "",
    "id": "458"
  },
  {
    "raw_code": "def direct_message_group?\n      direct_message.group?\n    end",
    "comment": "Group DMs are DMs with > 2 users",
    "label": "",
    "id": "459"
  },
  {
    "raw_code": "def create_message(chat_channel, message, mention_klass = nil)\n    chat_message = Fabricate(:chat_message, user: other, chat_channel:, message:)\n\n    if mention_klass\n      notification_type = Notification.types[:chat_mention]\n\n      Fabricate(\n        :chat_mention_notification,\n        notification: Fabricate(:notification, user:, notification_type:),\n        chat_mention: mention_klass.find_by(chat_message:),\n      )\n    end",
    "comment": "This helper is much faster than `Fabricate(:chat_message_with_service, ...)`",
    "label": "",
    "id": "460"
  },
  {
    "raw_code": "def classify_results(result)\n    if result.is_a?(Array)\n      result.each { |r| r.merge!(classify_result_pass_fail(r)) }\n    else\n      [classify_result_pass_fail(result)]\n    end",
    "comment": "@param result [String, Array<Hash>] the result of the eval, either \"llm response\" or [{ result: \"llm response\", other_attrs: here }] @return [Array<Hash>] an array of hashes with the result classified as pass or fail, along with extra attributes",
    "label": "",
    "id": "461"
  },
  {
    "raw_code": "def run_single_test(prompt, message, followups, output_thinking, stream, temperature, tools)\n    @c_prompt =\n      DiscourseAi::Completions::Prompt.new(prompt, messages: [{ type: :user, content: message }])\n    @c_prompt.tools = tools if tools\n    generate_result(temperature, output_thinking, stream)\n\n    if followups\n      followups.each do |followup|\n        generate_followup(followup, output_thinking, stream, temperature)\n      end",
    "comment": "Run a single test with a prompt and message, and some model settings @param prompt [String] the prompt to use @param message [String] the message to use @param followups [Array<Hash>] an array of followups (messages) to run after the initial prompt @param output_thinking [Boolean] whether to output the thinking state of the model @param stream [Boolean] whether to stream the output of the model @param temperature [Float] the temperature to use when generating completions @param tools [Array<Hash>] an array of tools to use when generating completions @return [Hash] the prompt, message, and result of the test",
    "label": "",
    "id": "462"
  },
  {
    "raw_code": "def find_summarization_model(persona_klass)\n        model_id = persona_klass.default_llm_id || SiteSetting.ai_default_llm_model\n\n        if model_id.present?\n          LlmModel.find_by(id: model_id)\n        else\n          LlmModel.last\n        end",
    "comment": "Priorities are: 1. Persona's default LLM 2. SiteSetting.ai_default_llm_model (or newest LLM if not set)",
    "label": "",
    "id": "463"
  },
  {
    "raw_code": "def build_bot(persona_klass, llm_model)\n        persona = persona_klass.new\n        user = User.find_by(id: persona_klass.user_id) || Discourse.system_user\n\n        DiscourseAi::Personas::Bot.as(user, persona: persona, model: llm_model)\n      end",
    "comment": "Private",
    "label": "",
    "id": "464"
  },
  {
    "raw_code": "def find_ai_hyde_model(persona_klass)\n        model_id = persona_klass.default_llm_id || SiteSetting.ai_default_llm_model\n\n        model_id.present? ? LlmModel.find_by(id: model_id) : LlmModel.last\n      end",
    "comment": "Priorities are: 1. Persona's default LLM 2. SiteSetting.ai_default_llm_model (or newest LLM if not set)",
    "label": "",
    "id": "465"
  },
  {
    "raw_code": "def log_creation(entity_type, entity, field_config = {}, entity_details = {})\n        # Start with provided entity details (id, name, etc.)\n        # Convert all keys to strings for consistent handling in StaffActionLogger\n        log_details = {}\n\n        # Extract subject for StaffActionLogger.base_attrs\n        subject =\n          entity_details[:subject] ||\n            (entity.respond_to?(:display_name) ? entity.display_name : nil)\n\n        # Add the entity details but preserve subject as a top-level attribute\n        entity_details.each { |k, v| log_details[k.to_s] = v unless k == :subject }\n\n        # Extract attributes based on field configuration and ensure string keys\n        extract_entity_attributes(entity, field_config).each do |key, value|\n          log_details[key.to_s] = value\n        end",
    "comment": "Logs the creation of an AI entity (LLM model or persona) @param entity_type [Symbol] The type of AI entity being created @param entity [Object] The entity object being created @param field_config [Hash] Configuration for how to handle different entity fields @param entity_details [Hash] Additional details about the entity to be logged",
    "label": "",
    "id": "466"
  },
  {
    "raw_code": "def log_update(\n        entity_type,\n        entity,\n        initial_attributes,\n        field_config = {},\n        entity_details = {}\n      )\n        current_attributes = entity.attributes\n        changes = {}\n\n        # Process changes based on field configuration\n        field_config\n          .except(:json_fields)\n          .each do |field, options|\n            # Skip if field is not to be tracked\n            next if options[:track] == false\n\n            initial_value = initial_attributes[field.to_s]\n            current_value = current_attributes[field.to_s]\n\n            # Only process if there's an actual change\n            if initial_value != current_value\n              # Format the change based on field type\n              changes[field.to_s] = format_field_change(\n                field,\n                initial_value,\n                current_value,\n                options,\n              )\n            end",
    "comment": "Logs an update to an AI entity with before/after comparison @param entity_type [Symbol] The type of AI entity being updated @param entity [Object] The entity object after update @param initial_attributes [Hash] The attributes of the entity before update @param field_config [Hash] Configuration for how to handle different entity fields @param entity_details [Hash] Additional details about the entity to be logged",
    "label": "",
    "id": "467"
  },
  {
    "raw_code": "def log_deletion(entity_type, entity_details)\n        # Extract subject for StaffActionLogger.base_attrs\n        subject = entity_details[:subject]\n\n        # Convert all keys to strings for consistent handling in StaffActionLogger\n        string_details = {}\n        entity_details.each { |k, v| string_details[k.to_s] = v unless k == :subject }\n\n        @staff_logger.log_custom(\"delete_ai_#{entity_type}\", string_details.merge(subject: subject))\n      end",
    "comment": "Logs the deletion of an AI entity @param entity_type [Symbol] The type of AI entity being deleted @param entity_details [Hash] Details about the entity being deleted",
    "label": "",
    "id": "468"
  },
  {
    "raw_code": "def log_custom(action_type, log_details)\n        # Extract subject for StaffActionLogger.base_attrs if present\n        subject = log_details[:subject]\n\n        # Convert all keys to strings for consistent handling in StaffActionLogger\n        string_details = {}\n        log_details.each { |k, v| string_details[k.to_s] = v unless k == :subject }\n\n        @staff_logger.log_custom(action_type, string_details.merge(subject: subject))\n      end",
    "comment": "Direct custom logging for complex cases @param action_type [String] The type of action being logged @param log_details [Hash] Details to be logged",
    "label": "",
    "id": "469"
  },
  {
    "raw_code": "def format_field_change(field, initial_value, current_value, options = {})\n        if options[:type] == :sensitive\n          return format_sensitive_field_change(initial_value, current_value)\n        elsif options[:type] == :large_text ||\n              (initial_value.is_a?(String) && initial_value.length > MAX_TEXT_LENGTH) ||\n              (current_value.is_a?(String) && current_value.length > MAX_TEXT_LENGTH)\n          return I18n.t(\"discourse_ai.ai_staff_action_logger.updated\")\n        end",
    "comment": "Formats the change in a field's value for logging @param field [Symbol] The field that changed @param initial_value [Object] The original value @param current_value [Object] The new value @param options [Hash] Options for formatting @return [String] Formatted representation of the change",
    "label": "",
    "id": "470"
  },
  {
    "raw_code": "def format_sensitive_field_change(initial_value, current_value)\n        if initial_value.present? && current_value.present?\n          I18n.t(\"discourse_ai.ai_staff_action_logger.updated\")\n        elsif current_value.present?\n          I18n.t(\"discourse_ai.ai_staff_action_logger.set\")\n        else\n          I18n.t(\"discourse_ai.ai_staff_action_logger.removed\")\n        end",
    "comment": "Formats changes to sensitive fields without exposing actual values @param initial_value [Object] The original value @param current_value [Object] The new value @return [String] Description of the change (updated/set/removed)",
    "label": "",
    "id": "471"
  },
  {
    "raw_code": "def extract_entity_attributes(entity, field_config)\n        result = {}\n        field_config.each do |field, options|\n          # Skip special keys like :json_fields which are arrays, not field configurations\n          next if field == :json_fields\n\n          # Skip if options is not a hash or if explicitly marked as not to be extracted\n          next if !options.is_a?(Hash) || options[:extract] == false\n\n          # Get the actual field value\n          field_sym = field.to_sym\n          value = entity.respond_to?(field_sym) ? entity.public_send(field_sym) : nil\n\n          # Apply field-specific handling\n          if options[:type] == :sensitive\n            result[field] = value.present? ? \"[FILTERED]\" : nil\n          elsif options[:type] == :large_text && value.is_a?(String) &&\n                value.length > MAX_TEXT_LENGTH\n            result[field] = value.truncate(MAX_TEXT_LENGTH)\n          else\n            result[field] = value\n          end",
    "comment": "Extracts relevant attributes from an entity based on field configuration @param entity [Object] The entity to extract attributes from @param field_config [Hash] Configuration for how to handle different entity fields @return [Hash] The extracted attributes",
    "label": "",
    "id": "472"
  },
  {
    "raw_code": "def read(length)\n      # for implementation simplicity we will process one image at a time\n      if !@buffer.empty?\n        part = @buffer.slice!(0, length)\n        return part\n      end",
    "comment": "return nil if no more data",
    "label": "",
    "id": "473"
  },
  {
    "raw_code": "def self.find_ai_helper_model(helper_mode, persona_klass)\n        model_id = persona_klass.default_llm_id || SiteSetting.ai_default_llm_model\n\n        if model_id.present?\n          LlmModel.find_by(id: model_id)\n        else\n          LlmModel.last\n        end",
    "comment": "Priorities are: 1. Persona's default LLM 2. SiteSetting.ai_default_llm_model (or newest LLM if not set)",
    "label": "",
    "id": "474"
  },
  {
    "raw_code": "def process_message(json)\n      result = []\n\n      (json[:output] || []).each do |item|\n        type = item[:type]\n\n        case type\n        when \"function_call\"\n          result << build_tool_call_from_item(item)\n        when \"message\"\n          text = extract_text(item)\n          result << text if text\n        end",
    "comment": "@param json [Hash] full JSON response from responses.create / retrieve @return [Array<String,ToolCall>] pieces in the order they were produced",
    "label": "",
    "id": "475"
  },
  {
    "raw_code": "def process_streamed_message(json)\n      rval = nil\n      event_type = json[:type] || json[\"type\"]\n\n      case event_type\n      when \"response.output_text.delta\"\n        delta = json[:delta] || json[\"delta\"]\n        rval = delta if !delta.empty?\n      when \"response.output_item.added\"\n        item = json[:item]\n        if item && item[:type] == \"function_call\"\n          handle_tool_stream(:start, item) { |finished| rval = finished }\n        end",
    "comment": "@param json [Hash] a single streamed event, already parsed from ND-JSON @return [String, ToolCall, nil] only when a complete chunk is ready",
    "label": "",
    "id": "476"
  },
  {
    "raw_code": "def notify_progress(key, value)\n      if @tool\n        @tool.partial = true\n        @tool.parameters[key.to_sym] = value\n        @has_new_data = true\n      end",
    "comment": "Called by JsonStreamingTracker when partial JSON arguments are parsed",
    "label": "",
    "id": "477"
  },
  {
    "raw_code": "def process_arguments\n      return if @tool_arguments.to_s.empty?\n      parsed = JSON.parse(@tool_arguments, symbolize_names: true)\n      @tool.parameters = parsed\n      @tool.partial = false\n      @tool_arguments = nil\n    rescue JSON::ParserError\n      # leave arguments empty; caller can decide how to handle\n    end",
    "comment": "Parse accumulated @tool_arguments once we have a complete JSON blob",
    "label": "",
    "id": "478"
  },
  {
    "raw_code": "def <<(data)\n          data = data.dup if data.frozen?\n          # Avoid state machine for complete UTF-8.\n          if @buffer.empty?\n            data.force_encoding(Encoding::UTF_8)\n            return data if data.valid_encoding?\n          end",
    "comment": "Fill the buffer with a String of binary UTF-8 encoded bytes. Returns as much of the data in a UTF-8 String as we have. Truncated multi-byte characters are saved in the buffer until the next call to this method where we expect to receive the rest of the multi-byte character.  data - The partial binary encoded String data.  Raises JSON::Stream::ParserError if the UTF-8 byte sequence is malformed.  Returns a UTF-8 encoded String.",
    "label": "",
    "id": "479"
  },
  {
    "raw_code": "def empty?\n          @buffer.empty?\n        end",
    "comment": "Determine if the buffer contains partial UTF-8 continuation bytes that are waiting on subsequent completion bytes before a full codepoint is formed.  Examples  bytes = \"\".bytes  buffer << bytes[0] buffer.empty? # => false  buffer << bytes[1] buffer.empty? # => true  Returns true if the buffer is empty.",
    "label": "",
    "id": "480"
  },
  {
    "raw_code": "def initialize(&block)\n        @state = :start_document\n        @utf8 = Buffer.new\n        @listeners = {\n          start_document: [],\n          end_document: [],\n          start_object: [],\n          end_object: [],\n          start_array: [],\n          end_array: [],\n          key: [],\n          value: [],\n        }\n\n        # Track parse stack.\n        @stack = []\n        @unicode = +\"\"\n        @buf = +\"\"\n        @pos = -1\n\n        # Register any observers in the block.\n        instance_eval(&block) if block_given?\n      end",
    "comment": "Create a new parser with an optional initialization block where we can register event callbacks.  Examples  parser = JSON::Stream::Parser.new do start_document { puts \"start document\" } end_document   { puts \"end document\" } start_object   { puts \"start object\" } end_object     { puts \"end object\" } start_array    { puts \"start array\" } end_array      { puts \"end array\" } key            { |k| puts \"key: #{k}\" } value          { |v| puts \"value: #{v}\" } end",
    "label": "",
    "id": "481"
  },
  {
    "raw_code": "def <<(data)\n        (@utf8 << data).each_char do |ch|\n          @pos += 1\n          case @state\n          when :start_document\n            start_value(ch)\n          when :start_object\n            case ch\n            when QUOTE\n              @state = :start_string\n              @stack.push(:key)\n            when RIGHT_BRACE\n              end_container(:object)\n            when WS\n              # ignore\n            else\n              error(\"Expected object key start\")\n            end",
    "comment": "Pass data into the parser to advance the state machine and generate callback events. This is well suited for an EventMachine receive_data loop.  data - The String of partial JSON data to parse.  Raises a JSON::Stream::ParserError if the JSON data is malformed.  Returns nothing.",
    "label": "",
    "id": "482"
  },
  {
    "raw_code": "def finish\n        # Partial multi-byte character waiting for completion bytes.\n        error(\"Unexpected end-of-file\") unless @utf8.empty?\n\n        # Partial array, object, or string.\n        error(\"Unexpected end-of-file\") unless @stack.empty?\n\n        case @state\n        when :end_document\n          # done, do nothing\n        when :in_float\n          end_value(@buf.to_f)\n        when :in_exponent\n          error(\"Unexpected end-of-file\") unless @buf =~ DIGIT_END\n          end_value(@buf.to_f)\n        when :start_zero\n          end_value(@buf.to_i)\n        when :start_int\n          end_value(@buf.to_i)\n        else\n          error(\"Unexpected end-of-file\")\n        end",
    "comment": "Drain any remaining buffered characters into the parser to complete the parsing of the document.  This is only required when parsing a document containing a single numeric value, integer or float. The parser has no other way to detect when it should no longer expect additional characters with which to complete the parse, so it must be signaled by a call to this method.  If you're parsing more typical object or array documents, there's no need to call `finish` because the parse will complete when the final closing `]` or `}` character is scanned.  Raises a JSON::Stream::ParserError if the JSON data is malformed.  Returns nothing.",
    "label": "",
    "id": "483"
  },
  {
    "raw_code": "def notify(type, *args)\n        @listeners[type].each { |block| block.call(*args) }\n      end",
    "comment": "Invoke all registered observer procs for the event type.  type - The Symbol listener name. args - The argument list to pass into the observer procs.  Examples  # broadcast events for {\"answer\": 42} notify(:start_object) notify(:key, \"answer\") notify(:value, 42) notify(:end_object)  Returns nothing.",
    "label": "",
    "id": "484"
  },
  {
    "raw_code": "def end_container(type)\n        @state = :end_value\n        if @stack.pop == type\n          case type\n          when :object\n            notify(:end_object)\n          when :array\n            notify(:end_array)\n          end",
    "comment": "Complete an object or array container value type.  type - The Symbol, :object or :array, of the expected type.  Raises a JSON::Stream::ParserError if the expected container type was not completed.  Returns nothing.",
    "label": "",
    "id": "485"
  },
  {
    "raw_code": "def notify_end_document\n        @state = :end_document\n        notify(:end_document)\n      end",
    "comment": "Broadcast an `end_document` event to observers after a complete JSON value document (object, array, number, string, true, false, null) has been parsed from the text. This is the final event sent to observers and signals the parse has finished.  Returns nothing.",
    "label": "",
    "id": "486"
  },
  {
    "raw_code": "def keyword(word, value, re, ch)\n        if ch =~ re\n          @buf << ch\n        else\n          error(\"Expected #{word} keyword\")\n        end",
    "comment": "Parse one of the three allowed keywords: true, false, null.  word  - The String keyword ('true', 'false', 'null'). value - The Ruby value (true, false, nil). re    - The Regexp of allowed keyword characters. ch    - The current String character being parsed.  Raises a JSON::Stream::ParserError if the character does not belong in the expected keyword.  Returns nothing.",
    "label": "",
    "id": "487"
  },
  {
    "raw_code": "def start_value(ch)\n        case ch\n        when LEFT_BRACE\n          notify(:start_document) if @stack.empty?\n          @state = :start_object\n          @stack.push(:object)\n          notify(:start_object)\n        when LEFT_BRACKET\n          notify(:start_document) if @stack.empty?\n          @state = :start_array\n          @stack.push(:array)\n          notify(:start_array)\n        when QUOTE\n          @state = :start_string\n          @stack.push(:string)\n        when T\n          @state = :start_true\n          @buf << ch\n        when F\n          @state = :start_false\n          @buf << ch\n        when N\n          @state = :start_null\n          @buf << ch\n        when MINUS\n          @state = :start_negative_number\n          @buf << ch\n        when ZERO\n          @state = :start_zero\n          @buf << ch\n        when DIGIT_1_9\n          @state = :start_int\n          @buf << ch\n        when WS\n          # ignore\n        else\n          error(\"Expected value\")\n        end",
    "comment": "Process the first character of one of the seven possible JSON values: object, array, string, true, false, null, number.  ch - The current character String.  Raises a JSON::Stream::ParserError if the character does not signal the start of a value.  Returns nothing.",
    "label": "",
    "id": "488"
  },
  {
    "raw_code": "def end_value(value)\n        @state = :end_value\n        notify(:start_document) if @stack.empty?\n        notify(:value, value)\n        notify_end_document if @stack.empty?\n      end",
    "comment": "Advance the state machine and notify `value` observers that a string, number or keyword (true, false, null) value was parsed.  value - The object to broadcast to observers.  Returns nothing.",
    "label": "",
    "id": "489"
  },
  {
    "raw_code": "def compress_messages_buffer(buffer, max_uploads:)\n        compressed = []\n        current_text = +\"\"\n        upload_count = 0\n\n        buffer.each do |item|\n          if item.is_a?(String)\n            current_text << item\n          elsif item.is_a?(Hash)\n            compressed << current_text if current_text.present?\n            compressed << item\n            current_text = +\"\"\n            upload_count += 1\n          end",
    "comment": "caps uploads to maximum uploads allowed in message stream and concats string elements",
    "label": "",
    "id": "490"
  },
  {
    "raw_code": "def generate(\n        prompt,\n        temperature: nil,\n        top_p: nil,\n        max_tokens: nil,\n        stop_sequences: nil,\n        user:,\n        feature_name: nil,\n        feature_context: nil,\n        partial_tool_calls: false,\n        output_thinking: false,\n        response_format: nil,\n        extra_model_params: nil,\n        cancel_manager: nil,\n        &partial_read_blk\n      )\n        self.class.record_prompt(\n          prompt,\n          {\n            temperature: temperature,\n            top_p: top_p,\n            max_tokens: max_tokens,\n            stop_sequences: stop_sequences,\n            user: user,\n            feature_name: feature_name,\n            feature_context: feature_context,\n            partial_tool_calls: partial_tool_calls,\n            output_thinking: output_thinking,\n            response_format: response_format,\n            extra_model_params: extra_model_params,\n          },\n        )\n\n        model_params = { max_tokens: max_tokens, stop_sequences: stop_sequences }\n\n        model_params[:temperature] = temperature if temperature\n        model_params[:top_p] = top_p if top_p\n\n        # internals expect symbolized keys, so we normalize here\n        response_format =\n          JSON.parse(response_format.to_json, symbolize_names: true) if response_format &&\n          response_format.is_a?(Hash)\n\n        model_params[:response_format] = response_format if response_format\n        model_params.merge!(extra_model_params) if extra_model_params\n\n        if prompt.is_a?(String)\n          prompt =\n            DiscourseAi::Completions::Prompt.new(\n              \"You are a helpful bot\",\n              messages: [{ type: :user, content: prompt }],\n            )\n        elsif prompt.is_a?(Array)\n          prompt = DiscourseAi::Completions::Prompt.new(messages: prompt)\n        end",
    "comment": "@param generic_prompt { DiscourseAi::Completions::Prompt } - Our generic prompt object @param user { User } - User requesting the summary. @param temperature { Float - Optional } - The temperature to use for the completion. @param top_p { Float - Optional } - The top_p to use for the completion. @param max_tokens { Integer - Optional } - The maximum number of tokens to generate. @param stop_sequences { Array<String> - Optional } - The stop sequences to use for the completion. @param feature_name { String - Optional } - The feature name to use for the completion. @param feature_context { Hash - Optional } - The feature context to use for the completion. @param partial_tool_calls { Boolean - Optional } - If true, the completion will return partial tool calls. @param output_thinking { Boolean - Optional } - If true, the completion will return the thinking output for thinking models. @param response_format { Hash - Optional } - JSON schema passed to the API as the desired structured output. @param [Experimental] extra_model_params { Hash - Optional } - Other params that are not available accross models. e.g. response_format JSON schema.  @param &on_partial_blk { Block - Optional } - The passed block will get called with the LLM partial response.  @returns String | ToolCall - Completion result. if multiple tools or a tool and a message come back, the result will be an array of ToolCall / String objects. ",
    "label": "",
    "id": "491"
  },
  {
    "raw_code": "def push_model_response(response)\n        response = [response] if !response.is_a? Array\n\n        thinking, thinking_signature, redacted_thinking_signature = nil\n\n        response.each do |message|\n          if message.is_a?(Thinking)\n            # we can safely skip partials here\n            next if message.partial?\n            if message.redacted\n              redacted_thinking_signature = message.signature\n            else\n              thinking = message.message\n              thinking_signature = message.signature\n            end",
    "comment": "this new api tries to create symmetry between responses and prompts this means anything we get back from the model via endpoint can be easily appended",
    "label": "",
    "id": "492"
  },
  {
    "raw_code": "def normalize_model_params(model_params)\n          raise NotImplementedError\n        end",
    "comment": "should normalize temperature, max_tokens, stop_words to endpoint specific values",
    "label": "",
    "id": "493"
  },
  {
    "raw_code": "def prompt_size(prompt)\n          tokenizer.size(prompt.system_prompt.to_s + \" \" + prompt.messages.to_s)\n        end",
    "comment": "this is an approximation, we will update it later if request goes through",
    "label": "",
    "id": "494"
  },
  {
    "raw_code": "def no_array_if_only_text(content_array)\n          if content_array.length == 1 && content_array.first[:type] == \"text\"\n            content_array.first[:text]\n          else\n            content_array\n          end",
    "comment": "keeping our payload as backward compatible as possible",
    "label": "",
    "id": "495"
  },
  {
    "raw_code": "def strip_upload_markdown_mode\n          :none\n        end",
    "comment": "supported options are :none/:all/:model_only",
    "label": "",
    "id": "496"
  },
  {
    "raw_code": "def supports_developer_messages?\n          !legacy_reasoning_model? && llm_model.provider == \"open_ai\" &&\n            (\n              llm_model.name.start_with?(\"o1\") || llm_model.name.start_with?(\"o3\") ||\n                llm_model.name.start_with?(\"gpt-5\")\n            )\n        end",
    "comment": "developer messages are preferred on recent reasoning models",
    "label": "",
    "id": "497"
  },
  {
    "raw_code": "def instructions\n          \"\"\n        end",
    "comment": "nativ tools require no system instructions",
    "label": "",
    "id": "498"
  },
  {
    "raw_code": "def list_concepts(limit: nil)\n        query = InferredConcept.all.order(\"name ASC\")\n\n        # Apply limit if provided\n        query = query.limit(limit) if limit.present?\n\n        query.pluck(:name)\n      end",
    "comment": "Get a list of existing concepts @param limit [Integer, nil] Optional maximum number of concepts to return @return [Array<InferredConcept>] Array of InferredConcept objects",
    "label": "",
    "id": "499"
  },
  {
    "raw_code": "def deduplicate_concepts_by_letter(per_letter_batch: 50, full_pass_batch: 150)\n        # Get all concepts\n        all_concepts = list_concepts\n        return if all_concepts.empty?\n\n        letter_groups = Hash.new { |h, k| h[k] = [] }\n\n        # Group concepts by first letter\n        all_concepts.each do |concept|\n          first_char = concept[0]&.upcase\n\n          if first_char && first_char.match?(/[A-Z]/)\n            letter_groups[first_char] << concept\n          else\n            # Non-alphabetic or empty concepts go in a special group\n            letter_groups[\"#\"] << concept\n          end",
    "comment": "Deduplicate concepts in batches by letter This method will: 1. Group concepts by first letter 2. Process each letter group separately through the deduplicator 3. Do a final pass with all deduplicated concepts @return [Hash] Statistics about the deduplication process",
    "label": "",
    "id": "500"
  },
  {
    "raw_code": "def identify_concepts(content)\n        DiscourseAi::InferredConcepts::Finder.new.identify_concepts(content)\n      end",
    "comment": "Extract new concepts from arbitrary content @param content [String] The content to analyze @return [Array<String>] The identified concept names",
    "label": "",
    "id": "501"
  },
  {
    "raw_code": "def generate_concepts_from_content(content)\n        return [] if content.blank?\n\n        # Identify concepts\n        finder = DiscourseAi::InferredConcepts::Finder.new\n        concept_names = finder.identify_concepts(content)\n        return [] if concept_names.blank?\n\n        # Create or find concepts in the database\n        finder.create_or_find_concepts(concept_names)\n      end",
    "comment": "Identify and create concepts from content without applying them to any topic @param content [String] The content to analyze @return [Array<InferredConcept>] The created or found concepts",
    "label": "",
    "id": "502"
  },
  {
    "raw_code": "def generate_concepts_from_topic(topic)\n        return [] if topic.blank?\n\n        # Get content to analyze\n        applier = DiscourseAi::InferredConcepts::Applier.new\n        content = applier.topic_content_for_analysis(topic)\n        return [] if content.blank?\n\n        # Generate concepts from the content\n        generate_concepts_from_content(content)\n      end",
    "comment": "Generate concepts from a topic's content without applying them to the topic @param topic [Topic] A Topic instance @return [Array<InferredConcept>] The created or found concepts",
    "label": "",
    "id": "503"
  },
  {
    "raw_code": "def generate_concepts_from_post(post)\n        return [] if post.blank?\n\n        # Get content to analyze\n        applier = DiscourseAi::InferredConcepts::Applier.new\n        content = applier.post_content_for_analysis(post)\n        return [] if content.blank?\n\n        # Generate concepts from the content\n        generate_concepts_from_content(content)\n      end",
    "comment": "Generate concepts from a post's content without applying them to the post @param post [Post] A Post instance @return [Array<InferredConcept>] The created or found concepts",
    "label": "",
    "id": "504"
  },
  {
    "raw_code": "def match_topic_to_concepts(topic)\n        return [] if topic.blank?\n\n        DiscourseAi::InferredConcepts::Applier.new.match_existing_concepts(topic)\n      end",
    "comment": "Match a topic against existing concepts @param topic [Topic] A Topic instance @return [Array<InferredConcept>] The concepts that were applied",
    "label": "",
    "id": "505"
  },
  {
    "raw_code": "def match_post_to_concepts(post)\n        return [] if post.blank?\n\n        DiscourseAi::InferredConcepts::Applier.new.match_existing_concepts_for_post(post)\n      end",
    "comment": "Match a post against existing concepts @param post [Post] A Post instance @return [Array<InferredConcept>] The concepts that were applied",
    "label": "",
    "id": "506"
  },
  {
    "raw_code": "def search_topics_by_concept(concept_name)\n        concept = ::InferredConcept.find_by(name: concept_name)\n        return [] unless concept\n        concept.topics\n      end",
    "comment": "Find topics that have a specific concept @param concept_name [String] The name of the concept to search for @return [Array<Topic>] Topics that have the specified concept",
    "label": "",
    "id": "507"
  },
  {
    "raw_code": "def search_posts_by_concept(concept_name)\n        concept = ::InferredConcept.find_by(name: concept_name)\n        return [] unless concept\n        concept.posts\n      end",
    "comment": "Find posts that have a specific concept @param concept_name [String] The name of the concept to search for @return [Array<Post>] Posts that have the specified concept",
    "label": "",
    "id": "508"
  },
  {
    "raw_code": "def match_content_to_concepts(content)\n        existing_concepts = InferredConcept.all.pluck(:name)\n        return [] if existing_concepts.empty?\n\n        DiscourseAi::InferredConcepts::Applier.new.match_concepts_to_content(\n          content,\n          existing_concepts,\n        )\n      end",
    "comment": "Match arbitrary content against existing concepts @param content [String] The content to analyze @return [Array<String>] Names of matching concepts",
    "label": "",
    "id": "509"
  },
  {
    "raw_code": "def find_candidate_topics(opts = {})\n        DiscourseAi::InferredConcepts::Finder.new.find_candidate_topics(**opts)\n      end",
    "comment": "Find candidate topics that are good for concept generation  @param opts [Hash] Options to pass to the finder @option opts [Integer] :limit (100) Maximum number of topics to return @option opts [Integer] :min_posts (5) Minimum number of posts in topic @option opts [Integer] :min_likes (10) Minimum number of likes across all posts @option opts [Integer] :min_views (100) Minimum number of views @option opts [Array<Integer>] :exclude_topic_ids ([]) Topic IDs to exclude @option opts [Array<Integer>] :category_ids (nil) Only include topics from these categories @option opts [DateTime] :created_after (30.days.ago) Only include topics created after this time @return [Array<Topic>] Array of Topic objects that are good candidates",
    "label": "",
    "id": "510"
  },
  {
    "raw_code": "def find_candidate_posts(opts = {})\n        DiscourseAi::InferredConcepts::Finder.new.find_candidate_posts(**opts)\n      end",
    "comment": "Find candidate posts that are good for concept generation @param opts [Hash] Options to pass to the finder @return [Array<Post>] Array of Post objects that are good candidates",
    "label": "",
    "id": "511"
  },
  {
    "raw_code": "def apply_to_topic(topic, concepts)\n        return if topic.blank? || concepts.blank?\n\n        topic.inferred_concepts << concepts\n      end",
    "comment": "Associates the provided concepts with a topic topic: a Topic instance concepts: an array of InferredConcept instances",
    "label": "",
    "id": "512"
  },
  {
    "raw_code": "def apply_to_post(post, concepts)\n        return if post.blank? || concepts.blank?\n\n        post.inferred_concepts << concepts\n      end",
    "comment": "Associates the provided concepts with a post post: a Post instance concepts: an array of InferredConcept instances",
    "label": "",
    "id": "513"
  },
  {
    "raw_code": "def topic_content_for_analysis(topic)\n        return \"\" if topic.blank?\n\n        # Combine title and first few posts for analysis\n        posts = Post.where(topic_id: topic.id).order(:post_number).limit(10)\n\n        content = \"Title: #{topic.title}\\n\\n\"\n        content += posts.map { |p| \"#{p.post_number}) #{p.user.username}: #{p.raw}\" }.join(\"\\n\\n\")\n\n        content\n      end",
    "comment": "Extracts content from a topic for concept analysis Returns a string with the topic title and first few posts",
    "label": "",
    "id": "514"
  },
  {
    "raw_code": "def post_content_for_analysis(post)\n        return \"\" if post.blank?\n\n        # Get the topic title for context\n        topic_title = post.topic&.title || \"\"\n\n        content = \"Topic: #{topic_title}\\n\\n\"\n        content += \"Post by #{post.user.username}:\\n#{post.raw}\"\n\n        content\n      end",
    "comment": "Extracts content from a post for concept analysis Returns a string with the post content",
    "label": "",
    "id": "515"
  },
  {
    "raw_code": "def match_existing_concepts(topic)\n        return [] if topic.blank?\n\n        # Get content to analyze\n        content = topic_content_for_analysis(topic)\n\n        # Get all existing concepts\n        existing_concepts = DiscourseAi::InferredConcepts::Manager.new.list_concepts\n        return [] if existing_concepts.empty?\n\n        # Use the ConceptMatcher persona to match concepts\n        matched_concept_names = match_concepts_to_content(content, existing_concepts)\n\n        # Find concepts in the database\n        matched_concepts = InferredConcept.where(name: matched_concept_names)\n\n        # Apply concepts to the topic\n        apply_to_topic(topic, matched_concepts)\n\n        matched_concepts\n      end",
    "comment": "Match a topic with existing concepts",
    "label": "",
    "id": "516"
  },
  {
    "raw_code": "def match_existing_concepts_for_post(post)\n        return [] if post.blank?\n\n        # Get content to analyze\n        content = post_content_for_analysis(post)\n\n        # Get all existing concepts\n        existing_concepts = DiscourseAi::InferredConcepts::Manager.new.list_concepts\n        return [] if existing_concepts.empty?\n\n        # Use the ConceptMatcher persona to match concepts\n        matched_concept_names = match_concepts_to_content(content, existing_concepts)\n\n        # Find concepts in the database\n        matched_concepts = InferredConcept.where(name: matched_concept_names)\n\n        # Apply concepts to the post\n        apply_to_post(post, matched_concepts)\n\n        matched_concepts\n      end",
    "comment": "Match a post with existing concepts",
    "label": "",
    "id": "517"
  },
  {
    "raw_code": "def match_concepts_to_content(content, concept_list)\n        return [] if content.blank? || concept_list.blank?\n\n        # Prepare user message with only the content\n        user_message = content\n\n        # Use the ConceptMatcher persona to match concepts\n\n        persona =\n          AiPersona\n            .all_personas(enabled_only: false)\n            .find { |p| p.id == SiteSetting.inferred_concepts_match_persona.to_i }\n            .new\n\n        llm = LlmModel.find(persona.class.default_llm_id)\n\n        input = { type: :user, content: content }\n\n        context =\n          DiscourseAi::Personas::BotContext.new(\n            messages: [input],\n            user: Discourse.system_user,\n            inferred_concepts: concept_list,\n          )\n\n        bot = DiscourseAi::Personas::Bot.as(Discourse.system_user, persona: persona, model: llm)\n        structured_output = nil\n\n        bot.reply(context) do |partial, _, type|\n          structured_output = partial if type == :structured_output\n        end",
    "comment": "Use ConceptMatcher persona to match content against provided concepts",
    "label": "",
    "id": "518"
  },
  {
    "raw_code": "def identify_concepts(content)\n        return [] if content.blank?\n\n        # Use the ConceptFinder persona to identify concepts\n        persona =\n          AiPersona\n            .all_personas(enabled_only: false)\n            .find { |p| p.id == SiteSetting.inferred_concepts_generate_persona.to_i }\n            .new\n\n        llm = LlmModel.find(persona.class.default_llm_id)\n        context =\n          DiscourseAi::Personas::BotContext.new(\n            messages: [{ type: :user, content: content }],\n            user: Discourse.system_user,\n            inferred_concepts: DiscourseAi::InferredConcepts::Manager.new.list_concepts,\n          )\n\n        bot = DiscourseAi::Personas::Bot.as(Discourse.system_user, persona: persona, model: llm)\n        structured_output = nil\n\n        bot.reply(context) do |partial, _, type|\n          structured_output = partial if type == :structured_output\n        end",
    "comment": "Identifies potential concepts from provided content Returns an array of concept names (strings)",
    "label": "",
    "id": "519"
  },
  {
    "raw_code": "def create_or_find_concepts(concept_names)\n        return [] if concept_names.blank?\n\n        concept_names.map { |name| InferredConcept.find_or_create_by(name: name) }\n      end",
    "comment": "Creates or finds concepts in the database from provided names Returns an array of InferredConcept instances",
    "label": "",
    "id": "520"
  },
  {
    "raw_code": "def find_candidate_topics(\n        limit: 100,\n        min_posts: 5,\n        min_likes: 10,\n        min_views: 100,\n        exclude_topic_ids: [],\n        category_ids: nil,\n        created_after: 30.days.ago\n      )\n        query =\n          Topic.where(\n            \"topics.posts_count >= ? AND topics.views >= ? AND topics.like_count >= ?\",\n            min_posts,\n            min_views,\n            min_likes,\n          )\n\n        # Apply additional filters\n        query = query.where(\"topics.id NOT IN (?)\", exclude_topic_ids) if exclude_topic_ids.present?\n        query = query.where(\"topics.category_id IN (?)\", category_ids) if category_ids.present?\n        query = query.where(\"topics.created_at >= ?\", created_after) if created_after.present?\n\n        # Exclude PM topics (if they exist in Discourse)\n        query = query.where(archetype: Archetype.default)\n\n        # Exclude topics that already have concepts\n        topics_with_concepts = <<~SQL\n          SELECT DISTINCT topic_id\n          FROM inferred_concept_topics\n        SQL\n\n        query = query.where(\"topics.id NOT IN (#{topics_with_concepts})\")\n\n        # Score and order topics by engagement (combination of views, likes, and posts)\n        query =\n          query.select(\n            \"topics.*,\n          (topics.like_count * 2 + topics.posts_count * 3 + topics.views * 0.1) AS engagement_score\",\n          ).order(\"engagement_score DESC\")\n\n        # Return limited number of topics\n        query.limit(limit)\n      end",
    "comment": "Finds candidate topics to use for concept generation  @param limit [Integer] Maximum number of topics to return @param min_posts [Integer] Minimum number of posts in topic @param min_likes [Integer] Minimum number of likes across all posts @param min_views [Integer] Minimum number of views @param exclude_topic_ids [Array<Integer>] Topic IDs to exclude @param category_ids [Array<Integer>] Only include topics from these categories (optional) @param created_after [DateTime] Only include topics created after this time (optional) @return [Array<Topic>] Array of Topic objects that are good candidates",
    "label": "",
    "id": "521"
  },
  {
    "raw_code": "def find_candidate_posts(\n        limit: 100,\n        min_likes: 5,\n        exclude_first_posts: true,\n        exclude_post_ids: [],\n        category_ids: nil,\n        created_after: 30.days.ago\n      )\n        query = Post.where(\"posts.like_count >= ?\", min_likes)\n\n        # Exclude first posts if specified\n        query = query.where(\"posts.post_number > 1\") if exclude_first_posts\n\n        # Apply additional filters\n        query = query.where(\"posts.id NOT IN (?)\", exclude_post_ids) if exclude_post_ids.present?\n        query = query.where(\"posts.created_at >= ?\", created_after) if created_after.present?\n\n        # Filter by category if specified\n        if category_ids.present?\n          query = query.joins(:topic).where(\"topics.category_id IN (?)\", category_ids)\n        end",
    "comment": "Find candidate posts that are good for concept generation  @param limit [Integer] Maximum number of posts to return @param min_likes [Integer] Minimum number of likes @param exclude_first_posts [Boolean] Exclude first posts in topics @param exclude_post_ids [Array<Integer>] Post IDs to exclude @param category_ids [Array<Integer>] Only include posts from topics in these categories @param created_after [DateTime] Only include posts created after this time @return [Array<Post>] Array of Post objects that are good candidates",
    "label": "",
    "id": "522"
  },
  {
    "raw_code": "def deduplicate_concepts(concept_names)\n        return { deduplicated_concepts: [], mapping: {} } if concept_names.blank?\n\n        # Use the ConceptDeduplicator persona to deduplicate concepts\n        persona =\n          AiPersona\n            .all_personas(enabled_only: false)\n            .find { |p| p.id == SiteSetting.inferred_concepts_deduplicate_persona.to_i }\n            .new\n\n        llm = LlmModel.find(persona.class.default_llm_id)\n\n        # Create the input for the deduplicator\n        input = { type: :user, content: concept_names.join(\", \") }\n\n        context =\n          DiscourseAi::Personas::BotContext.new(messages: [input], user: Discourse.system_user)\n\n        bot = DiscourseAi::Personas::Bot.as(Discourse.system_user, persona: persona, model: llm)\n        structured_output = nil\n\n        bot.reply(context) do |partial, _, type|\n          structured_output = partial if type == :structured_output\n        end",
    "comment": "Deduplicate and standardize a list of concepts @param concept_names [Array<String>] List of concept names to deduplicate @return [Hash] Hash with deduplicated concepts and mapping",
    "label": "",
    "id": "523"
  },
  {
    "raw_code": "def self.get\n        categories = Category.all\n        if SiteSetting.ai_translation_backfill_limit_to_public_content\n          categories = categories.where(read_restricted: false)\n        end",
    "comment": "all categories that are eligible for translation based on site settings, including those without locale detected yet.",
    "label": "",
    "id": "524"
  },
  {
    "raw_code": "def self.get\n        topics =\n          Topic\n            .where(\n              \"topics.created_at > ?\",\n              SiteSetting.ai_translation_backfill_max_age_days.days.ago,\n            )\n            .where(deleted_at: nil)\n            .where(\"topics.user_id > 0\")\n\n        if SiteSetting.ai_translation_backfill_limit_to_public_content\n          # exclude all PMs\n          # and only include topics from public categories\n          topics =\n            topics\n              .where.not(archetype: Archetype.private_message)\n              .where(category_id: Category.where(read_restricted: false).select(:id))\n        else\n          # all regular topics, and group PMs\n          topics =\n            topics.where(\n              \"topics.archetype != ? OR topics.id IN (SELECT topic_id FROM topic_allowed_groups)\",\n              Archetype.private_message,\n            )\n        end",
    "comment": "all topics that are eligible for translation based on site settings, including those without locale detected yet.",
    "label": "",
    "id": "525"
  },
  {
    "raw_code": "def self.get\n        raise NotImplementedError\n      end",
    "comment": "ModelType that are eligible for translation based on site settings @return [ActiveRecord::Relation] the ActiveRecord relation of the candidates",
    "label": "",
    "id": "526"
  },
  {
    "raw_code": "def self.get_total_and_with_locale_count\n        Discourse\n          .cache\n          .fetch(get_total_cache_key, expires_in: CACHE_TTL) do\n            total, with_locale = total_and_with_locale_count\n            return { total: 0, posts_with_detected_locale: 0 } if total.zero?\n            { total:, posts_with_detected_locale: with_locale }\n          end",
    "comment": "Returns the total number of candidates and the number of candidates that have a detected locale. The values are cached and provides an overview of how many posts are eligible for translation and how many have been detected with a locale. @return [Hash] a hash with keys :total and :posts_with_detected_locale",
    "label": "",
    "id": "527"
  },
  {
    "raw_code": "def self.get_completion_all_locales\n        Discourse\n          .cache\n          .fetch(get_completion_cache_key, expires_in: CACHE_TTL) { completion_all_locales }\n      end",
    "comment": "Returns the number of posts that have been translated, and the total number of posts that need translation for a given locale. The total number of posts is based off candidates that already have a locale. @param locale [String] the locale for which to calculate the completion percentage @return [Hash] a hash with keys :done and :total",
    "label": "",
    "id": "528"
  },
  {
    "raw_code": "def self.get\n        posts =\n          Post\n            .where(\n              \"posts.created_at > ?\",\n              SiteSetting.ai_translation_backfill_max_age_days.days.ago,\n            )\n            .where(deleted_at: nil)\n            .where(\"posts.user_id > 0\")\n            .where.not(raw: [nil, \"\"])\n\n        posts = posts.joins(:topic)\n        if SiteSetting.ai_translation_backfill_limit_to_public_content\n          # exclude all PMs\n          # and only include posts from public categories\n          posts =\n            posts\n              .where.not(topics: { archetype: Archetype.private_message })\n              .where(topics: { category_id: Category.where(read_restricted: false).select(:id) })\n        else\n          # all regular topics, and group PMs\n          posts =\n            posts.where(\n              \"topics.archetype != ? OR topics.id IN (SELECT topic_id FROM topic_allowed_groups)\",\n              Archetype.private_message,\n            )\n        end",
    "comment": "all posts that are eligible for translation based on site settings, including those without locale detected yet.",
    "label": "",
    "id": "529"
  },
  {
    "raw_code": "def self.perform_sd3!(\n        prompt,\n        aspect_ratio: nil,\n        api_key: nil,\n        engine: nil,\n        api_url: nil,\n        output_format: \"png\",\n        seed: nil\n      )\n        api_key ||= SiteSetting.ai_stability_api_key\n        engine ||= SiteSetting.ai_stability_engine\n        api_url ||= SiteSetting.ai_stability_api_url\n\n        allowed_ratios = %w[16:9 1:1 21:9 2:3 3:2 4:5 5:4 9:16 9:21]\n\n        aspect_ratio = \"1:1\" if !aspect_ratio || !allowed_ratios.include?(aspect_ratio)\n\n        payload = {\n          prompt: prompt,\n          mode: \"text-to-image\",\n          model: engine,\n          output_format: output_format,\n          aspect_ratio: aspect_ratio,\n        }\n\n        payload[:seed] = seed if seed\n\n        endpoint = \"v2beta/stable-image/generate/sd3\"\n\n        form_data = payload.to_a.map { |k, v| [k.to_s, v.to_s] }\n\n        uri = URI(\"#{api_url}/#{endpoint}\")\n        request = FinalDestination::HTTP::Post.new(uri)\n\n        request[\"authorization\"] = \"Bearer #{api_key}\"\n        request[\"accept\"] = \"application/json\"\n        request[\"User-Agent\"] = DiscourseAi::AiBot::USER_AGENT\n        request.set_form form_data, \"multipart/form-data\"\n\n        response =\n          FinalDestination::HTTP.start(\n            uri.hostname,\n            uri.port,\n            use_ssl: uri.port != 80,\n            read_timeout: TIMEOUT,\n            open_timeout: TIMEOUT,\n            write_timeout: TIMEOUT,\n          ) { |http| http.request(request) }\n\n        if response.code != \"200\"\n          Rails.logger.error(\n            \"AI stability generator failed with status #{response.code}: #{response.body}}\",\n          )\n          raise Net::HTTPBadResponse\n        end",
    "comment": "there is a new api for sd3",
    "label": "",
    "id": "530"
  },
  {
    "raw_code": "def self.create_edited_upload!(\n        images,\n        prompt,\n        model: \"gpt-image-1\",\n        size: \"auto\",\n        api_key: nil,\n        api_url: nil,\n        user_id:,\n        for_private_message: false,\n        n: 1,\n        quality: nil,\n        cancel_manager: nil\n      )\n        api_response =\n          edit_images(\n            images,\n            prompt,\n            model: model,\n            size: size,\n            api_key: api_key,\n            api_url: api_url,\n            n: n,\n            quality: quality,\n            cancel_manager: cancel_manager,\n          )\n\n        create_uploads_from_responses([api_response], user_id, for_private_message).first\n      end",
    "comment": "Method for image editing that returns Upload objects",
    "label": "",
    "id": "531"
  },
  {
    "raw_code": "def self.create_uploads_from_responses(\n        api_responses,\n        user_id,\n        for_private_message,\n        title = nil\n      )\n        all_uploads = []\n\n        api_responses.each do |response|\n          next unless response\n\n          response[:data].each_with_index do |image, index|\n            Tempfile.create(\"ai_image_#{index}.png\") do |file|\n              file.binmode\n              file.write(Base64.decode64(image[:b64_json]))\n              file.rewind\n\n              upload =\n                UploadCreator.new(\n                  file,\n                  title || \"image.png\",\n                  for_private_message: for_private_message,\n                ).create_for(user_id)\n\n              all_uploads << {\n                # Use revised_prompt if available (DALL-E 3), otherwise use original prompt\n                prompt: image[:revised_prompt] || response[:original_prompt],\n                upload: upload,\n              }\n            end",
    "comment": "Common method to create uploads from API responses",
    "label": "",
    "id": "532"
  },
  {
    "raw_code": "def self.perform_generation_api_call!(\n        prompt,\n        model:,\n        size: nil,\n        api_key: nil,\n        api_url: nil,\n        n: 1,\n        quality: nil,\n        style: nil,\n        background: nil,\n        moderation: nil,\n        output_compression: nil,\n        output_format: nil,\n        cancel_manager: nil\n      )\n        api_key ||= SiteSetting.ai_openai_api_key\n        api_url ||= SiteSetting.ai_openai_image_generation_url\n\n        uri = URI(api_url)\n        headers = { \"Content-Type\" => \"application/json\" }\n\n        if uri.host.include?(\"azure\")\n          headers[\"api-key\"] = api_key\n        else\n          headers[\"Authorization\"] = \"Bearer #{api_key}\"\n        end",
    "comment": "Image generation API call method",
    "label": "",
    "id": "533"
  },
  {
    "raw_code": "def summarize(user, &on_partial_blk)\n        truncated_content = content_to_summarize.map { |cts| truncate(cts) }\n\n        summary = fold(truncated_content, user, &on_partial_blk)\n\n        if persist_summaries\n          AiSummary.store!(strategy, llm_model, summary, truncated_content, human: user&.human?)\n        else\n          AiSummary.new(summarized_text: summary)\n        end",
    "comment": "@param user { User } - User object used for auditing usage. @param &on_partial_blk { Block - Optional } - The passed block will get called with the LLM partial response. Note: The block is only called with results of the final summary, not intermediate summaries.  This method doesn't care if we already have an up to date summary. It always regenerate.  @returns { AiSummary } - Resulting summary.",
    "label": "",
    "id": "534"
  },
  {
    "raw_code": "def existing_summary\n        if !defined?(@existing_summary)\n          summary = AiSummary.find_by(target: strategy.target, summary_type: strategy.type)\n\n          if summary\n            @existing_summary = summary\n\n            if summary.original_content_sha != latest_sha ||\n                 content_to_summarize.any? { |cts| cts[:last_version_at] > summary.updated_at }\n              summary.mark_as_outdated\n            end",
    "comment": "@returns { AiSummary } - Resulting summary.  Finds a summary matching the target and strategy. Marks it as outdated if the strategy found newer content",
    "label": "",
    "id": "535"
  },
  {
    "raw_code": "def fold(items, user, &on_partial_blk)\n        tokenizer = llm_model.tokenizer_class\n        tokens_left = available_tokens\n        content_in_window = []\n\n        items.each_with_index do |item, idx|\n          as_text = \"(#{item[:id]} #{item[:poster]} said: #{item[:text]} \"\n\n          if tokenizer.below_limit?(\n               as_text,\n               tokens_left,\n               strict: SiteSetting.ai_strict_token_counting,\n             )\n            content_in_window << item\n            tokens_left -= tokenizer.size(as_text)\n          else\n            break\n          end",
    "comment": "@param items { Array<Hash> } - Content to summarize. Structure will be: { poster: who wrote the content, id: a way to order content, text: content } @param user { User } - User object used for auditing usage. @param &on_partial_blk { Block - Optional } - The passed block will get called with the LLM partial response. Note: The block is only called with results of the final summary, not intermediate summaries.  The summarization algorithm. It will summarize as much content summarize given the model's context window. If will prioriotize newer content in case it doesn't fit.  @returns { String } - Resulting summary.",
    "label": "",
    "id": "536"
  },
  {
    "raw_code": "def type\n          raise NotImplementedError\n        end",
    "comment": "The summary type differentiates instances of `AiSummary` pointing to a single target. See the `summary_type` enum for available options.",
    "label": "",
    "id": "537"
  },
  {
    "raw_code": "def targets_data\n          raise NotImplementedError\n        end",
    "comment": "@returns { Array<Hash> } - Content to summarize.  This method returns an array of hashes with the content to summarize using the following structure:  { poster: A way to tell who write the content, id: A number to signal order, text: Text to summarize } ",
    "label": "",
    "id": "538"
  },
  {
    "raw_code": "def as_llm_messages(_input)\n          raise NotImplementedError\n        end",
    "comment": "@returns { Array } - Prompt messages to send to the LLM for summarizing content.",
    "label": "",
    "id": "539"
  },
  {
    "raw_code": "def feature\n          \"summarize\"\n        end",
    "comment": "We'll pass this as the feature_name when doing LLM calls.",
    "label": "",
    "id": "540"
  },
  {
    "raw_code": "def self.find_chat_persona(message, channel, user)\n        if channel.direct_message_channel?\n          AiPersona\n            .allowed_modalities(allow_chat_direct_messages: true)\n            .find do |p|\n              p[:user_id].in?(channel.allowed_user_ids) && (user.group_ids & p[:allowed_group_ids])\n            end",
    "comment": "An abstraction to manage the bot and topic interactions. The bot will take care of completions while this class updates the topic title and stream replies.",
    "label": "",
    "id": "541"
  },
  {
    "raw_code": "def self.ai_share_error(topic, guardian)\n        return nil if guardian.can_share_ai_bot_conversation?(topic)\n\n        return :not_allowed if !guardian.can_see?(topic)\n\n        # other people in PM\n        if topic.topic_allowed_users.where(\"user_id > 0 and user_id <> ?\", guardian.user.id).exists?\n          return :other_people_in_pm\n        end",
    "comment": "Most errors are simply \"not_allowed\" we do not want to reveal information about this system the 2 exceptions are \"other_people_in_pm\" and \"other_content_in_pm\" in both cases you have access to the PM so we are not revealing anything",
    "label": "",
    "id": "542"
  },
  {
    "raw_code": "def self.on_callback=(on_callback)\n        @on_callback = on_callback\n      end",
    "comment": "test only",
    "label": "",
    "id": "543"
  },
  {
    "raw_code": "def queue_streamed_reply(\n          io:,\n          persona:,\n          user:,\n          topic:,\n          query:,\n          custom_instructions:,\n          current_user:\n        )\n          schedule_block do\n            begin\n              post_params = {\n                raw: query,\n                skip_validations: true,\n                custom_fields: {\n                  DiscourseAi::AiBot::Playground::BYPASS_AI_REPLY_CUSTOM_FIELD => true,\n                },\n              }\n\n              if topic\n                post_params[:topic_id] = topic.id\n              else\n                post_params[:title] = I18n.t(\"discourse_ai.ai_bot.default_pm_prefix\")\n                post_params[:archetype] = Archetype.private_message\n                post_params[:target_usernames] = \"#{user.username},#{persona.user.username}\"\n              end",
    "comment": "keeping this in a static method so we don't capture ENV and other bits this allows us to release memory earlier",
    "label": "",
    "id": "544"
  },
  {
    "raw_code": "def attach_sleep(mini_racer_context)\n        mini_racer_context.attach(\n          \"sleep\",\n          ->(duration_ms) do\n            @sleep_calls_made += 1\n            if @sleep_calls_made > MAX_SLEEP_CALLS\n              raise TooManyRequestsError.new(\"Tool made too many sleep calls\")\n            end",
    "comment": "this is useful for polling apis",
    "label": "",
    "id": "545"
  },
  {
    "raw_code": "def self.name\n          name, tool_name = AiTool.where(id: tool_id).pluck(:name, :tool_name).first\n          tool_name.presence || name\n        end",
    "comment": "Backwards compatibility: if tool_name is not set (existing custom tools), use name",
    "label": "",
    "id": "546"
  },
  {
    "raw_code": "def has_scripts?(script_names)\n          DB\n            .query_single(\n              \"SELECT COUNT(*) FROM discourse_automation_automations WHERE script IN (:names) and enabled\",\n              names: script_names,\n            )\n            .first\n            .to_i > 0\n        end",
    "comment": "Private",
    "label": "",
    "id": "547"
  },
  {
    "raw_code": "def self.values_for_serialization(allowed_seeded_llm_ids: nil)\n        builder = DB.build(<<~SQL)\n          SELECT id, display_name AS name, vision_enabled\n          FROM llm_models\n          /*where*/\n        SQL\n\n        if allowed_seeded_llm_ids.is_a?(Array) && !allowed_seeded_llm_ids.empty?\n          builder.where(\n            \"id > 0 OR id IN (:allowed_seeded_llm_ids)\",\n            allowed_seeded_llm_ids: allowed_seeded_llm_ids,\n          )\n        else\n          builder.where(\"id > 0\")\n        end",
    "comment": "returns an array of hashes (id: , name:, vision_enabled:)",
    "label": "",
    "id": "548"
  },
  {
    "raw_code": "def fetch_setting(name)\n    DB.query_single(\n      \"SELECT value FROM site_settings WHERE name = :setting_name\",\n      setting_name: name,\n    ).first || ENV[\"DISCOURSE_#{name&.upcase}\"]\n  end",
    "comment": "Utils",
    "label": "",
    "id": "549"
  },
  {
    "raw_code": "def execute(args)\n      return if (fragments = RagDocumentFragment.where(id: args[:fragment_ids].to_a)).empty?\n\n      vector = DiscourseAi::Embeddings::Vector.instance\n\n      # generate_representation_from checks compares the digest value to make sure\n      # the embedding is only generated once per fragment unless something changes.\n      fragments.map { |fragment| vector.generate_representation_from(fragment) }\n\n      last_fragment = fragments.last\n      target = last_fragment.target\n      upload = last_fragment.upload\n\n      indexing_status = RagDocumentFragment.indexing_status(target, [upload])[upload.id]\n      RagDocumentFragment.publish_status(upload, indexing_status)\n    end",
    "comment": "we could also restrict concurrency but this takes so long if it is not concurrent",
    "label": "",
    "id": "550"
  },
  {
    "raw_code": "def execute(args)\n      return if (upload = Upload.find_by(id: args[:upload_id])).nil?\n\n      target_type = args[:target_type]\n      target_id = args[:target_id]\n\n      return if !target_type || !target_id\n\n      target = target_type.constantize.find_by(id: target_id)\n      return if !target\n\n      vector_rep = DiscourseAi::Embeddings::Vector.instance\n\n      tokenizer = vector_rep.tokenizer\n      chunk_tokens = target.rag_chunk_tokens\n      overlap_tokens = target.rag_chunk_overlap_tokens\n\n      fragment_ids = RagDocumentFragment.where(target: target, upload: upload).pluck(:id)\n\n      # Check if this is the first time we process this upload.\n      if fragment_ids.empty?\n        document = get_uploaded_file(upload: upload, target: target)\n        return if document.nil?\n\n        RagDocumentFragment.publish_status(upload, { total: 0, indexed: 0, left: 0 })\n\n        fragment_ids = []\n        idx = 0\n\n        ActiveRecord::Base.transaction do\n          chunk_document(\n            file: document,\n            tokenizer: tokenizer,\n            chunk_tokens: chunk_tokens,\n            overlap_tokens: overlap_tokens,\n          ) do |chunk, metadata|\n            fragment_ids << RagDocumentFragment.create!(\n              target: target,\n              fragment: chunk,\n              fragment_number: idx + 1,\n              upload: upload,\n              metadata: metadata,\n            ).id\n\n            idx += 1\n\n            if idx > MAX_FRAGMENTS\n              Rails.logger.warn(\"Upload #{upload.id} has too many fragments, truncating.\")\n              break\n            end",
    "comment": "TODO(roman): Add a way to automatically recover from errors, resulting in unindexed uploads.",
    "label": "",
    "id": "551"
  },
  {
    "raw_code": "def execute(args = {})\n      return if args[:item_ids].blank? || args[:item_type].blank?\n\n      if %w[topics posts].exclude?(args[:item_type])\n        Rails.logger.error(\"Invalid item_type for GenerateInferredConcepts: #{args[:item_type]}\")\n        return\n      end",
    "comment": "Process items to generate new concepts  @param args [Hash] Contains job arguments @option args [String] :item_type Required - Type of items to process ('topics' or 'posts') @option args [Array<Integer>] :item_ids Required - List of item IDs to process @option args [Integer] :batch_size (100) Number of items to process in each batch @option args [Boolean] :match_only (false) Only match against existing concepts without generating new ones",
    "label": "",
    "id": "552"
  },
  {
    "raw_code": "def execute(_args)\n      return unless SiteSetting.inferred_concepts_enabled\n\n      process_popular_topics\n      process_popular_posts\n    end",
    "comment": "This job runs daily and generates new concepts from popular topics and posts It selects items based on engagement metrics and generates concepts from their content",
    "label": "",
    "id": "553"
  },
  {
    "raw_code": "def self.action_aliases\n    {\n      agree_and_keep_hidden: :agree_and_keep,\n      agree_and_silence: :agree_and_keep,\n      agree_and_suspend: :agree_and_keep,\n      disagree_and_restore: :disagree,\n    }\n  end",
    "comment": "Penalties are handled by the modal after the action is performed",
    "label": "",
    "id": "554"
  },
  {
    "raw_code": "def function_call_name\n    tool_name.presence || name\n  end",
    "comment": "Backwards compatibility: if tool_name is not set (existing custom tools), use name",
    "label": "",
    "id": "555"
  },
  {
    "raw_code": "def write_to(path)\n    css_path = \"#{path}/main.css\"\n    html_path = \"#{path}/main.html\"\n    js_path = \"#{path}/main.js\"\n    instructions_path = \"#{path}/instructions.txt\"\n\n    File.write(css_path, css)\n    File.write(html_path, html)\n    File.write(js_path, js)\n    File.write(instructions_path, change_description)\n  end",
    "comment": "used when generating test cases",
    "label": "",
    "id": "556"
  },
  {
    "raw_code": "def self.share_asset_url(asset_name)\n        if !%w[share.css highlight.js].include?(asset_name)\n          raise StandardError, \"unknown asset type #{asset_name}\"\n        end",
    "comment": "keeping it here for caching",
    "label": "",
    "id": "557"
  },
  {
    "raw_code": "def seed_embeddings(topics)\n      schema = DiscourseAi::Embeddings::Schema.for(Topic)\n      base_value = 1\n\n      topics.each_with_index do |t, idx|\n        base_value -= 0.01\n        schema.store(t, [base_value] * embedding_definition.dimensions, \"digest\")\n      end",
    "comment": "The Distance gap to target increases for each element of topics.",
    "label": "",
    "id": "558"
  },
  {
    "raw_code": "def seed_embeddings(topics)\n        schema = DiscourseAi::Embeddings::Schema.for(Topic)\n        base_value = 1\n\n        schema.store(target, [base_value] * 1024, \"disgest\")\n\n        topics.each do |t|\n          base_value -= 0.01\n          schema.store(t, [base_value] * 1024, \"digest\")\n        end",
    "comment": "The Distance gap to target increases for each element of topics.",
    "label": "",
    "id": "559"
  },
  {
    "raw_code": "def mocked_http\n    Class.new(FinalDestination::HTTP) do\n      def request(*)\n        super do |response|\n          response.instance_eval do\n            def read_body(*, &block)\n              if block_given?\n                @body.each(&block)\n              else\n                super\n              end\n            end\n          end",
    "comment": "Copied from https://github.com/bblimke/webmock/issues/629 Workaround for stubbing a streamed response",
    "label": "",
    "id": "560"
  },
  {
    "raw_code": "def has_rg?\n  if defined?(@has_rg)\n    @has_rg\n  else\n    @has_rg |= system(\"which rg\")\n  end",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "561"
  },
  {
    "raw_code": "def self.inject(plugin)\n      plugin.register_modifier(:assigns_reminder_assigned_topics_query) do |query|\n        next query if !SiteSetting.ignore_solved_topics_in_assigned_reminder\n        query.where.not(id: DiscourseSolved::SolvedTopic.select(:topic_id))\n      end",
    "comment": "TODO: These four plugin api usages should ideally be in the assign plugin, not the solved plugin. They have been moved here from plugin.rb as part of the custom fields migration.",
    "label": "",
    "id": "562"
  },
  {
    "raw_code": "def generate_html(text, opts = {})\n  output = \"<p><span\"\n  output += \" class=\\\"discourse-local-date\\\"\"\n  output += \" data-date=\\\"#{opts[:date]}\\\"\" if opts[:date]\n  output += \" data-email-preview=\\\"#{opts[:email_preview]}\\\"\" if opts[:email_preview]\n  output += \" data-format=\\\"#{opts[:format]}\\\"\" if opts[:format]\n  output += \" data-time=\\\"#{opts[:time]}\\\"\" if opts[:time]\n  output += \" data-timezone=\\\"#{opts[:timezone]}\\\"\" if opts[:timezone]\n  output += \" data-timezones=\\\"#{opts[:timezones]}\\\"\" if opts[:timezones]\n  output += \">\"\n  output += text\n  output + \"</span></p>\"\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "563"
  },
  {
    "raw_code": "def filter_posts_near(post_number)\n      return super if !post_voting_topic?\n\n      post_number = 1 if post_number == 0\n\n      cte_query = <<~SQL\n      WITH rows AS (\n        WITH posts AS (\n          #{@filtered_posts.to_sql}\n        )\n        SELECT\n          id,\n          post_number,\n          ROW_NUMBER() OVER () AS row_number\n        FROM posts\n      )\n      SQL\n\n      row_number, max_row_number = DB.query_single(<<~SQL)\n      #{cte_query}\n      SELECT\n        row_number,\n        (SELECT row_number FROM rows ORDER BY row_number DESC LIMIT 1) AS max_row_number\n      FROM rows\n      WHERE rows.post_number = #{post_number.to_i}\n      SQL\n\n      row_number = 1 if row_number.blank? # Post number does not exist so load from first post.\n\n      posts_before = (@limit.to_f / 4).floor\n      posts_before = 1 if posts_before.zero?\n      posts_after = @limit - posts_before - 1\n\n      range =\n        # Lower boundary window\n        if (row_number - posts_before) <= 0\n          1..(@limit - (row_number - 1))\n          # Upper boundary window\n        elsif (max_row_number - row_number) < posts_after\n          (max_row_number - @limit + 1)..max_row_number\n          # Any other window in between.\n        else\n          (row_number - posts_before)..(row_number + posts_after)\n        end",
    "comment": "Monkey patch core's method. In an ideal world, we wouldn't have to do this here but `TopicView` in core does not yet properly support ordering posts in any other order except by `Post#sort_order` and several methods in core's `TopicView` is strongly tied to the assumption that posts are always ordered by `Post#sort_order`. Fixing core is hard and risky so we will just carry this monkey patch instead. There is also a small performance tradeoff here in the following implementation. In PostgreSQL, we basically have to scan for every single posts in order to figure out what the \"row_number\" for each post. From there, we can then properly fetch the window of posts near a given post number.",
    "label": "",
    "id": "564"
  },
  {
    "raw_code": "def self.holiday_ends_at(events)\n      sorted_events = events.sort_by(&:start_date)\n      return nil if sorted_events.first.in_future?\n      return sorted_events.first.ends_at if events.count == 1\n\n      result = sorted_events.first.ends_at\n      sorted_events.each_cons(2) do |pair|\n        if pair[0].ends_at < pair[1].start_date\n          return result\n        elsif pair[1].ends_at > result\n          result = pair[1].ends_at\n        end",
    "comment": "If a user has several holidays one after another we want to show the farthest end date.  Let's say today is Monday and I am sick, and I also have days off from Tuesday to Friday:  sick       days off     We want to show Friday as an end date of my holiday.  This algorithm also works in case the holidays intersect, like this:  event_1   event_2     event_3         or like this:  event_1   event_2   event_3      or like this:  event_1   event_2       ",
    "label": "",
    "id": "565"
  },
  {
    "raw_code": "def next_holidays(holidays_count, options, from_date = Date.today)\n      raise ArgumentError unless holidays_count\n      raise ArgumentError if options.empty?\n      raise ArgumentError unless options.is_a?(Array)\n\n      # remove the timezone\n      from_date = from_date.new_offset(0) + from_date.offset if from_date.respond_to?(:new_offset)\n\n      from_date = get_date(from_date)\n\n      Factory::Finder.next_holiday.call(holidays_count, from_date, options)\n    end",
    "comment": "FIXME All other methods start with a date and require a date. For the next major version bump we should take the opportunity to change this signature to match, e.g. next_holidays(from_date, count, options)",
    "label": "",
    "id": "566"
  },
  {
    "raw_code": "def year_holidays(options, from_date = Date.today)\n      raise ArgumentError if options.empty?\n      raise ArgumentError unless options.is_a?(Array)\n\n      # remove the timezone\n      from_date = from_date.new_offset(0) + from_date.offset if from_date.respond_to?(:new_offset)\n      from_date = get_date(from_date)\n\n      Factory::Finder.year_holiday.call(from_date, options)\n    end",
    "comment": "FIXME All other methods start with a date and require a date. For the next major version bump we should take the opportunity to change this signature to match, e.g. year_holidays(from_date, options)",
    "label": "",
    "id": "567"
  },
  {
    "raw_code": "def days_in_month(month, year = current.year)\n          if month == 2 && ::Date.gregorian_leap?(year)\n            29\n          else\n            COMMON_YEAR_DAYS_IN_MONTH[month]\n          end",
    "comment": "Returns the number of days in the given month. If no year is specified, it will use the current year.",
    "label": "",
    "id": "568"
  },
  {
    "raw_code": "def holidays(*options)\n        Holidays.on(self, *options)\n      end",
    "comment": "Get holidays on the current date.  Returns an array of hashes or nil. See Holidays#between for options and the output format.  Date.civil('2008-01-01').holidays(:ca_) => [{:name => 'New Year\\'s Day',...}]  Also available via Holidays#on.",
    "label": "",
    "id": "569"
  },
  {
    "raw_code": "def holiday?(*options)\n        holidays = self.holidays(*options)\n        holidays && !holidays.empty?\n      end",
    "comment": "Check if the current date is a holiday.  Returns true or false.  Date.civil('2008-01-01').holiday?(:ca) => true",
    "label": "",
    "id": "570"
  },
  {
    "raw_code": "def change(options)\n        ::Date.new(\n          options.fetch(:year, year),\n          options.fetch(:month, month),\n          options.fetch(:day, day)\n        )\n      end",
    "comment": "Returns a new Date where one or more of the elements have been changed according to the +options+ parameter. The +options+ parameter is a hash with a combination of these keys: <tt>:year</tt>, <tt>:month</tt>, <tt>:day</tt>.  Date.new(2007, 5, 12).change(day: 1)               # => Date.new(2007, 5, 1) Date.new(2007, 5, 12).change(year: 2005, month: 1) # => Date.new(2005, 1, 12)",
    "label": "",
    "id": "571"
  },
  {
    "raw_code": "def add_border_months(current_date, dates_driver)\n          if current_date.month == 1\n            dates_driver[current_date.year] << 2\n\n            prev_year = current_date.year - 1\n            dates_driver[prev_year] = [] unless dates_driver[prev_year]\n            dates_driver[prev_year] << 12\n          elsif current_date.month == 12\n            dates_driver[current_date.year] << 11\n\n            next_year = current_date.year + 1\n            dates_driver[next_year] = [] unless dates_driver[next_year]\n            dates_driver[next_year] << 1\n          else\n            dates_driver[current_date.year] << current_date.month - 1 << current_date.month + 1\n          end",
    "comment": "As part of https://github.com/holidays/holidays/issues/146 I am returning additional months in an attempt to catch month-spanning date situations (i.e. dates falling on 2/1 but being observed on 1/31). By including the additional months we are increasing runtimes slightly but improving accuracy, which is more important to me at this stage.",
    "label": "",
    "id": "572"
  },
  {
    "raw_code": "def call(*options)\n          options.flatten!\n\n          #TODO This is garbage. These two deletes MUST come before the\n          # parse_regions call, otherwise it thinks that :observed and :informal\n          # are regions to parse. We should be splitting these things out.\n          observed = options.delete(:observed) ? true : false\n          informal = options.delete(:informal) ? true : false\n          regions = parse_regions!(options)\n\n          return regions, observed, informal\n        end",
    "comment": "Returns [(arr)regions, (bool)observed, (bool)informal]",
    "label": "",
    "id": "573"
  },
  {
    "raw_code": "def parse_regions!(regions)\n          regions = [regions] unless regions.kind_of?(Array)\n\n          if regions.empty?\n            regions = [:any]\n          else\n            regions = regions.collect { |r| r.to_sym }\n          end",
    "comment": "Check regions against list of supported regions and return an array of symbols.  If a wildcard region is found (e.g. :ca_) it is expanded into all of its available sub regions.",
    "label": "",
    "id": "574"
  },
  {
    "raw_code": "def is_holiday?(flag)\n          flag.nil? ? true : !!flag\n        end",
    "comment": "If flag is not present then default to 'true'",
    "label": "",
    "id": "575"
  },
  {
    "raw_code": "def parse_month_definitions(month_definitions, parsed_custom_methods)\n          regions = []\n          rules_by_month = {}\n\n          if month_definitions\n            month_definitions.each do |month, definitions|\n              rules_by_month[month] = [] unless rules_by_month[month]\n              definitions.each do |definition|\n                rule = {}\n\n                definition.each do |key, val|\n                  # Ruby 2.4 doesn't have the `transform_keys` method. Once we drop 2.4 support we can\n                  # use `val.transform_keys!(&:to_sym) if val.is_a?(Hash)` instead of this `if` statement.\n                  if val.is_a?(Hash)\n                    val = val.keys.each_with_object({}) do |k, result|\n                      result[k.to_sym] = val[k]\n                    end",
    "comment": "FIXME This should be a 'month_definitions_parser' like the above parser",
    "label": "",
    "id": "576"
  },
  {
    "raw_code": "def generate_month_definition_strings(rules_by_month, parsed_custom_methods)\n          month_strings = []\n\n          rules_by_month.each do |month, rules|\n            month_string = \"      #{month.to_s} => [\"\n            rule_strings = []\n            rules.each do |rule|\n              string = '{'\n              if rule[:mday]\n                string << \":mday => #{rule[:mday]}, \"\n              end",
    "comment": "FIXME This should really be split out and tested with its own unit tests.",
    "label": "",
    "id": "577"
  },
  {
    "raw_code": "def get_function_arguments(function_id, parsed_custom_methods)\n          if method = @custom_methods_repository.find(function_id)\n            method.parameters.collect { |arg| arg[1] }\n          elsif method = parsed_custom_methods[function_id]\n            method.arguments.collect { |arg| arg.to_sym }\n          end",
    "comment": "This method sucks. The issue here is that the custom methods repo has the 'general' methods (like easter) but the 'parsed_custom_methods' have the recently parsed stuff. We don't load those until they are needed later. This entire file is a refactor target so I am adding some tech debt to get me over the hump. What we should do is ensure that all custom methods are loaded into the repo as soon as they are parsed so we only have one place to look.",
    "label": "",
    "id": "578"
  },
  {
    "raw_code": "def add(new_custom_methods)\n          raise ArgumentError if new_custom_methods.nil?\n          @custom_methods.merge!(new_custom_methods)\n        end",
    "comment": "This performs a merge that overwrites any conflicts. While this is not ideal I'm leaving it as-is since I have no evidence of any current definitions that will cause an issue.  FIXME: this should probably return an error if a method with the same ID already exists.",
    "label": "",
    "id": "579"
  },
  {
    "raw_code": "def find_wildcard_base(region)\n          r = region.to_s\n\n          if r =~ /_$/\n            base = r.split('_').first\n          else\n            base = r\n          end",
    "comment": "Ex: :gb_ transformed to :gb",
    "label": "",
    "id": "580"
  },
  {
    "raw_code": "def valid_name?(n)\n          return true unless n\n          n.is_a?(String)\n        end",
    "comment": "Can be missing",
    "label": "",
    "id": "581"
  },
  {
    "raw_code": "def valid_holiday?(h)\n          return true unless h\n          h.is_a?(TrueClass)\n        end",
    "comment": "Can be missing",
    "label": "",
    "id": "582"
  },
  {
    "raw_code": "def valid_options?(options)\n          return true unless options\n\n          if options.is_a?(Array)\n            options.all? do |o|\n              o.is_a?(String)\n            end",
    "comment": "Okay to be missing and can be either string or array of strings",
    "label": "",
    "id": "583"
  },
  {
    "raw_code": "def calculate_easter_for(year)\n          g = year % 19 + 1\n          s = (year - 1600) / 100 - (year - 1600) / 400\n          l = (((year - 1400) / 100) * 8) / 25\n\n          p_2 = (3 - 11 * g + s - l) % 30\n          if p_2 == 29 || (p_2 == 28 && g > 11)\n            p = p_2 - 1\n          else\n            p = p_2\n          end",
    "comment": "Copied from https://github.com/Loyolny/when_easter Graciously allowed by Micha Nierebiski (https://github.com/Loyolny)",
    "label": "",
    "id": "584"
  },
  {
    "raw_code": "def to_monday_if_weekend(date)\n        return date unless date.wday == 6 || date.wday == 0\n        to_next_weekday(date)\n      end",
    "comment": "Move date to Monday if it occurs on a Saturday on Sunday. Does not modify date if it is not a weekend. Used as a callback function.",
    "label": "",
    "id": "585"
  },
  {
    "raw_code": "def to_monday_if_sunday(date)\n        return date unless date.wday == 0\n        to_next_weekday(date)\n      end",
    "comment": "Move date to Monday if it occurs on a Sunday. Does not modify the date if it is not a Sunday. Used as a callback function.",
    "label": "",
    "id": "586"
  },
  {
    "raw_code": "def to_weekday_if_boxing_weekend(date)\n        if date.wday == 6 || date.wday == 0\n          date += 2\n        elsif date.wday == 1 # https://github.com/holidays/holidays/issues/27\n          date += 1\n        end",
    "comment": "Move Boxing Day if it falls on a weekend, leaving room for Christmas. Used as a callback function.",
    "label": "",
    "id": "587"
  },
  {
    "raw_code": "def to_tuesday_if_sunday_or_monday_if_saturday(date)\n        date += 2 if [0, 6].include?(date.wday)\n        date\n      end",
    "comment": "if Christmas falls on a Saturday, move it to the next Monday (Boxing Day will be Sunday and potentially Tuesday) if Christmas falls on a Sunday, move it to the next Tuesday (Boxing Day will go on Monday)  if Boxing Day falls on a Saturday, move it to the next Monday (Christmas will go on Friday) if Boxing Day falls on a Sunday, move it to the next Tuesday (Christmas will go on Saturday & Monday)",
    "label": "",
    "id": "588"
  },
  {
    "raw_code": "def to_weekday_if_boxing_weekend_from_year_or_to_tuesday_if_monday(year)\n        to_weekday_if_boxing_weekend(Date.civil(year, 12, 26))\n      end",
    "comment": "Call to_weekday_if_boxing_weekend but first get date based on year Used as a callback function.",
    "label": "",
    "id": "589"
  },
  {
    "raw_code": "def to_weekday_if_boxing_weekend_from_year(year)\n        to_tuesday_if_sunday_or_monday_if_saturday(Date.civil(year, 12, 26))\n      end",
    "comment": "Call to_weekday_if_boxing_weekend but first get date based on year Used as a callback function.",
    "label": "",
    "id": "590"
  },
  {
    "raw_code": "def to_weekday_if_weekend(date)\n        date += 1 if date.wday == 0\n        date -= 1 if date.wday == 6\n        date\n      end",
    "comment": "Move date to Monday if it occurs on a Sunday or to Friday if it occurs on a Saturday. Used as a callback function.",
    "label": "",
    "id": "591"
  },
  {
    "raw_code": "def to_next_weekday(date)\n        case date.wday\n        when 6\n          date += 2\n        when 5\n          date += 3\n        else\n          date += 1\n        end",
    "comment": "Finds the next weekday. For example, if a 'Friday' date is received it will return the following Monday. If Sunday then return Monday, if Saturday return Monday, if Tuesday return Wednesday, etc.",
    "label": "",
    "id": "592"
  },
  {
    "raw_code": "def returns_true_for_various_holidays_in_poland\n    assert subject.call(Date.civil(2018, 1, 1), :pl)\n    assert subject.call(Date.civil(2018, 1, 2), :pl)\n    assert subject.call(Date.civil(2018, 5, 2), :pl)\n    assert subject.call(Date.civil(2018, 5, 3), :pl)\n    assert subject.call(Date.today, Date.today + 365*2, :pl, :observed)\n  end",
    "comment": "These are in response to https://github.com/holidays/holidays/issues/264, just to be completely sure it's fixed.",
    "label": "",
    "id": "593"
  },
  {
    "raw_code": "def reset_cache\n    Holidays::Factory::Definition.instance_variable_set(:@regions_repo, nil)\n    Holidays::Factory::Definition.instance_variable_set(:@holidays_repo, nil)\n  end",
    "comment": "Simulate load of new environment where the repositories begin empty",
    "label": "",
    "id": "594"
  },
  {
    "raw_code": "def test_available_regions_returns_correct_number_of_regions\n    assert_equal 258, Holidays.available_regions.count\n  end",
    "comment": "This test might fail if we add new regions. Since this is an integration test I am fine with that!",
    "label": "",
    "id": "595"
  },
  {
    "raw_code": "def test_function_returns_nil_date_should_not_be_returned\n    @holidays_by_month_repo.expects(:find_by_month).at_most_once.returns([:mday => 1, :name => \"Test\", :regions=> @regions, :function => \"func-id\", :function_arguments => [:year], :function_modifier => 1])\n\n    @custom_method_processor.expects(:call).with(\n      {:year => 2015, :month => 1, :day => 1, :region => :us},\n      \"func-id\",\n      [:year],\n      1,\n    ).returns(nil)\n\n    assert_equal([], @subject.call(@dates_driver, @regions, @options))\n  end",
    "comment": "FIXME This is a test that reflects how the current system works but this is NOT valid. See https://github.com/holidays/holidays/issues/204",
    "label": "",
    "id": "596"
  },
  {
    "raw_code": "def test_returns_expected_result_if_custom_method_modifies_month_when_multiple_holidays_found\n    @in_region_rule.expects(:call).twice.returns(true)\n    @holidays_by_month_repo.expects(:find_by_month).at_most_once.returns(\n      [\n        {:mday => 14, :name => \"Test\", :function => \"func-id\", :function_arguments => [:year], :regions => @regions},\n        {:mday => 14, :name => \"Test2\", :regions => @regions},\n      ]\n    )\n\n    @custom_method_processor.expects(:call).with(\n      {:year => 2015, :month => 1, :day => 14, :region => :us},\n      \"func-id\",\n      [:year],\n      nil,\n    ).returns(Date.civil(2015, 3, 14))\n\n    assert_equal(\n      [\n        {\n          :date => Date.civil(2015, 3, 14),\n          :name => \"Test\",\n          :regions => [:us],\n        },\n        {\n          :date => Date.civil(2015, 1, 14),\n          :name => \"Test2\",\n          :regions => [:us],\n        }\n      ],\n      @subject.call(@dates_driver, @regions, @options)\n    )\n  end",
    "comment": "This is a specific scenario but it COULD happen in our current flow. The goal: any date manipulation that occurs for a specific holiday should have no impact on other holidays.",
    "label": "",
    "id": "597"
  },
  {
    "raw_code": "def test_lookup_simply_returns_result_of_cache_if_present_after_first_call\n    function = lambda { |year| Date.civil(year, 2, 1) - 1 }\n    function_argument = 2015\n\n    assert_equal(Date.civil(2015, 1, 31), @subject.lookup(function, function_argument))\n  end",
    "comment": "FIXME This test stinks. I don't know how to show that the second invocation doesn't call the function. In rspec I could just do an expect().not_to but it doesn't seem like Mocha can do that? I'm punting.",
    "label": "",
    "id": "598"
  },
  {
    "raw_code": "def build_post(user, raw)\n  Post.new(user: user, raw: raw)\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "599"
  },
  {
    "raw_code": "def create_missing_post_actions\n      sql_query = <<~SQL\n        INSERT INTO post_actions(\n          post_id, user_id, post_action_type_id, created_at, updated_at\n        )\n        SELECT ru.post_id, ru.user_id, :pa_like, ru.created_at, ru.updated_at\n        FROM discourse_reactions_reaction_users ru\n        INNER JOIN discourse_reactions_reactions\n          ON discourse_reactions_reactions.id = ru.reaction_id\n        LEFT JOIN post_actions\n          ON post_actions.user_id = ru.user_id\n          AND post_actions.post_id = ru.post_id\n        WHERE post_actions.id IS NULL\n        #{@excluded_from_like.any? ? \" AND discourse_reactions_reactions.reaction_value NOT IN (:excluded_from_like)\" : \"\"}\n        RETURNING post_actions.id\n      SQL\n\n      DB.query_single(\n        sql_query,\n        pa_like: PostActionType::LIKE_POST_ACTION_ID,\n        excluded_from_like: @excluded_from_like,\n      )\n    end",
    "comment": "Find all ReactionUser records that do not have a corresponding PostAction like record, for any reactions that are not in excluded_from_like, and create a PostAction record for each.",
    "label": "",
    "id": "600"
  },
  {
    "raw_code": "def recover_trashed_post_actions\n      sql_query = <<~SQL\n        UPDATE post_actions\n        SET deleted_at = NULL, deleted_by_id = NULL, updated_at = NOW()\n        FROM discourse_reactions_reaction_users ru\n        INNER JOIN discourse_reactions_reactions\n          ON discourse_reactions_reactions.id = ru.reaction_id\n        WHERE post_actions.deleted_at IS NOT NULL AND post_actions.user_id = ru.user_id\n          AND post_actions.post_id = ru.post_id AND post_actions.post_action_type_id = :pa_like\n        #{@excluded_from_like.any? ? \" AND discourse_reactions_reactions.reaction_value NOT IN (:excluded_from_like)\" : \"\"}\n      SQL\n\n      DB.query_single(\n        sql_query,\n        pa_like: PostActionType::LIKE_POST_ACTION_ID,\n        excluded_from_like: @excluded_from_like,\n      )\n    end",
    "comment": "Find all trashed PostAction records matching ReactionUser records, which are not in excluded_from_like, and untrash them.",
    "label": "",
    "id": "601"
  },
  {
    "raw_code": "def create_missing_user_actions(post_action_ids)\n      return if post_action_ids.none?\n\n      sql_query = <<~SQL\n        INSERT INTO user_actions (\n          action_type, user_id, acting_user_id, target_post_id, target_topic_id, created_at, updated_at\n        )\n        SELECT :ua_like,\n               post_actions.user_id,\n               post_actions.user_id,\n               post_actions.post_id,\n               posts.topic_id,\n               post_actions.created_at,\n               post_actions.created_at\n        FROM post_actions\n        INNER JOIN posts ON posts.id = post_actions.post_id\n        WHERE post_actions.id IN (:post_action_ids) AND posts.user_id IS NOT NULL\n        ON CONFLICT DO NOTHING\n      SQL\n      inserted_user_action_count =\n        DB.exec(sql_query, ua_like: UserAction::LIKE, post_action_ids: post_action_ids)\n      Rails.logger.info(\n        \"[ReactionsLikeSynchronizer] Inserted #{inserted_user_action_count} like UserActions\",\n      )\n\n      sql_query = <<~SQL\n        INSERT INTO user_actions (\n          action_type, user_id, acting_user_id, target_post_id, target_topic_id, created_at, updated_at\n        )\n        SELECT :ua_was_liked,\n               posts.user_id,\n               post_actions.user_id,\n               post_actions.post_id,\n               posts.topic_id,\n               post_actions.created_at,\n               post_actions.created_at\n        FROM post_actions\n        INNER JOIN posts ON posts.id = post_actions.post_id\n        WHERE post_actions.id IN (:post_action_ids) AND posts.user_id IS NOT NULL\n        ON CONFLICT DO NOTHING\n      SQL\n      inserted_user_action_count =\n        DB.exec(sql_query, ua_was_liked: UserAction::WAS_LIKED, post_action_ids: post_action_ids)\n      Rails.logger.info(\n        \"[ReactionsLikeSynchronizer] Inserted #{inserted_user_action_count} was_liked UserActions\",\n      )\n    end",
    "comment": "Create the corresponding UserAction records for the PostAction records. In the ReactionManager, this is done via PostActionCreator.  The only difference between LIKE and WAS LIKED is the user; * LIKE is the post action user because they are the one who liked the post * WAS LIKED is done by the post user, because they are the like-ee  No need to do any UserAction inserts if there wasn't any PostAction changes.",
    "label": "",
    "id": "602"
  },
  {
    "raw_code": "def delete_excluded_user_actions(trashed_post_action_ids)\n      return if trashed_post_action_ids.empty?\n\n      sql_query = <<~SQL\n        DELETE FROM user_actions\n        WHERE id IN (\n          -- Select IDs for LIKED actions\n          SELECT user_actions.id\n          FROM user_actions\n          INNER JOIN post_actions ON user_actions.target_post_id = post_actions.post_id\n            AND user_actions.acting_user_id = post_actions.user_id\n          WHERE post_actions.id IN (:trashed_post_action_ids)\n          AND user_actions.action_type = :ua_like\n\n          UNION\n\n          -- Select IDs for WAS_LIKED actions\n          SELECT user_actions.id\n          FROM user_actions user_actions\n          INNER JOIN post_actions ON user_actions.target_post_id = post_actions.post_id\n          INNER JOIN posts ON posts.id = post_actions.post_id\n          WHERE post_actions.id IN (:trashed_post_action_ids)\n          AND user_actions.action_type = :ua_was_liked\n          AND user_actions.user_id = posts.user_id\n          AND user_actions.acting_user_id = post_actions.user_id\n        )\n      SQL\n      DB.exec(\n        sql_query,\n        ua_like: UserAction::LIKE,\n        ua_was_liked: UserAction::WAS_LIKED,\n        trashed_post_action_ids: trashed_post_action_ids,\n      )\n    end",
    "comment": "Delete any UserAction records for LIKE or WAS_LIKED that match up with PostAction records that got trashed.",
    "label": "",
    "id": "603"
  },
  {
    "raw_code": "def trash_excluded_post_actions\n      return [] if @excluded_from_like.none?\n\n      sql_query = <<~SQL\n        UPDATE post_actions\n        SET deleted_at = NOW()\n        FROM discourse_reactions_reaction_users ru\n        INNER JOIN discourse_reactions_reactions ON discourse_reactions_reactions.id = ru.reaction_id\n        WHERE post_actions.user_id = ru.user_id\n          AND post_actions.post_id = ru.post_id\n          AND post_actions.post_action_type_id = :like\n          AND discourse_reactions_reactions.reaction_value IN (:excluded_from_like)\n        RETURNING post_actions.id\n      SQL\n\n      DB.query_single(\n        sql_query,\n        like: PostActionType::LIKE_POST_ACTION_ID,\n        excluded_from_like: @excluded_from_like,\n        ua_like: UserAction::LIKE,\n        ua_was_liked: UserAction::WAS_LIKED,\n      )\n    end",
    "comment": "Find all PostAction records that have a ReactionUser record that uses a reaction in the excluded_from_like list and trash them.",
    "label": "",
    "id": "604"
  },
  {
    "raw_code": "def update_post_like_counts(all_affected_post_action_ids)\n      post_ids = DB.query_single(<<~SQL, post_action_ids: all_affected_post_action_ids)\n        SELECT DISTINCT post_id\n        FROM post_actions\n        WHERE ID IN (:post_action_ids)\n      SQL\n\n      sql_query = <<~SQL\n        UPDATE posts\n        SET like_count = (\n          SELECT COUNT(*)\n          FROM post_actions\n          WHERE post_actions.post_id = posts.id\n          AND post_action_type_id = 2\n          AND post_actions.deleted_at IS NULL\n        )\n        WHERE posts.id IN (:post_ids)\n      SQL\n      DB.exec(sql_query, post_ids: post_ids)\n    end",
    "comment": "Update the like_count counter cache on all Post records affected by created/recovered/trashed post actions.",
    "label": "",
    "id": "605"
  },
  {
    "raw_code": "def update_topic_like_counts(all_affected_post_action_ids)\n      topic_ids = DB.query_single(<<~SQL, post_action_ids: all_affected_post_action_ids)\n        SELECT DISTINCT topic_id\n        FROM posts\n        INNER JOIN post_actions ON post_actions.post_id = posts.id\n        WHERE post_actions.id IN (:post_action_ids)\n      SQL\n\n      sql_query = <<~SQL\n        UPDATE topics\n        SET like_count = (\n          SELECT SUM(like_count)\n          FROM posts\n          WHERE posts.topic_id = topics.id\n        )\n        WHERE topics.id IN (:topic_ids)\n      SQL\n\n      DB.exec(sql_query, topic_ids: topic_ids)\n    end",
    "comment": "Update the like_count counter cache on all Topic records affected by created/recovered/trashed post actions.",
    "label": "",
    "id": "606"
  },
  {
    "raw_code": "def update_user_stats(all_affected_post_action_ids)\n      return if all_affected_post_action_ids.empty?\n\n      users_needing_likes_received_recalc = DB.query_single(<<~SQL, all_affected_post_action_ids)\n        SELECT DISTINCT posts.user_id\n        FROM posts\n        INNER JOIN post_actions ON post_actions.post_id = posts.id\n        WHERE post_actions.id IN (?)\n      SQL\n\n      if users_needing_likes_received_recalc.any?\n        # NOTE: UserAction created as a result of a PostAction like\n        # will have acting_user_id, target_post_id, and target_topic_id\n        # filled but NOT target_user_id, see UserActionManager.post_action_rows\n        sql_query = <<~SQL\n          WITH likes_received_cte AS (\n            SELECT posts.user_id AS user_id, COUNT(user_actions.id) AS new_likes_received\n            FROM user_actions\n            INNER JOIN posts ON user_actions.target_post_id = posts.id\n            WHERE user_actions.action_type = :ua_was_liked\n              AND posts.user_id IN (:affected_user_ids)\n            GROUP BY posts.user_id\n          )\n          UPDATE user_stats\n          SET likes_received = lrc.new_likes_received\n          FROM likes_received_cte lrc\n          WHERE user_stats.user_id = lrc.user_id\n          RETURNING user_stats.user_id\n        SQL\n\n        changed_user_ids =\n          DB.query_single(\n            sql_query,\n            affected_user_ids: users_needing_likes_received_recalc,\n            ua_was_liked: UserAction::WAS_LIKED,\n          )\n        UserStat.where(user_id: users_needing_likes_received_recalc - changed_user_ids).update_all(\n          likes_received: 0,\n        )\n      end",
    "comment": "Update the likes_given and likes_received counter caches on the UserStat table based on posts matching up with created/restored/trashed post actions.  The UserAction records (which are created/deleted before this) are an easier way to calculate this rather than going via PostAction again.",
    "label": "",
    "id": "607"
  },
  {
    "raw_code": "def upsert_given_daily_likes(all_affected_post_action_ids)\n      return if all_affected_post_action_ids.blank?\n\n      sql_query = <<~SQL\n        SELECT user_id\n        FROM post_actions\n        WHERE post_actions.id = ANY(ARRAY[:all_affected_post_action_ids])\n        UNION\n        SELECT posts.user_id\n        FROM posts\n        INNER JOIN post_actions ON post_actions.post_id = posts.id \n        WHERE post_actions.id = ANY(ARRAY[:all_affected_post_action_ids])\n      SQL\n      user_ids =\n        DB.query_single(sql_query, all_affected_post_action_ids: all_affected_post_action_ids)\n\n      return if user_ids.blank?\n\n      sql_query = <<~SQL\n        INSERT INTO given_daily_likes (user_id, given_date, likes_given)\n        SELECT user_actions.acting_user_id, DATE(user_actions.created_at) AS given_date, COUNT(*) AS likes_given\n        FROM user_actions\n        WHERE user_actions.action_type = :ua_like\n          AND user_actions.acting_user_id IN (:user_ids)\n        GROUP BY user_actions.acting_user_id, DATE(user_actions.created_at)\n        ON CONFLICT (user_id, given_date)\n        DO UPDATE SET likes_given = EXCLUDED.likes_given\n      SQL\n      DB.exec(sql_query, ua_like: UserAction::LIKE, user_ids: user_ids)\n\n      sql_query = <<~SQL\n        DELETE FROM given_daily_likes gdl\n        WHERE NOT EXISTS (\n          SELECT 1\n          FROM user_actions\n          WHERE\n              user_actions.acting_user_id = gdl.user_id\n              AND user_actions.action_type = :ua_like\n              AND DATE(user_actions.created_at) = gdl.given_date\n        ) AND gdl.user_id IN (:user_ids)\n      SQL\n      DB.exec(sql_query, ua_like: UserAction::LIKE, user_ids: user_ids)\n    end",
    "comment": "Upsert any existing GivenDailyLike records for the users who created or were affected by the created/restored/trashed post actions. There is a count per day per user that needs to be recalculated.  We delete any GivenDailyLike records that would equate to a count of 0 for that day and that user, which is based on UserAction records (which are created or destroyed before this).",
    "label": "",
    "id": "608"
  },
  {
    "raw_code": "def self.mount_engines\n      engines = []\n      DiscourseChatIntegration::Provider.providers.each do |provider|\n        engine =\n          provider\n            .constants\n            .select { |constant| constant.to_s =~ (/Engine$/) && (constant.to_s != \"HookEngine\") }\n            .map(&provider.method(:const_get))\n            .first\n\n        engines.push(engine: engine, name: provider::PROVIDER_NAME) if engine\n      end",
    "comment": "Automatically mount each provider's engine inside the HookEngine",
    "label": "",
    "id": "609"
  },
  {
    "raw_code": "def guess_first_message(skip_messages: 5) # Can skip the last n messages\n      return true if @requested_thread_ts # Always start thread on first message\n      return false if @messages.blank? || @messages.size < skip_messages\n\n      possible_first_messages = @messages[0..-skip_messages]\n\n      # Work through the messages in order. If a gap is found, this could be the first message\n      new_first_message_index = nil\n      previous_message_ts = @messages[-skip_messages].ts.split(\".\").first.to_i\n      possible_first_messages.each_with_index do |message, index|\n        # Calculate the time since the last message\n        this_ts = message.ts.split(\".\").first.to_i\n        time_since_previous_message = this_ts - previous_message_ts\n\n        # If greater than 3 minutes, this could be the first message\n        new_first_message_index = index if time_since_previous_message > 3.minutes\n\n        previous_message_ts = this_ts\n      end",
    "comment": "Apply a heuristic to decide which is the first message in the current conversation",
    "label": "",
    "id": "610"
  },
  {
    "raw_code": "def first_message_number\n      @first_message_index < 0 ? @messages.length + @first_message_index : @first_message_index\n    end",
    "comment": "These two methods convert potentially negative array indices into positive ones",
    "label": "",
    "id": "611"
  },
  {
    "raw_code": "def tags=(array)\n    if array.nil? || array.empty?\n      super(nil)\n    else\n      super(array)\n    end",
    "comment": "We never want an empty array, set it to nil instead",
    "label": "",
    "id": "612"
  },
  {
    "raw_code": "def channel\n    DiscourseChatIntegration::Channel.find_by(id: channel_id)\n  end",
    "comment": "Mock foreign key Could return nil",
    "label": "",
    "id": "613"
  },
  {
    "raw_code": "def self.status_for_channel(channel)\n      rules = channel.rules.order_by_precedence\n      provider = channel.provider\n\n      text = I18n.t(\"chat_integration.provider.#{provider}.status.header\") + \"\\n\"\n\n      i = 1\n      rules.each do |rule|\n        category_id = rule.category_id\n\n        case rule.type\n        when \"normal\"\n          if category_id.nil?\n            category_name = I18n.t(\"chat_integration.all_categories\")\n          else\n            category = Category.find_by(id: category_id)\n            if category\n              category_name = category.slug\n            else\n              category_name = I18n.t(\"chat_integration.deleted_category\")\n            end",
    "comment": "Produce a string with a list of all rules associated with a channel",
    "label": "",
    "id": "614"
  },
  {
    "raw_code": "def self.delete_by_index(channel, index)\n      rules = channel.rules.order_by_precedence\n      return false if index < (1) || index > (rules.size)\n      :deleted if rules[index - 1].destroy\n    end",
    "comment": "Delete a rule based on its (1 based) index as seen in the status_for_channel function",
    "label": "",
    "id": "615"
  },
  {
    "raw_code": "def self.smart_create_rule(channel:, filter:, category_id: nil, tags: nil)\n      existing_rules = DiscourseChatIntegration::Rule.with_channel(channel).with_type(\"normal\")\n\n      # Select the ones that have the same category\n      same_category = existing_rules.select { |rule| rule.category_id == category_id }\n\n      same_category_and_tags =\n        same_category.select do |rule|\n          (rule.tags.nil? ? [] : rule.tags.sort) == (tags.nil? ? [] : tags.sort)\n        end",
    "comment": "Create a rule for a specific channel Designed to be used by provider's \"Slash commands\" Will intelligently adjust existing rules to avoid duplicates Returns :updated if an existing rule has been updated :created if a new rule has been created false if there was an error",
    "label": "",
    "id": "616"
  },
  {
    "raw_code": "def self.run_query(query, req_params = {}, opts = {})\n      # Safety checks\n      # see test 'doesn't allow you to modify the database #2'\n      if query.sql =~ /;/\n        err = ValidationError.new(I18n.t(\"js.errors.explorer.no_semicolons\"))\n        return { error: err, duration_nanos: 0 }\n      end",
    "comment": "Run a data explorer query on the currently connected database.  @param [Query] query the Query object to run @param [Hash] params the colon-style query parameters for the query @param [Hash] opts hash of options explain - include a query plan in the result @return [Hash] error - any exception that was raised in the execution. Check this first before looking at any other fields. pg_result - the PG::Result object duration_nanos - the query duration, in nanoseconds explain - the query",
    "label": "",
    "id": "617"
  },
  {
    "raw_code": "def self.search_query(bookmarks, query, ts_query, &bookmarkable_search)\n      bookmarkable_search.call(bookmarks, \"data_explorer_queries.name ILIKE :q\")\n    end",
    "comment": "Searchable only by data_explorer_queries name",
    "label": "",
    "id": "618"
  },
  {
    "raw_code": "def public_run\n      return raise Discourse::NotFound if !guardian.user_can_access_query?(@query) || @query.hidden\n\n      run\n    end",
    "comment": "Public GET endpoint to run a query by ID for users with access",
    "label": "",
    "id": "619"
  },
  {
    "raw_code": "def run\n      rate_limit_query_runs!\n\n      check_xhr unless params[:download]\n\n      query = Query.find(params[:id].to_i)\n      query.update!(last_run_at: Time.now)\n\n      response.sending_file = true if params[:download]\n\n      query_params = {}\n      query_params = MultiJson.load(params[:params]) if params[:params]\n\n      opts = { current_user: current_user&.username }\n      opts[:explain] = true if params[:explain] == \"true\"\n\n      opts[:limit] = if params[:format] == \"csv\"\n        if params[:limit].present?\n          limit = params[:limit].to_i\n          limit = QUERY_RESULT_MAX_LIMIT if limit > QUERY_RESULT_MAX_LIMIT\n          limit\n        else\n          QUERY_RESULT_MAX_LIMIT\n        end",
    "comment": "Return value: success - true/false. if false, inspect the errors value. errors - array of strings. params - hash. Echo of the query parameters as executed. duration - float. Time to execute the query, in milliseconds, to 1 decimal place. columns - array of strings. Titles of the returned columns, in order. explain - string. (Optional - pass explain=true in the request) Postgres query plan, UNIX newlines. rows - array of array of strings. Results of the query. In the same order as 'columns'.",
    "label": "",
    "id": "620"
  },
  {
    "raw_code": "def backfill!\n    User\n      .real\n      .where(staged: false)\n      .select(:id)\n      .find_in_batches do |users|\n        rows = []\n        user_ids = users.map(&:id)\n\n        user_ids.each do |user_id|\n          @added_ids.each do |linkable_id|\n            rows << {\n              user_id: user_id,\n              linkable_type: @linkable_klass.to_s,\n              linkable_id: linkable_id,\n            }\n          end",
    "comment": "This should only be called from the `Jobs::BackfillSidebarSiteSettings` job as the job is ran with a cluster concurrency of 1 to ensure that only one process is running the backfill at any point in time.",
    "label": "",
    "id": "621"
  },
  {
    "raw_code": "def remember_message_sent\n    unless @opts[:limit_once_per] == false\n      Discourse.redis.setex(sent_recently_key, @opts[:limit_once_per].try(:to_i) || 86_400, 1)\n    end",
    "comment": "default is to send no more than once every 24 hours (24 * 60 * 60 = 86,400 seconds)",
    "label": "",
    "id": "622"
  },
  {
    "raw_code": "def self.normalize_to_i18n(locale)\n    return nil if locale.blank?\n    locale = locale.to_s.gsub(\"-\", \"_\")\n\n    i18n_pairs.each { |downcased, value| return value if locale.downcase == downcased }\n\n    locale\n  end",
    "comment": "Normalizes locale string, matching the list of I18n.locales where possible @param locale [String,Symbol] the locale to normalize @return [String] the normalized locale",
    "label": "",
    "id": "623"
  },
  {
    "raw_code": "def self.is_same?(locale1, locale2)\n    locale1 = locale1.to_s\n    locale2 = locale2.to_s\n    return true if locale1 == locale2\n    locale1 = locale1.gsub(\"-\", \"_\").downcase\n    locale2 = locale2.gsub(\"-\", \"_\").downcase\n    locale1.split(\"_\").first == locale2.split(\"_\").first\n  end",
    "comment": "Checks if two locales are the same based on exact match and normalized match - is_same?(\"a_b\", \"a-b\") == true - is_same?(\"a_b\", \"a\") == true @param locale1 [String,Symbol] the first locale to compare @param locale2 [String,Symbol] the second locale to compare",
    "label": "",
    "id": "624"
  },
  {
    "raw_code": "def get_category_id_by_name(category_name)\n      Category.where(\"name_lower = LOWER(?)\", category_name).pick(:id)\n    end",
    "comment": "@param [String] Name of the category to retrieve the id of. @return [Integer|nil] The id of the category with the given name or nil if a category does not exist for the given name.",
    "label": "",
    "id": "625"
  },
  {
    "raw_code": "def is_valid_url(url)\n      UrlHelper.is_valid_url?(url)\n    end",
    "comment": "@param [String] URL string to check if it is a valid absolute URL, path or anchor. @return [Boolean] True if the URL is a valid URL or path, false otherwise.",
    "label": "",
    "id": "626"
  },
  {
    "raw_code": "def self.contract_checks!(sql, opts = {})\n    return if sql.blank?\n\n    if Badge::Trigger.uses_post_ids?(opts[:trigger])\n      unless sql.match(/:post_ids/)\n        raise(\n          \"Contract violation:\\nQuery triggers on posts, but does not reference the ':post_ids' array\",\n        )\n      end",
    "comment": "Options: :target_posts - whether the badge targets posts :trigger - the Badge::Trigger id",
    "label": "",
    "id": "627"
  },
  {
    "raw_code": "def self.preview(sql, opts = {})\n    params = { user_ids: [], post_ids: [], backfill: true }\n\n    BadgeGranter.contract_checks!(sql, opts)\n\n    # hack to allow for params, otherwise sanitizer will trigger sprintf\n    count_sql = <<~SQL\n      SELECT COUNT(*) count\n                 FROM (\n                        #{sql}\n                      ) q\n                WHERE :backfill = :backfill\n    SQL\n    grant_count = DB.query_single(count_sql, params).first.to_i\n\n    grants_sql =\n      if opts[:target_posts]\n        <<~SQL\n        SELECT u.id, u.username, q.post_id, t.title, q.granted_at\n          FROM (\n                 #{sql}\n               ) q\n          JOIN users u on u.id = q.user_id\n     LEFT JOIN badge_posts p on p.id = q.post_id\n     LEFT JOIN topics t on t.id = p.topic_id\n         WHERE :backfill = :backfill\n         LIMIT 10\n      SQL\n      else\n        <<~SQL\n        SELECT u.id, u.username, q.granted_at\n         FROM (\n                #{sql}\n              ) q\n         JOIN users u on u.id = q.user_id\n        WHERE :backfill = :backfill\n        LIMIT 10\n      SQL\n      end",
    "comment": "Options: :target_posts - whether the badge targets posts :trigger - the Badge::Trigger id :explain - return the EXPLAIN query",
    "label": "",
    "id": "628"
  },
  {
    "raw_code": "def self.compiled_regexps_for_action(action, engine: :ruby, raise_errors: false)\n    words = cached_words_for_action(action)\n    return [] if words.blank?\n\n    words\n      .values\n      .group_by { |attrs| attrs[:case_sensitive] ? :case_sensitive : :case_insensitive }\n      .map do |group_key, attrs_list|\n        words = attrs_list.map { |attrs| attrs[:word] }\n\n        # Compile all watched words into a single regular expression\n        regexp =\n          words\n            .map do |word|\n              r = word_to_regexp(word, match_word: SiteSetting.watched_words_regular_expressions?)\n              begin\n                r if Regexp.new(r)\n              rescue RegexpError\n                raise if raise_errors\n              end",
    "comment": "This regexp is run in miniracer, and the client JS app Make sure it is compatible with major browsers when changing hint: non-chrome browsers do not support 'lookbehind'",
    "label": "",
    "id": "629"
  },
  {
    "raw_code": "def self.match_word_regexp(regexp, engine: :ruby)\n    if engine == :js\n      \"(?:\\\\P{L}|^)(#{regexp})(?=\\\\P{L}|$)\"\n    elsif engine == :ruby\n      \"(?:[^[:word:]]|^)(#{regexp})(?=[^[:word:]]|$)\"\n    else\n      raise \"unknown regexp engine: #{engine}\"\n    end",
    "comment": "Returns a regexp that transforms a regular expression into a regular expression that matches a whole word.",
    "label": "",
    "id": "630"
  },
  {
    "raw_code": "def self.reset!\n    @custom_post_revision_notifier_recipients = nil\n  end",
    "comment": "For testing purposes",
    "label": "",
    "id": "631"
  },
  {
    "raw_code": "def self.data_sources\n    # Category and Tag data sources are in core and always should be\n    # included for searches and lookups.\n    Set.new(DEFAULT_DATA_SOURCES | DiscoursePluginRegistry.hashtag_autocomplete_data_sources)\n  end",
    "comment": "NOTE: This is not meant to be called directly; use `enabled_data_sources` or the individual data_source_X methods instead.",
    "label": "",
    "id": "632"
  },
  {
    "raw_code": "def lookup(slugs, types_in_priority_order)\n    raise Discourse::InvalidParameters.new(:slugs) if !slugs.is_a?(Array)\n    raise Discourse::InvalidParameters.new(:order) if !types_in_priority_order.is_a?(Array)\n\n    types_in_priority_order =\n      types_in_priority_order.select do |type|\n        HashtagAutocompleteService.data_source_types.include?(type)\n      end",
    "comment": " Finds resources of the provided types by their exact slugs, unlike search which can search partial names, slugs, etc. Used for cooking fully formed #hashtags in the markdown pipeline. The @guardian handles permissions around which results should be returned here.  @param {Array} slugs The fully formed slugs to look up, which can have ::type suffixes attached as well (e.g. ::category), and in the case of categories can have parent:child relationships. @param {Array} types_in_priority_order The resource types we are looking up and the priority order in which we should match them if they do not have type suffixes. @returns {Hash} A hash with the types as keys and an array of HashtagItem that matches the provided slugs.",
    "label": "",
    "id": "633"
  },
  {
    "raw_code": "def search(\n    term,\n    types_in_priority_order,\n    limit: SiteSetting.experimental_hashtag_search_result_limit\n  )\n    raise Discourse::InvalidParameters.new(:order) if !types_in_priority_order.is_a?(Array)\n    limit = [limit, SEARCH_MAX_LIMIT].min\n    types_in_priority_order =\n      types_in_priority_order.select do |type|\n        HashtagAutocompleteService.data_source_types.include?(type)\n      end",
    "comment": " Searches registered hashtag data sources using the provided term (data sources determine what is actually searched) and prioritises the results based on types_in_priority_order and the limit. For example, if 5 categories were returned for the term and the limit was 5, we would not even bother searching tags. The @guardian handles permissions around which results should be returned here.  Items which have a slug that exactly matches the search term via lookup will be found first and floated to the top of the results, and still be ordered by type.  @param {String} term Search term, from the UI generally where the user is typing #has... @param {Array} types_in_priority_order The resource types we are searching for and the priority order in which we should return them. @param {Integer} limit The maximum number of search results to return, we don't bother searching subsequent types if the first types in the array already reach the limit. @returns {Array} The results as HashtagItems",
    "label": "",
    "id": "634"
  },
  {
    "raw_code": "def set_refs(hashtag_items)\n    hashtag_items.each { |item| item.ref ||= item.slug }\n  end",
    "comment": "Sometimes a specific ref is required, e.g. for categories that have a parent their ref will be parent_slug:child_slug, though most of the time it will be the same as the slug. The ref can then be used for lookup in the UI.",
    "label": "",
    "id": "635"
  },
  {
    "raw_code": "def self.validate_pop3(\n    host:,\n    port:,\n    username:,\n    password:,\n    ssl: SiteSetting.pop3_polling_ssl,\n    openssl_verify: SiteSetting.pop3_polling_openssl_verify,\n    debug: Rails.env.development?\n  )\n    begin\n      pop3 = Net::POP3.new(host, port)\n\n      # Note that we do not allow which verification mode to be specified\n      # like we do for SMTP, we just pick TLS1_2 if the SSL and openSSL verify\n      # options have been enabled.\n      if ssl\n        if openssl_verify\n          pop3.enable_ssl(max_version: OpenSSL::SSL::TLS1_2_VERSION)\n        else\n          pop3.enable_ssl(OpenSSL::SSL::VERIFY_NONE)\n        end",
    "comment": " Attempts to authenticate and disconnect a POP3 session and if that raises an error then it is assumed the credentials or some other settings are wrong.  @param debug [Boolean] - When set to true, any errors will be logged at a warning level before being re-raised.",
    "label": "",
    "id": "636"
  },
  {
    "raw_code": "def self.validate_smtp(\n    host:,\n    port:,\n    username:,\n    password:,\n    domain: nil,\n    authentication: nil,\n    enable_starttls_auto: GlobalSetting.smtp_enable_start_tls,\n    enable_tls: GlobalSetting.smtp_force_tls,\n    openssl_verify_mode: GlobalSetting.smtp_openssl_verify_mode,\n    debug: Rails.env.development?\n  )\n    begin\n      if enable_tls && enable_starttls_auto\n        raise ArgumentError, \"TLS and STARTTLS are mutually exclusive\"\n      end",
    "comment": " Attempts to start an SMTP session and if that raises an error then it is assumed the credentials or other settings are wrong.  @param domain [String] - Used for HELO, should be the FQDN of the server sending the mail localhost can be used in development mode. See https://datatracker.ietf.org/doc/html/rfc788#section-4 @param debug [Boolean] - When set to true, any errors will be logged at a warning level before being re-raised.",
    "label": "",
    "id": "637"
  },
  {
    "raw_code": "def self.validate_imap(\n    host:,\n    port:,\n    username:,\n    password:,\n    open_timeout: 5,\n    ssl: true,\n    debug: false\n  )\n    begin\n      imap = Net::IMAP.new(host, port: port, ssl: ssl, open_timeout: open_timeout)\n      imap.login(username, password)\n      begin\n        imap.logout\n      rescue StandardError\n        nil\n      end",
    "comment": " Attempts to login, logout, and disconnect an IMAP session and if that raises an error then it is assumed the credentials or some other settings are wrong.  @param debug [Boolean] - When set to true, any errors will be logged at a warning level before being re-raised.",
    "label": "",
    "id": "638"
  },
  {
    "raw_code": "def extract_mentions(post)\n    mentions = post.raw_mentions\n    return if mentions.blank?\n\n    groups = Group.where(\"LOWER(name) IN (?)\", mentions)\n    mentions -= groups.map(&:name).map(&:downcase)\n    groups = nil if groups.empty?\n\n    if mentions.present?\n      users =\n        User\n          .where(username_lower: mentions)\n          .includes(:do_not_disturb_timings)\n          .where.not(id: post.user_id)\n      users = nil if users.empty?\n    end",
    "comment": "TODO: Move to post-analyzer?",
    "label": "",
    "id": "639"
  },
  {
    "raw_code": "def extract_quoted_users(post)\n    usernames =\n      if SiteSetting.display_name_on_posts && !SiteSetting.prioritize_username_in_ux\n        post.raw.scan(/username:([[:alnum:]]*)\"(?=\\])/)\n      else\n        post.raw.scan(/\\[quote=\\\"([^,]+),.+\\\"\\]/)\n      end.uniq.map { |q| q.first.strip.downcase }\n    User.where.not(id: post.user_id).where(username_lower: usernames)\n  end",
    "comment": "TODO: Move to post-analyzer? Returns a list of users who were quoted in the post",
    "label": "",
    "id": "640"
  },
  {
    "raw_code": "def notify_non_pm_users(users, type, post, opts = {})\n    return [] if post.topic&.private_message?\n\n    notify_users(users, type, post, opts)\n  end",
    "comment": "Notify a bunch of users",
    "label": "",
    "id": "641"
  },
  {
    "raw_code": "def initialize(user, actor = nil, opts = nil)\n    @user = user\n    @actor = actor\n    @user_history = nil\n    @opts = opts || {}\n  end",
    "comment": "opts: anonymize_ip  - an optional new IP to update their logs with",
    "label": "",
    "id": "642"
  },
  {
    "raw_code": "def perform_search_query(bookmarks, query, ts_query)\n    bookmarkable_klass.search_query(bookmarks, query, ts_query) do |bookmarks_joined, where_sql|\n      bookmarks_joined.where(\"#{where_sql} OR bookmarks.name ILIKE :q\", q: query)\n    end",
    "comment": " The block here warrants explanation -- when the search_query is called, we call the provided block with the bookmark relation with additional joins as well as the where_sql string, and then also add the additional OR bookmarks.name filter. This is so every bookmarkable is filtered by its own customized columns _as well as_ the bookmark name, because the bookmark name must always be used in the search.  See BaseBookmarkable#search_query for argument docs.",
    "label": "",
    "id": "643"
  },
  {
    "raw_code": "def perform_preload(bookmarks, guardian)\n    bookmarks_of_type = Bookmark.select_type(bookmarks, bookmarkable_klass.model.to_s)\n    return if bookmarks_of_type.empty?\n\n    if bookmarkable_klass.has_preloads?\n      ActiveRecord::Associations::Preloader.new(\n        records: bookmarks_of_type,\n        associations: [bookmarkable: bookmarkable_klass.preload_associations],\n      ).call\n    end",
    "comment": " When displaying the bookmarks in a list for a user there is often additional information drawn from other tables joined to the bookmarkable that must be displayed. We preload these additional associations here on top of the array of bookmarks which has already been filtered, offset by page, ordered, and limited. The preload_associations array should be in the same format as used for .includes() e.g.  [{ topic: [:topic_users, :tags] }, :user]  For more advanced preloading, bookmarkable classes can implement `perform_custom_preload!`  @param [Array] bookmarks The array of bookmarks after initial listing and filtering, note this is array _not_ an ActiveRecord::Relation. @return [void]",
    "label": "",
    "id": "644"
  },
  {
    "raw_code": "def destroy(user, opts = {})\n    raise Discourse::InvalidParameters.new(\"user is nil\") unless user && user.is_a?(User)\n    raise PostsExistError if !opts[:delete_posts] && user.posts.joins(:topic).count != 0\n    @guardian.ensure_can_delete_user!(user)\n\n    # default to using a transaction\n    opts[:transaction] = true if opts[:transaction] != false\n\n    prepare_for_destroy(user) if opts[:prepare_for_destroy] == true\n\n    result = nil\n\n    optional_transaction(open_transaction: opts[:transaction]) do\n      UserSecurityKey.where(user_id: user.id).delete_all\n      Bookmark.where(user_id: user.id).delete_all\n      Draft.where(user_id: user.id).delete_all\n      Reviewable.where(created_by_id: user.id).delete_all\n\n      category_topic_ids = Category.where(\"topic_id IS NOT NULL\").pluck(:topic_id)\n\n      if opts[:delete_posts]\n        DiscoursePluginRegistry.user_destroyer_on_content_deletion_callbacks.each do |cb|\n          cb.call(user, @guardian, opts)\n        end",
    "comment": "Returns false if the user failed to be deleted. Returns a frozen instance of the User if the delete succeeded.",
    "label": "",
    "id": "645"
  },
  {
    "raw_code": "def self.model\n    raise NotImplementedError\n  end",
    "comment": "@return [ActiveRecord::Base] The ActiveRecord model class which will be used to denote the type of the bookmarkable upon registration along with querying.",
    "label": "",
    "id": "646"
  },
  {
    "raw_code": "def self.serializer\n    raise NotImplementedError\n  end",
    "comment": "@return [ApplicationSerializer] The serializer class inheriting from UserBookmarkBaseSerializer",
    "label": "",
    "id": "647"
  },
  {
    "raw_code": "def self.preload_associations\n    nil\n  end",
    "comment": "@return [Array] Used for preloading associations on the bookmarks for listing purposes. Should be in the same format used for .includes() e.g.  [{ topic: [:topic_users, :tags] }, :user]",
    "label": "",
    "id": "648"
  },
  {
    "raw_code": "def self.perform_custom_preload!(bookmarks_of_type, guardian)\n    nil\n  end",
    "comment": "  Implementations can define their own preloading logic here @param [Array] bookmarks_of_type The list of bookmarks to preload data for. Already filtered to be of the correct class. @param [Guardian] guardian An instance of Guardian for the current_user",
    "label": "",
    "id": "649"
  },
  {
    "raw_code": "def self.list_query(user, guardian)\n    raise NotImplementedError\n  end",
    "comment": " This is where the main query to filter the bookmarks by the provided bookmarkable type should occur. This should join on additional tables that are required later on to preload additional data for serializers, and also is the place where the bookmarks should be filtered based on security checks, which is why the Guardian instance is provided.  @param [User] user The user to perform the query for, this scopes the bookmarks returned. @param [Guardian] guardian An instance of Guardian for the user to be used for security filters. @return [Bookmark::ActiveRecord_AssociationRelation] Should be an appropriately scoped list of bookmarks for the user.",
    "label": "",
    "id": "650"
  },
  {
    "raw_code": "def self.search_query(bookmarks, query, ts_query, &bookmarkable_search)\n    raise NotImplementedError\n  end",
    "comment": " Called from BookmarkQuery when the initial results have been returned by perform_list_query. The search_query should join additional tables required to filter the bookmarks further, as well as defining a string used for where_sql, which can include comparisons with the :q parameter.  @param [Bookmark::ActiveRecord_Relation] bookmarks The bookmark records returned by perform_list_query @param [String] query The search query from the user surrounded by the %% wildcards @param [String] ts_query The postgres TSQUERY string used for comparisons with full text search columns @param [Block] bookmarkable_search This block _must_ be called with the additional WHERE clause SQL relevant for the bookmarkable to be searched, as well as the bookmarks relation with any additional joins applied. @return [Bookmark::ActiveRecord_AssociationRelation] The list of bookmarks from perform_list_query filtered further by the query parameter.",
    "label": "",
    "id": "651"
  },
  {
    "raw_code": "def self.reminder_conditions(bookmark)\n    raise NotImplementedError\n  end",
    "comment": " When sending bookmark reminders, we want to make sure that whatever we are sending the reminder for has not been deleted or is otherwise inaccessible. Most of the time we can just check if the bookmarkable record is present because it will be trashable, though in some cases there will be additional conditions in the form of a lambda that we should use instead.  The logic around whether it is the right time to send a reminder does not belong here, that is done in the BookmarkReminderNotifications job.  @param [Bookmark] bookmark The bookmark that we are considering sending a reminder for. @return [Boolean]",
    "label": "",
    "id": "652"
  },
  {
    "raw_code": "def self.reminder_handler(bookmark)\n    raise NotImplementedError\n  end",
    "comment": " Different bookmarkables may have different ways of notifying a user or presenting the reminder and what it is for, so it is up to the bookmarkable to register its preferred method of sending the reminder.  @param [Bookmark] bookmark The bookmark that we are sending the reminder notification for. @return [void]",
    "label": "",
    "id": "653"
  },
  {
    "raw_code": "def self.send_reminder_notification(bookmark, notification_data)\n    if notification_data[:data].blank? || notification_data[:data][:bookmarkable_url].blank? ||\n         notification_data[:data][:title].blank?\n      raise Discourse::InvalidParameters.new(\n              \"A `data` key must be present with at least `bookmarkable_url` and `title` entries.\",\n            )\n    end",
    "comment": " Can be used by the inheriting class via reminder_handler, most of the time we just want to make a Notification for a bookmark reminder, this gives consumers a way to do it without having provide all of the required data themselves.  @param [Bookmark] bookmark          The bookmark that we are sending the reminder notification for. @param [Hash]     notification_data Any data, either top-level (e.g. topic_id, post_number) or inside the data sub-key, which should be stored when the notification is created. @return [void]",
    "label": "",
    "id": "654"
  },
  {
    "raw_code": "def self.can_see?(guardian, bookmark)\n    raise NotImplementedError\n  end",
    "comment": " Access control is dependent on what has been bookmarked, the appropriate guardian can_see_X? method should be called from the bookmarkable class to determine whether the bookmarkable record (e.g. Post, Topic) is accessible by the guardian user.  @param [Guardian] guardian The guardian class for the user that we are performing the access check for. @param [Bookmark] bookmark The bookmark which we are checking access for using the bookmarkable association. @return [Boolean]",
    "label": "",
    "id": "655"
  },
  {
    "raw_code": "def self.can_see_bookmarkable?(guardian, bookmarkable)\n    raise NotImplementedError\n  end",
    "comment": " The can_see? method calls this one directly. can_see_bookmarkable? can be used in cases where you know the bookmarkable based on type but don't have a bookmark record to check against.  @param [Guardian] guardian The guardian class for the user that we are performing the access check for. @param [Bookmark] bookmarkable The bookmarkable which we are checking access for (e.g. Post, Topic) which is an ActiveModel instance. @return [Boolean]",
    "label": "",
    "id": "656"
  },
  {
    "raw_code": "def self.bookmark_metadata(bookmark, user)\n    {}\n  end",
    "comment": " Some additional information about the bookmark or the surrounding relations may be required when the bookmark is created or destroyed. For example, when destroying a bookmark within a topic we need to know whether there are other bookmarks still remaining in the topic.  @param [Bookmark] bookmark The bookmark that we are retrieving additional metadata for. @param [User] user The current user which is accessing the bookmark metadata. @return [Hash] (optional)",
    "label": "",
    "id": "657"
  },
  {
    "raw_code": "def self.validate_before_create(guardian, bookmarkable)\n    # noop\n  end",
    "comment": " Optional bookmarkable specific validations may need to be run before a bookmark is created via the BookmarkManager. From here an error should be raised if there is an issue with the bookmarkable.  @param [Guardian] guardian The guardian for the user which is creating the bookmark. @param [Model] bookmarkable The ActiveRecord model which is acting as the bookmarkable for the new bookmark.",
    "label": "",
    "id": "658"
  },
  {
    "raw_code": "def self.after_create(guardian, bookmark, opts)\n    # noop\n  end",
    "comment": " Optional additional actions may need to occur after a bookmark is created via the BookmarkManager.  @param [Guardian] guardian The guardian for the user which is creating the bookmark. @param [Model] bookmark The bookmark which was created. @param [Hash] opts Additional options that may be passed down via BookmarkManager.",
    "label": "",
    "id": "659"
  },
  {
    "raw_code": "def self.after_destroy(guardian, bookmark, opts)\n    # noop\n  end",
    "comment": " Optional additional actions may need to occur after a bookmark is destroyed via the BookmarkManager.  @param [Guardian] guardian The guardian for the user which is destroying the bookmark. @param [Model] bookmark The bookmark which was destroyed. @param [Hash] opts Additional options that may be passed down via BookmarkManager.",
    "label": "",
    "id": "660"
  },
  {
    "raw_code": "def self.cleanup_deleted\n    # noop\n  end",
    "comment": " Some bookmarkable records are Trashable, and as such we don't delete the bookmark with dependent_destroy. This should be used to delete those records after a grace period, defined by the bookmarkable. For example, post bookmarks may be deleted 3 days after the post or topic is deleted.  In the case of bookmarkable records that are not trashable, and where dependent_destroy is not used, this should just delete the bookmarks pointing to the record which no longer exists in the database.",
    "label": "",
    "id": "661"
  },
  {
    "raw_code": "def convert\n      raise NotImplementedError, \"#{self.class} must implement #convert\"\n    end",
    "comment": "Starts the conversion process and returns a job identifier",
    "label": "",
    "id": "662"
  },
  {
    "raw_code": "def check_status(job_id)\n      raise NotImplementedError, \"#{self.class} must implement #check_status\"\n    end",
    "comment": "Checks the status of a conversion job Returns a symbol: STATUS_COMPLETE, STATUS_ERROR, or STATUS_PENDING",
    "label": "",
    "id": "663"
  },
  {
    "raw_code": "def handle_completion(job_id, output_path, new_sha1)\n      raise NotImplementedError, \"#{self.class} must implement #handle_completion\"\n    end",
    "comment": "Handles the completion of a successful conversion This is called by the job system when status is :complete",
    "label": "",
    "id": "664"
  },
  {
    "raw_code": "def bookmarkable_url\n    post.full_url\n  end",
    "comment": "NOTE: In the UI there are special topic-status and topic-link components to display the topic URL, this is only used for certain routes like the .ics bookmarks.",
    "label": "",
    "id": "665"
  },
  {
    "raw_code": "def linked_post_number\n    1\n  end",
    "comment": "NOTE: It does not matter what the linked post number is for topic bookmarks, on the client we always take the user to the last unread post in the topic when the bookmark URL is clicked",
    "label": "",
    "id": "666"
  },
  {
    "raw_code": "def bookmarkable_url\n    if @options[:link_to_first_unread_post]\n      Topic.url(topic_id, slug, (last_read_post_number || 0) + 1)\n    else\n      topic.url\n    end",
    "comment": "NOTE: In the UI there are special topic-status and topic-link components to display the topic URL, this is only used for certain routes like the .ics bookmarks.",
    "label": "",
    "id": "667"
  },
  {
    "raw_code": "def self.add_compared_field(field)\n    changes_name = \"#{field}_changes\".to_sym\n\n    self.attributes changes_name\n    define_method(changes_name) { { previous: previous[field], current: current[field] } }\n\n    define_method(\"include_#{changes_name}?\") { previous[field] != current[field] }\n  end",
    "comment": "Creates a field called field_name_changes with previous and current members if a field has changed in this revision",
    "label": "",
    "id": "668"
  },
  {
    "raw_code": "def sort_order\n    10 - object.id\n  end",
    "comment": "change this if/when we allow custom badge types correct for now, though",
    "label": "",
    "id": "669"
  },
  {
    "raw_code": "def about_url\n    object.about_url if UrlHelper.is_valid_url?(object.about_url)\n  end",
    "comment": "ActiveModelSerializer has some pretty nutty logic where it tries to find the path here from action dispatch, tell it not to",
    "label": "",
    "id": "670"
  },
  {
    "raw_code": "def staff_attributes(*attrs)\n  end",
    "comment": "remove staff attributes",
    "label": "",
    "id": "671"
  },
  {
    "raw_code": "def can_remove_self_id\n    scope.user.id\n  end",
    "comment": "confusingly this is an id, not a bool like all other `can` methods",
    "label": "",
    "id": "672"
  },
  {
    "raw_code": "def can_edit\n    scope.can_edit?(object.topic)\n  end",
    "comment": "NOTE: A Category Group Moderator moving a topic to a different category may result in the 'can_edit?' result changing from `true` to `false`. Explicitly returning a `false` value is required to update the client UI.",
    "label": "",
    "id": "673"
  },
  {
    "raw_code": "def self.target_attributes(*attributes)\n    attributes.each { |a| create_attribute(a, \"object.target&.#{a}\") }\n  end",
    "comment": "This is easier than creating an AMS method for each attribute",
    "label": "",
    "id": "674"
  },
  {
    "raw_code": "def topic\n    return @topic if @topic\n    @topic = object.topic || Topic.with_deleted.find_by_id(object.topic_id)\n  end",
    "comment": "we need this to handle deleted topics which aren't loaded via Topic.unscoped do Post.includes(:topic) end because Rails 4 \"unscoped\" support is still bugged (cf. https://github.com/rails/rails/issues/13775)",
    "label": "",
    "id": "675"
  },
  {
    "raw_code": "def themeable_site_settings\n    # UI for editing settings always expects the value + default to be a string\n    # to compare whether the setting has been changed or not.\n    object.themeable_site_settings.each do |tss|\n      tss[:default] = tss[:default].to_s\n      tss[:value] = tss[:value].to_s\n    end",
    "comment": "Components always return an empty array here",
    "label": "",
    "id": "676"
  },
  {
    "raw_code": "def self.untrusted_attributes(*attrs)\n    attributes(*attrs)\n    attrs.each do |attr|\n      method_name = \"include_#{attr}?\"\n      define_method(method_name) do\n        return false if scope.restrict_user_fields?(object)\n        public_send(attr).present?\n      end",
    "comment": "attributes that are hidden for TL0 users when seen by anonymous",
    "label": "",
    "id": "677"
  },
  {
    "raw_code": "def can_send_private_messages\n    scope.can_send_private_messages?\n  end",
    "comment": "Needed because 'send_private_message_to_user' will always return false when the current user is being serialized",
    "label": "",
    "id": "678"
  },
  {
    "raw_code": "def has_topic_user?\n    object.topic_user.present?\n  end",
    "comment": "Topic user stuff",
    "label": "",
    "id": "679"
  },
  {
    "raw_code": "def title\n    ReviewableScore.type_title(type)\n  end",
    "comment": "Allow us to share post action type translations for backwards compatibility",
    "label": "",
    "id": "680"
  },
  {
    "raw_code": "def unread\n    0\n  end",
    "comment": "TODO: For backwards compatibility with themes, Remove once Discourse 2.8 is released",
    "label": "",
    "id": "681"
  },
  {
    "raw_code": "def new_posts\n    unread_helper.unread_posts\n  end",
    "comment": "TODO: For backwards compatibility with themes, Remove once Discourse 2.8 is released",
    "label": "",
    "id": "682"
  },
  {
    "raw_code": "def custom_url\n    object.custom_url\n  end",
    "comment": "ensures that the \"/custom\" route doesn't trigger the magic custom_url helper in ActionDispatch",
    "label": "",
    "id": "683"
  },
  {
    "raw_code": "def user_notification_schedule\n    UserNotificationScheduleSerializer.new(\n      object.user_notification_schedule,\n      scope: scope,\n      root: false,\n    ).as_json || UserNotificationSchedule::DEFAULT\n  end",
    "comment": " ATTRIBUTES  ",
    "label": "",
    "id": "684"
  },
  {
    "raw_code": "def post_count\n    object.user_stat.try(:post_count)\n  end",
    "comment": " STAFF ATTRIBUTES ",
    "label": "",
    "id": "685"
  },
  {
    "raw_code": "def muted_category_ids\n    categories_with_notification_level(:muted)\n  end",
    "comment": " PRIVATE ATTRIBUTES ",
    "label": "",
    "id": "686"
  },
  {
    "raw_code": "def actions\n    return post_actions if post_actions.present?\n    return all_post_actions[object.id] if all_post_actions.present?\n    nil\n  end",
    "comment": "Helper function to decide between #post_actions and @all_post_actions",
    "label": "",
    "id": "687"
  },
  {
    "raw_code": "def actions_summary\n    result = []\n    can_see_post = scope.can_see_post?(object)\n\n    @post_action_type_view =\n      @topic_view ? @topic_view.post_action_type_view : PostActionTypeView.new\n\n    public_flag_types = @post_action_type_view.public_types\n\n    @post_action_type_view.types.each do |sym, id|\n      count_col = \"#{sym}_count\".to_sym\n\n      count = object.public_send(count_col) if object.respond_to?(count_col)\n      summary = { id: id, count: count }\n\n      if scope.post_can_act?(\n           object,\n           sym,\n           opts: {\n             taken_actions: actions,\n             notify_flag_types: @post_action_type_view.notify_flag_types,\n             additional_message_types: @post_action_type_view.additional_message_types,\n             post_action_type_view: @post_action_type_view,\n           },\n           can_see_post: can_see_post,\n         )\n        summary[:can_act] = true\n      end",
    "comment": "Summary of the actions taken on this post",
    "label": "",
    "id": "688"
  },
  {
    "raw_code": "def include_locked?\n    object.locked? && (yours || scope.is_staff?)\n  end",
    "comment": "Only show locked posts to the users who made the post and staff",
    "label": "",
    "id": "689"
  },
  {
    "raw_code": "def reviewable_id\n    if @topic_view.present?\n      for_post = @topic_view.reviewable_counts[object.id]\n      return for_post ? for_post[:reviewable_id] : 0\n    end",
    "comment": "If we have a topic view, it has bulk values for the reviewable content we can use",
    "label": "",
    "id": "690"
  },
  {
    "raw_code": "def self.set_log_path(path)\n        @@log_path = path\n        @@logger = nil\n      end",
    "comment": "For test environment only",
    "label": "",
    "id": "691"
  },
  {
    "raw_code": "def self.reset_log_path\n        @@log_path = nil\n        @@logger = nil\n      end",
    "comment": "For test environment only",
    "label": "",
    "id": "692"
  },
  {
    "raw_code": "def error_context(opts, code_desc = nil, extra = {})\n      ctx = {}\n      ctx[:opts] = opts\n      ctx[:job] = self.class\n      ctx[:message] = code_desc if code_desc\n      ctx.merge!(extra) if extra != nil\n      ctx\n    end",
    "comment": "Construct an error context object for Discourse.handle_exception Subclasses are encouraged to use this!  `opts` is the arguments passed to execute(). `code_desc` is a short string describing what the code was doing (optional). `extra` is for any other context you logged. Note that, when building your `extra`, that :opts, :job, and :code are used by this method, and :current_db and :current_hostname are used by handle_exception.",
    "label": "",
    "id": "693"
  },
  {
    "raw_code": "def execute(args)\n    job_name = self.class.name_for(self.class)\n    has_lock = Discourse.redis.setnx(running_key_name, Time.now.to_i)\n\n    # If we can't get a lock, just noop\n    if args[:force] || has_lock\n      begin\n        return if OnceoffLog.where(job_name: job_name).exists? && !args[:force]\n        execute_onceoff(args)\n        OnceoffLog.create!(job_name: job_name)\n      ensure\n        Discourse.redis.del(running_key_name) if has_lock\n      end",
    "comment": "Pass `force: true` to force it happen again",
    "label": "",
    "id": "694"
  },
  {
    "raw_code": "def execute_onceoff(args)\n      DB.exec <<~SQL\n        DELETE\n        FROM post_timings pt\n        WHERE NOT EXISTS(\n                SELECT 1\n                FROM posts p\n                WHERE p.topic_id = pt.topic_id\n                  AND p.post_number = pt.post_number\n            )\n      SQL\n\n      DB.exec <<~SQL\n        DELETE\n        FROM post_timings pt\n        WHERE NOT EXISTS(\n                SELECT 1\n                FROM users u\n                WHERE pt.user_id = u.id\n            )\n      SQL\n    end",
    "comment": "Remove post timings that are remnants of previous post moves or other shenanigans and don't reference a valid user or post anymore.",
    "label": "",
    "id": "695"
  },
  {
    "raw_code": "def execute(args)\n    topic = Topic.find_by(id: args[:topic_id])\n    return if topic.blank?\n\n    UserAction\n      .where(\n        target_topic_id: topic.id,\n        action_type: [UserAction::GOT_PRIVATE_MESSAGE, UserAction::NEW_PRIVATE_MESSAGE],\n      )\n      .find_each do |ua|\n        UserAction.remove_action!(\n          ua.attributes.symbolize_keys.slice(\n            :action_type,\n            :user_id,\n            :acting_user_id,\n            :target_topic_id,\n            :target_post_id,\n          ),\n        )\n      end",
    "comment": "Re-creating all the user actions could be very slow, so let's do it in a job to avoid a N+1 query on a front facing operation.",
    "label": "",
    "id": "696"
  },
  {
    "raw_code": "def update_cooked(cooked)\n      doc = Nokogiri::HTML5.fragment(cooked)\n\n      @quote_rewriter.rewrite_cooked_display_name(doc, old_display_name, new_display_name)\n\n      doc.to_html\n    end",
    "comment": "Uses Nokogiri instead of rebake, because it works for posts and revisions and there is no reason to invalidate oneboxes, run the post analyzer etc. when only the display name changes.",
    "label": "",
    "id": "697"
  },
  {
    "raw_code": "def update_cooked(cooked)\n      doc = Nokogiri::HTML5.fragment(cooked)\n\n      doc\n        .css(\"a.mention\")\n        .each do |a|\n          a.content = a.content.gsub(@cooked_mention_username_regex, \"@#{@new_username}\")\n          a[\"href\"] = a[\"href\"].gsub(\n            @cooked_mention_user_path_regex,\n            \"/u/#{UrlHelper.encode_component(@new_username)}\",\n          ) if a[\"href\"]\n        end",
    "comment": "Uses Nokogiri instead of rebake, because it works for posts and revisions and there is no reason to invalidate oneboxes, run the post analyzer etc. when only the username changes.",
    "label": "",
    "id": "698"
  },
  {
    "raw_code": "def extract_links(post)\n      TopicLink.extract_from(post)\n      QuotedPost.extract_from(post)\n    end",
    "comment": "onebox may have added some links, so extract them now",
    "label": "",
    "id": "699"
  },
  {
    "raw_code": "def execute(args)\n    raise Discourse::InvalidParameters.new(:user_ids) if args[:user_ids].blank?\n\n    args[:user_ids].each do |u|\n      user_stat = UserStat.find_by(user_id: u)\n      next if user_stat.blank?\n\n      total = user_stat.flags_agreed + user_stat.flags_disagreed + user_stat.flags_ignored\n      next if total < self.class.truncate_to\n\n      params =\n        ReviewableScore\n          .statuses\n          .slice(:agreed, :disagreed, :ignored)\n          .merge(user_id: u, truncate_to: self.class.truncate_to)\n\n      result = DB.query(<<~SQL, params)\n        SELECT SUM(CASE WHEN x.status = :agreed THEN 1 ELSE 0 END) AS agreed,\n          SUM(CASE WHEN x.status = :disagreed THEN 1 ELSE 0 END) AS disagreed,\n          SUM(CASE WHEN x.status = :ignored THEN 1 ELSE 0 END) AS ignored\n        FROM (\n          SELECT rs.status\n          FROM reviewable_scores AS rs\n          INNER JOIN reviewables AS r ON r.id = rs.reviewable_id\n          INNER JOIN posts AS p ON p.id = r.target_id\n          WHERE rs.user_id = :user_id\n            AND r.type = 'ReviewableFlaggedPost'\n            AND rs.status IN (:agreed, :disagreed, :ignored)\n            AND rs.user_id <> p.user_id\n          ORDER BY rs.created_at DESC\n          LIMIT :truncate_to\n        ) AS x\n      SQL\n\n      user_stat.update_columns(\n        flags_agreed: result[0].agreed || 0,\n        flags_disagreed: result[0].disagreed || 0,\n        flags_ignored: result[0].ignored || 0,\n      )\n    end",
    "comment": "To give users a chance to improve, we limit their flag stats to the last N flags",
    "label": "",
    "id": "700"
  },
  {
    "raw_code": "def quit_email_early?\n      SiteSetting.disable_emails == \"yes\"\n    end",
    "comment": "Can be overridden by subclass, for example critical email should always consider being sent",
    "label": "",
    "id": "701"
  },
  {
    "raw_code": "def skip_email_for_post(post, user)\n      return false unless post\n\n      return SkippedEmailLog.reason_types[:user_email_topic_nil] if post.topic.blank?\n\n      return SkippedEmailLog.reason_types[:user_email_post_user_deleted] if post.user.blank?\n\n      return SkippedEmailLog.reason_types[:user_email_post_deleted] if post.user_deleted?\n\n      if user.suspended? && (!post.user&.staff? || !post.user&.human?)\n        return SkippedEmailLog.reason_types[:user_email_user_suspended]\n      end",
    "comment": "If this email has a related post, don't send an email if it's been deleted or seen recently.",
    "label": "",
    "id": "702"
  },
  {
    "raw_code": "def self.min_reviewables\n    15\n  end",
    "comment": "We need this many reviewables before we'll calculate priorities",
    "label": "",
    "id": "703"
  },
  {
    "raw_code": "def self.target_count\n    2\n  end",
    "comment": "We want to look at scores for items with this many reviewables (flags) attached",
    "label": "",
    "id": "704"
  },
  {
    "raw_code": "def send_rejection(template, message_from, template_args)\n    if template_args.keys.any? { |k| DISALLOWED_TEMPLATE_ARGS.include? k }\n      raise ArgumentError.new(\"Reserved key in template arguments\")\n    end",
    "comment": "Send an email rejection message.  template - i18n key under system_messages message_from - Who to send the rejection message to template_args - arguments to pass to i18n for interpolation into the message Certain keys are disallowed in template_args to avoid confusing the BuildEmailHelper. You can see the list in DISALLOWED_TEMPLATE_ARGS.",
    "label": "",
    "id": "705"
  },
  {
    "raw_code": "def title\n        return I18n.t(\"reports.#{type}.title_legacy\") if legacy?\n        I18n.t(\"reports.#{type}.title\")\n      end",
    "comment": "HACK: We need to show a different label and description for some old reports while people are still relying on them, that lets us point toward the new 'Site traffic' report as well. Not ideal, but apart from duplicating the report there's not a nicer way to do this.",
    "label": "",
    "id": "706"
  },
  {
    "raw_code": "def cards\n    guardian.ensure_public_can_see_profiles!\n\n    user_ids = params.require(:user_ids).split(\",\").map(&:to_i)\n    raise Discourse::InvalidParameters.new(:user_ids) if user_ids.length > 50\n\n    users =\n      User.where(id: user_ids).includes(\n        :user_option,\n        :user_stat,\n        :default_featured_user_badges,\n        :user_profile,\n        :card_background_upload,\n        :primary_group,\n        :flair_group,\n        :primary_email,\n        :user_status,\n      )\n\n    users = users.filter { |u| guardian.can_see_profile?(u) }\n\n    preload_fields =\n      User.allowed_user_custom_fields(guardian) +\n        UserField.all.pluck(:id).map { |fid| \"#{User::USER_FIELD_PREFIX}#{fid}\" }\n    User.preload_custom_fields(users, preload_fields)\n    User.preload_recent_time_read(users)\n\n    render json: users, each_serializer: UserCardSerializer\n  end",
    "comment": "This route is not used in core, but is used by theme components (e.g. https://meta.discourse.org/t/144479)",
    "label": "",
    "id": "707"
  },
  {
    "raw_code": "def check_username\n    if !params[:username].present?\n      params.require(:username) if !params[:email].present?\n      return render(json: success_json)\n    end",
    "comment": "Used for checking availability of a username and will return suggestions if the username is not available.",
    "label": "",
    "id": "708"
  },
  {
    "raw_code": "def perform_accept_invitation\n    params.require(:id)\n    params.permit(\n      :email,\n      :username,\n      :name,\n      :password,\n      :timezone,\n      :email_token,\n      user_custom_fields: {\n      },\n    )\n\n    raise Discourse::NotFound if SiteSetting.enable_discourse_connect\n\n    invite = Invite.find_by(invite_key: params[:id])\n    redeeming_user = current_user\n\n    if invite.present?\n      begin\n        attrs = { ip_address: request.remote_ip, session: session }\n\n        if redeeming_user\n          attrs[:redeeming_user] = redeeming_user\n        else\n          attrs[:username] = params[:username]\n          attrs[:name] = params[:name]\n          attrs[:password] = params[:password]\n          attrs[:user_custom_fields] = params[:user_custom_fields]\n\n          # If the invite is not scoped to an email then we allow the\n          # user to provide it themselves\n          if invite.is_invite_link?\n            params.require(:email)\n            attrs[:email] = params[:email]\n          else\n            # Otherwise we always use the email from the invitation.\n            attrs[:email] = invite.email\n            attrs[:email_token] = params[:email_token] if params[:email_token].present?\n          end",
    "comment": "For DiscourseConnect SSO, all invite acceptance is done via the SessionController#sso_login route",
    "label": "",
    "id": "709"
  },
  {
    "raw_code": "def handle_unverified_request\n    # NOTE: API key is secret, having it invalidates the need for a CSRF token\n    unless is_api? || is_user_api?\n      super\n      clear_current_user\n      render plain: \"[\\\"BAD CSRF\\\"]\", status: 403\n    end",
    "comment": "Default Rails 3.2 lets the request through with a blank session we are being more pedantic here and nulling session / current_user and then raising a CSRF exception",
    "label": "",
    "id": "710"
  },
  {
    "raw_code": "def self.requires_plugin(plugin_name)\n    before_action do\n      if plugin = Discourse.plugins_by_name[plugin_name]\n        raise PluginDisabled.new if !plugin.enabled?\n      elsif Rails.env.test?\n        raise \"Required plugin '#{plugin_name}' not found. The string passed to requires_plugin should match the plugin's name at the top of plugin.rb\"\n      else\n        Rails.logger.warn(\"Required plugin '#{plugin_name}' not found\")\n      end",
    "comment": "If a controller requires a plugin, it will raise an exception if that plugin is disabled. This allows plugins to be disabled programmatically.",
    "label": "",
    "id": "711"
  },
  {
    "raw_code": "def render_serialized(obj, serializer, opts = nil)\n    render_json_dump(serialize_data(obj, serializer, opts), opts)\n  end",
    "comment": "This is odd, but it seems that in Rails `render json: obj` is about 20% slower than calling MultiJSON.dump ourselves. I'm not sure why Rails doesn't call MultiJson.dump when you pass it json: obj but it seems we don't need whatever Rails is doing.",
    "label": "",
    "id": "712"
  },
  {
    "raw_code": "def discourse_expires_in(time_length)\n    return unless can_cache_content?\n    Middleware::AnonymousCache.anon_cache(request.env, time_length)\n  end",
    "comment": "Our custom cache method",
    "label": "",
    "id": "713"
  },
  {
    "raw_code": "def preload_json\n    return if request.format&.json? || request.xhr? || !request.get?\n    @_preloaded = {}\n  end",
    "comment": "This method is intended to be a no-op. The only reason this `before_action` callback continues to exist is for backwards compatibility purposes which we cannot easily solve at this point. In the `rescue_discourse_actions` method, the `@_preloaded` instance variable is used to determine if the `no_ember` or `application` layout should be used. To use the `no_ember` layout, controllers have been setting `skip_before_action :preload_json`. This is however a flawed implementation as which layout is used for rendering errors should ideally not be set by skipping a `before_action` callback. To fix this properly will require some careful planning which we do not intend to tackle at this point.",
    "label": "",
    "id": "714"
  },
  {
    "raw_code": "def render_json_error(obj, opts = {})\n    opts = { status: opts } if opts.is_a?(Integer)\n    opts.fetch(:headers, {}).each { |name, value| headers[name.to_s] = value }\n\n    render(\n      json: MultiJson.dump(create_errors_json(obj, opts)),\n      status: opts[:status] || status_code(obj),\n    )\n  end",
    "comment": "Render action for a JSON error.  obj       - a translated string, an ActiveRecord model, or an array of translated strings opts: type    - a machine-readable description of the error status  - HTTP status code to return headers - extra headers for the response",
    "label": "",
    "id": "715"
  },
  {
    "raw_code": "def param_to_integer_list(key, delimiter = \",\")\n    case params[key]\n    when String\n      params[key].split(delimiter).map(&:to_i)\n    when Array\n      params[key].map(&:to_i)\n    end",
    "comment": "returns an array of integers given a param key returns nil if key is not found",
    "label": "",
    "id": "716"
  },
  {
    "raw_code": "def add_early_hint_header\n    return if GlobalSetting.early_hint_header_mode.nil?\n\n    links = []\n\n    if GlobalSetting.early_hint_header_mode == \"preconnect\"\n      [GlobalSetting.cdn_url, SiteSetting.s3_cdn_url].each do |url|\n        next if url.blank?\n        base_url = URI.join(url, \"/\").to_s.chomp(\"/\")\n        links.push(\"<#{base_url}>; rel=preconnect\")\n      end",
    "comment": "We don't actually send 103 Early Hint responses from Discourse. However, upstream proxies can be configured to cache a response header from the app and use that to send an Early Hint response to future clients. See 'early_hint_header_mode' and 'early_hint_header_name' Global Setting descriptions for more info.",
    "label": "",
    "id": "717"
  },
  {
    "raw_code": "def enter\n    params.delete(:username)\n    params.delete(:password)\n\n    destination = extract_redirect_param\n\n    allow_other_hosts = false\n\n    if cookies[:sso_destination_url]\n      destination = cookies.delete(:sso_destination_url)\n      allow_other_hosts = true\n    end",
    "comment": "This method just redirects to a given url. It's used when an ajax login was successful but we want the browser to see a post of a login form so that it offers to remember your password.",
    "label": "",
    "id": "718"
  },
  {
    "raw_code": "def favicon\n    is_asset_path\n\n    hijack do\n      data =\n        DistributedMemoizer.memoize(\"FAVICON#{SiteIconManager.favicon_url}\", 60 * 30) do\n          favicon = SiteIconManager.favicon\n          next \"\" unless favicon\n\n          if Discourse.store.external?\n            begin\n              file =\n                FileHelper.download(\n                  Discourse.store.cdn_url(favicon.url),\n                  max_file_size: favicon.filesize,\n                  tmp_file_name: FAVICON,\n                  follow_redirect: true,\n                )\n\n              file&.read || \"\"\n            rescue => e\n              ProblemCheckTracker[:bad_favicon_url].problem!\n              Rails.logger.debug(\"Failed to fetch favicon #{favicon.url}: #{e}\\n#{e.backtrace}\")\n              \"\"\n            ensure\n              file&.unlink\n            end",
    "comment": "We need to be able to draw our favicon on a canvas, this happens when you enable the feature that draws the notification count on top of favicon (per user default off)  With s3 the original upload is going to be stored at s3, we don't have a local copy of the favicon. To allow canvas to work with s3 we are going to need to add special CORS headers and use a special crossorigin hint on the original, this is not easily workable.  Forcing all consumers to set magic CORS headers on a CDN is also not workable for us.  So we cache the favicon in redis and serve it out real quick with a huge expiry, we also cache these assets in nginx so it is bypassed if needed",
    "label": "",
    "id": "719"
  },
  {
    "raw_code": "def fetch_badge_from_params\n    badge = nil\n\n    params.permit(:badge_name)\n    if params[:badge_name].nil?\n      params.require(:badge_id)\n      badge = Badge.find_by(id: params[:badge_id], enabled: true)\n    else\n      badge = Badge.find_by(name: params[:badge_name], enabled: true)\n    end",
    "comment": "Get the badge from either the badge name or id specified in the params.",
    "label": "",
    "id": "720"
  },
  {
    "raw_code": "def not_found_body\n    render html: build_not_found_page(status: 200)\n  end",
    "comment": "Give us an endpoint to use for 404 content in the ember app",
    "label": "",
    "id": "721"
  },
  {
    "raw_code": "def backwards_compatible_json(json_obj)\n    json_obj.symbolize_keys!\n\n    success = json_obj[:success]\n\n    if params[:nested_post].blank? && json_obj[:errors].blank? &&\n         json_obj[:action].to_s != \"enqueued\"\n      json_obj = json_obj[:post]\n    end",
    "comment": "We can't break the API for making posts. The new, queue supporting API doesn't return the post as the root JSON object, but as a nested object. If a param is present it uses that result structure.",
    "label": "",
    "id": "722"
  },
  {
    "raw_code": "def sso_url(sso)\n    sso.to_url\n  end",
    "comment": "extension to allow plugins to customize the SSO URL",
    "label": "",
    "id": "723"
  },
  {
    "raw_code": "def validate_invitiation!(sso)\n    invite_key = server_session[\"invite-key\"]\n    return if invite_key.blank?\n\n    invite = Invite.find_by(invite_key: invite_key)\n\n    if invite.blank?\n      raise Invite::ValidationFailed.new(I18n.t(\"invite.not_found\", base_url: Discourse.base_url))\n    end",
    "comment": "the invite_key will be present if set in InvitesController when the user visits an /invites/xxxx link; however we do not want to complete the SSO process of creating a user and redeeming the invite if the invite is not redeemable or for the wrong user",
    "label": "",
    "id": "724"
  },
  {
    "raw_code": "def max_file_size\n    1.megabyte\n  end",
    "comment": "Allow plugins to overwrite max file size value",
    "label": "",
    "id": "725"
  },
  {
    "raw_code": "def render_blank\n    path = Rails.root + \"public/images/avatar.png\"\n    expires_in 10.minutes, public: true\n    response.headers[\"Last-Modified\"] = Time.new(1990, 01, 01).httpdate\n    response.headers[\"Content-Length\"] = File.size(path).to_s\n    send_file path, disposition: nil\n  end",
    "comment": "this protects us from a DoS",
    "label": "",
    "id": "726"
  },
  {
    "raw_code": "def get_optimized_image(upload, size)\n    return if !upload\n    return upload if upload.extension == \"svg\"\n\n    upload.get_optimized_image(size, size)\n    # TODO decide if we want to detach here\n  end",
    "comment": "consider removal of hacks some time in 2019",
    "label": "",
    "id": "727"
  },
  {
    "raw_code": "def _show_secure_deprecated\n    show_secure\n  end",
    "comment": "Kept to avoid rebaking old posts with /show-secure-uploads/ in their contents, this will ensure the uploads in these posts continue to work in future.",
    "label": "",
    "id": "728"
  },
  {
    "raw_code": "def attachment_too_big?(file_name, file_size)\n    !FileHelper.is_supported_image?(file_name) &&\n      file_size >= UploadsController.max_attachment_size_for_user(current_user).kilobytes\n  end",
    "comment": "We can preemptively check size for attachments, but not for (most) images as they may be further reduced in size by UploadCreator (at this point they may have already been reduced in size by preprocessors)",
    "label": "",
    "id": "729"
  },
  {
    "raw_code": "def image_too_big?(file_name, file_size)\n    FileHelper.is_supported_image?(file_name) && File.extname(file_name) == \".gif\" &&\n      file_size >= SiteSetting.max_image_size_kb.kilobytes\n  end",
    "comment": "Gifs are not resized on the client and not reduced in size by UploadCreator",
    "label": "",
    "id": "730"
  },
  {
    "raw_code": "def builder\n    result = self.class.fetch_default_robots_info\n    overridden = SiteSetting.overridden_robots_txt\n    result[:overridden] = overridden if overridden.present?\n    render json: result\n  end",
    "comment": "If you are hosting Discourse in a subfolder, you will need to create your robots.txt in the root of your web server with the appropriate paths. This method will return JSON that can be used by a script to create a robots.txt that works well with your existing site.",
    "label": "",
    "id": "731"
  },
  {
    "raw_code": "def penalty_history\n    # We don't delete any history, we merely remove the action type\n    # with a removed type. It can still be viewed in the logs but\n    # will not affect TL3 promotions.\n    sql = <<~SQL\n      UPDATE user_histories\n      SET action = CASE\n        WHEN action = :silence_user THEN :removed_silence_user\n        WHEN action = :unsilence_user THEN :removed_unsilence_user\n        WHEN action = :suspend_user THEN :removed_suspend_user\n        WHEN action = :unsuspend_user THEN :removed_unsuspend_user\n      END\n      WHERE target_user_id = :user_id\n        AND action IN (\n          :silence_user,\n          :suspend_user,\n          :unsilence_user,\n          :unsuspend_user\n        )\n    SQL\n\n    DB.exec(\n      sql,\n      UserHistory\n        .actions\n        .slice(\n          :silence_user,\n          :suspend_user,\n          :unsilence_user,\n          :unsuspend_user,\n          :removed_silence_user,\n          :removed_unsilence_user,\n          :removed_suspend_user,\n          :removed_unsuspend_user,\n        )\n        .merge(user_id: params[:user_id].to_i),\n    )\n\n    render json: success_json\n  end",
    "comment": "DELETE action to delete penalty history for a user",
    "label": "",
    "id": "732"
  },
  {
    "raw_code": "def update_badge_from_params(badge, opts = {})\n    errors = []\n    Badge.transaction do\n      allowed = Badge.column_names.map(&:to_sym)\n      allowed -= %i[id created_at updated_at grant_count]\n      allowed -= Badge.protected_system_fields if badge.system?\n      allowed -= [:query] unless SiteSetting.enable_badge_sql\n\n      params.permit(*allowed)\n\n      allowed.each { |key| badge.public_send(\"#{key}=\", params[key]) if params[key] }\n\n      # Badge query contract checks\n      begin\n        if SiteSetting.enable_badge_sql\n          BadgeGranter.contract_checks!(\n            badge.query,\n            target_posts: badge.target_posts,\n            trigger: badge.trigger,\n          )\n        end",
    "comment": "Options: :new - reset the badge id to nil before saving",
    "label": "",
    "id": "733"
  },
  {
    "raw_code": "def theme_user\n    current_user\n  end",
    "comment": "Overridden by theme-creator plugin",
    "label": "",
    "id": "734"
  },
  {
    "raw_code": "def self.email_keys\n    @email_keys ||= %w[\n      admin_confirmation_mailer\n      custom_invite_forum_mailer\n      custom_invite_mailer\n      download_backup_mailer\n      invite_forum_mailer\n      invite_mailer\n      invite_password_instructions\n      new_version_mailer\n      new_version_mailer_with_notes\n      system_messages.backup_failed\n      system_messages.backup_succeeded\n      system_messages.bulk_invite_failed\n      system_messages.bulk_invite_succeeded\n      system_messages.csv_export_failed\n      system_messages.csv_export_succeeded\n      system_messages.download_remote_images_disabled\n      system_messages.email_error_notification\n      system_messages.email_reject_attachment\n      system_messages.email_reject_auto_generated\n      system_messages.email_reject_bad_destination_address\n      system_messages.email_reject_empty\n      system_messages.email_reject_inactive_user\n      system_messages.email_reject_insufficient_trust_level\n      system_messages.email_reject_invalid_access\n      system_messages.email_reject_invalid_post\n      system_messages.email_reject_invalid_post_action\n      system_messages.email_reject_invalid_post_specified\n      system_messages.email_reject_not_allowed_email\n      system_messages.email_reject_old_destination\n      system_messages.email_reject_parsing\n      system_messages.email_reject_post_too_short\n      system_messages.email_reject_reply_key\n      system_messages.email_reject_reply_not_allowed\n      system_messages.email_reject_reply_to_digest\n      system_messages.email_reject_reply_user_not_matching\n      system_messages.email_reject_screened_email\n      system_messages.email_reject_silenced_user\n      system_messages.email_reject_strangers_not_allowed\n      system_messages.email_reject_too_many_recipients\n      system_messages.email_reject_topic_closed\n      system_messages.email_reject_topic_not_found\n      system_messages.email_reject_unrecognized_error\n      system_messages.email_reject_user_not_found\n      system_messages.email_revoked\n      system_messages.flags_agreed_and_post_deleted\n      system_messages.flags_agreed_and_post_deleted_for_responders\n      system_messages.flags_disagreed\n      system_messages.ignored_users_summary\n      system_messages.new_user_of_the_month\n      system_messages.pending_users_reminder\n      system_messages.post_hidden\n      system_messages.post_hidden_again\n      system_messages.queued_by_staff\n      system_messages.queued_posts_reminder\n      system_messages.restore_failed\n      system_messages.restore_succeeded\n      system_messages.reviewable_queued_post_revise_and_reject\n      system_messages.reviewable_queued_post_revise_and_reject_new_topic\n      system_messages.reviewables_reminder\n      system_messages.silenced_by_staff\n      system_messages.spam_post_blocked\n      system_messages.tl2_promotion_message\n      system_messages.too_many_spam_flags\n      system_messages.too_many_tl3_flags\n      system_messages.unsilenced\n      system_messages.user_added_to_group_as_member\n      system_messages.user_added_to_group_as_owner\n      system_messages.user_automatically_silenced\n      system_messages.welcome_invite\n      system_messages.welcome_staff\n      system_messages.welcome_tl1_user\n      system_messages.welcome_user\n      test_mailer\n      unsubscribe_mailer\n      user_notifications.account_created\n      user_notifications.account_deleted\n      user_notifications.account_exists\n      user_notifications.account_second_factor_disabled\n      user_notifications.account_silenced\n      user_notifications.account_silenced_forever\n      user_notifications.account_suspended\n      user_notifications.account_suspended_forever\n      user_notifications.activation_reminder\n      user_notifications.admin_login\n      user_notifications.confirm_new_email\n      user_notifications.confirm_new_email_via_admin\n      user_notifications.confirm_old_email\n      user_notifications.confirm_old_email_add\n      user_notifications.email_login\n      user_notifications.forgot_password\n      user_notifications.notify_old_email\n      user_notifications.notify_old_email_add\n      user_notifications.post_approved\n      user_notifications.set_password\n      user_notifications.signup\n      user_notifications.signup_after_approval\n      user_notifications.signup_after_reject\n      user_notifications.suspicious_login\n      user_notifications.user_group_mentioned\n      user_notifications.user_group_mentioned_pm\n      user_notifications.user_group_mentioned_pm_group\n      user_notifications.user_invited_to_private_message_pm\n      user_notifications.user_invited_to_private_message_pm_group\n      user_notifications.user_invited_to_private_message_pm_staged\n      user_notifications.user_invited_to_topic\n      user_notifications.user_linked\n      user_notifications.user_mentioned\n      user_notifications.user_mentioned_pm\n      user_notifications.user_posted\n      user_notifications.user_posted_pm\n      user_notifications.user_posted_pm_staged\n      user_notifications.user_quoted\n      user_notifications.user_replied\n      user_notifications.user_replied_pm\n      user_notifications.user_watching_category_or_tag\n      user_notifications.user_watching_first_post\n    ]\n  end",
    "comment": "to update the list of keys below, run the `list_email_templates_strings` rake task and replace the list below with the output from the rake task",
    "label": "",
    "id": "735"
  },
  {
    "raw_code": "def create\n    file = params[:file] || params[:files].first\n    name = params[:name] || File.basename(file.original_filename, \".*\")\n    group = params[:group] ? params[:group].downcase : nil\n\n    hijack do\n      # fix the name\n      name = File.basename(name, \".*\")\n      name = Emoji.sanitize_emoji_name(name)\n      upload =\n        UploadCreator.new(file.tempfile, file.original_filename, type: \"custom_emoji\").create_for(\n          current_user.id,\n        )\n\n      good = true\n\n      data =\n        if upload.persisted?\n          custom_emoji =\n            CustomEmoji.new(name: name, upload: upload, group: group, user: current_user)\n\n          if custom_emoji.save\n            StaffActionLogger.new(current_user).log_custom_emoji_create(name, group: group)\n\n            Emoji.clear_cache\n            { name: custom_emoji.name, url: custom_emoji.upload.url, group: group }\n          else\n            good = false\n            failed_json.merge(errors: custom_emoji.errors.full_messages)\n          end",
    "comment": "NOTE: This kind of custom logic also needs to be implemented to be run in the ExternalUploadManager when a direct S3 upload is completed, related to preventDirectS3Uploads in the UppyUploadMixin.  Until then, preventDirectS3Uploads is set to true in the UppyUploadMixin.",
    "label": "",
    "id": "736"
  },
  {
    "raw_code": "def index\n    if params[:plugin].blank? && params[:categories].blank? && params[:filter_names].blank? &&\n         SiteSetting.valid_areas.exclude?(params[:filter_area])\n      raise Discourse::InvalidParameters\n    end",
    "comment": "This endpoint is intended to be used only for admin config areas, for a specific collection of site settings. The admin site settings UI itself uses the Admin::SiteSettingsController#index endpoint, which also supports a `category` and `plugin` filter.",
    "label": "",
    "id": "737"
  },
  {
    "raw_code": "def initialize(regex:, canonical:, targets:, names:, types:)\n      @allowed_values = {}\n      @allowed_values[:names] = Array(names) if names\n      @allowed_values[:targets] = Array(targets) if targets\n      @allowed_values[:types] = Array(types) if types\n      @canonical = canonical\n      @regex = regex\n    end",
    "comment": "regex: used to match file names to fields (import). can contain named capture groups for name/type/target canonical: a lambda which converts name/type/target to filename (export) targets/names/types: can be nil if any value is allowed single value array of allowed values",
    "label": "",
    "id": "738"
  },
  {
    "raw_code": "def file_path\n    FILE_MATCHERS.each do |matcher|\n      if filename =\n           matcher.filename_from_opts(\n             target: target_name.to_sym,\n             name: name,\n             type: ThemeField.types[type_id],\n             filename: upload&.original_filename,\n           )\n        return filename\n      end",
    "comment": "For now just work for standard fields",
    "label": "",
    "id": "739"
  },
  {
    "raw_code": "def Report.remove_report(name)\n    singleton_class.instance_eval { remove_method(\"report_#{name}\") }\n  end",
    "comment": "Only used for testing.",
    "label": "",
    "id": "740"
  },
  {
    "raw_code": "def self.req_report(report, filter = nil)\n    data =\n      # For this report we intentionally do not want to count mobile pageviews.\n      if filter == :page_view_total\n        SiteSetting.use_legacy_pageviews ? legacy_page_view_requests : page_view_requests\n        # This is a separate report because if people have switched over\n        # to _not_ use legacy pageviews, we want to show both a Pageviews\n        # and Legacy Pageviews report.\n      elsif filter == :page_view_legacy_total\n        legacy_page_view_requests\n      else\n        ApplicationRequest.where(req_type: ApplicationRequest.req_types[filter])\n      end",
    "comment": "NOTE: Once use_legacy_pageviews is always false or no longer needed we will no longer support the page_view_anon and page_view_logged_in reports, they can be removed.",
    "label": "",
    "id": "741"
  },
  {
    "raw_code": "def self.legacy_page_view_requests\n    ApplicationRequest.where(\n      req_type: [\n        ApplicationRequest.req_types[:page_view_crawler],\n        ApplicationRequest.req_types[:page_view_anon],\n        ApplicationRequest.req_types[:page_view_logged_in],\n      ].flatten,\n    )\n  end",
    "comment": "We purposefully exclude \"browser\" pageviews. See `ConsolidatedPageViewsBrowserDetection` for browser pageviews.",
    "label": "",
    "id": "742"
  },
  {
    "raw_code": "def self.page_view_requests\n    ApplicationRequest.where(\n      req_type: [\n        ApplicationRequest.req_types[:page_view_anon_browser],\n        ApplicationRequest.req_types[:page_view_logged_in_browser],\n      ].flatten,\n    )\n  end",
    "comment": "We purposefully exclude \"crawler\" pageviews here and by only doing browser pageviews we are excluding \"other\" pageviews too. This is to reflect what is shown in the \"Site traffic\" report by default.",
    "label": "",
    "id": "743"
  },
  {
    "raw_code": "def self.perform_validation(object, field_name, opts = {})\n    validator = UsernameValidator.new(object.public_send(field_name), **opts)\n    unless validator.valid_format?\n      validator.errors.each { |e| object.errors.add(field_name.to_sym, e) }\n    end",
    "comment": "Public: Perform the validation of a field in a given object it adds the errors (if any) to the object that we're giving as parameter  object - Object in which we're performing the validation field_name - name of the field that we're validating  Example: UsernameValidator.perform_validation(user, 'name')",
    "label": "",
    "id": "744"
  },
  {
    "raw_code": "def self.types\n    PostActionType.flag_types.merge(PostActionType.score_types).merge(@api_types || {})\n  end",
    "comment": "To keep things simple the types correspond to `PostActionType` for backwards compatibility, but we can add extra reasons for scores.",
    "label": "",
    "id": "745"
  },
  {
    "raw_code": "def self.reload_types\n    @api_types = nil\n    types\n  end",
    "comment": "When extending post action flags, we need to call this method in order to get the latests flags.",
    "label": "",
    "id": "746"
  },
  {
    "raw_code": "def self.user_flag_score(user)\n    1.0 + (user.staff? ? 5.0 : user.trust_level.to_f) + user_accuracy_bonus(user)\n  end",
    "comment": "A user's flag score is: 1.0 + trust_level + user_accuracy_bonus (trust_level is 5 for staff)",
    "label": "",
    "id": "747"
  },
  {
    "raw_code": "def self.user_accuracy_bonus(user)\n    user_stat = user&.user_stat\n    return 0.0 if user_stat.blank? || user.bot?\n\n    calc_user_accuracy_bonus(user_stat.flags_agreed, user_stat.flags_disagreed)\n  end",
    "comment": "A user's accuracy bonus is: if 5 or less flags => 0.0 if > 5 flags => (agreed flags / total flags) * 5.0",
    "label": "",
    "id": "748"
  },
  {
    "raw_code": "def is_invite_link?\n    self.email.blank?\n  end",
    "comment": "Even if a domain is specified on the invite, it still counts as an invite link.",
    "label": "",
    "id": "749"
  },
  {
    "raw_code": "def is_email_invite?\n    self.email.present?\n  end",
    "comment": "Email invites have specific behaviour and it's easier to visually parse is_email_invite? than !is_invite_link?",
    "label": "",
    "id": "750"
  },
  {
    "raw_code": "def all_allowed_users\n    moderators_sql = \" UNION #{User.moderators.to_sql}\" if private_message? &&\n      (has_flags? || is_official_warning?)\n    User.from(\n      \"(#{allowed_users.to_sql} UNION #{allowed_group_users.to_sql}#{moderators_sql}) as users\",\n    )\n  end",
    "comment": "all users (in groups or directly targeted) that are going to get the pm",
    "label": "",
    "id": "751"
  },
  {
    "raw_code": "def limit_topics_per_day\n    return unless regular?\n    if user && user.new_user_posting_on_first_day?\n      limit_first_day_topics_per_day\n    else\n      apply_per_day_rate_limit_for(\"topics\", :max_topics_per_day)\n    end",
    "comment": "Additional rate limits on topics: per day and private messages per day",
    "label": "",
    "id": "752"
  },
  {
    "raw_code": "def self.for_digest(user, since, opts = nil)\n    opts ||= {}\n\n    period = ListController.best_period_for(since)\n\n    topics =\n      Topic\n        .visible\n        .secured(Guardian.new(user))\n        .joins(\n          \"LEFT OUTER JOIN topic_users ON topic_users.topic_id = topics.id AND topic_users.user_id = #{user.id.to_i}\",\n        )\n        .joins(\n          \"LEFT OUTER JOIN category_users ON category_users.category_id = topics.category_id AND category_users.user_id = #{user.id.to_i}\",\n        )\n        .joins(\"LEFT OUTER JOIN users ON users.id = topics.user_id\")\n        .where(closed: false, archived: false)\n        .where(\n          \"COALESCE(topic_users.notification_level, 1) <> ?\",\n          TopicUser.notification_levels[:muted],\n        )\n        .created_since(since)\n        .where(\"topics.created_at < ?\", (SiteSetting.editing_grace_period || 0).seconds.ago)\n        .listable_topics\n        .includes(:category)\n\n    unless opts[:include_tl0] || user.user_option.try(:include_tl0_in_digests)\n      topics = topics.where(\"COALESCE(users.trust_level, 0) > 0\")\n    end",
    "comment": "Returns hot topics since a date for display in email digest.",
    "label": "",
    "id": "753"
  },
  {
    "raw_code": "def self.next_post_number(topic_id, opts = {})\n    highest =\n      DB\n        .query_single(\n          \"SELECT coalesce(max(post_number),0) AS max FROM posts WHERE topic_id = ?\",\n          topic_id,\n        )\n        .first\n        .to_i\n\n    if opts[:whisper]\n      result = DB.query_single(<<~SQL, highest, topic_id)\n        UPDATE topics\n        SET highest_staff_post_number = ? + 1\n        WHERE id = ?\n        RETURNING highest_staff_post_number\n      SQL\n\n      result.first.to_i\n    else\n      reply_sql = opts[:reply] ? \", reply_count = reply_count + 1\" : \"\"\n      posts_sql = opts[:post] ? \", posts_count = posts_count + 1\" : \"\"\n\n      result = DB.query_single(<<~SQL, highest: highest, topic_id: topic_id)\n        UPDATE topics\n        SET highest_staff_post_number = :highest + 1,\n            highest_post_number = :highest + 1\n            #{reply_sql}\n            #{posts_sql}\n        WHERE id = :topic_id\n        RETURNING highest_post_number\n      SQL\n\n      result.first.to_i\n    end",
    "comment": "Atomically creates the next post number",
    "label": "",
    "id": "754"
  },
  {
    "raw_code": "def self.reset_highest(topic_id)\n    archetype = Topic.where(id: topic_id).pick(:archetype)\n\n    # ignore small_action replies for private messages\n    post_type =\n      archetype == Archetype.private_message ? \" AND post_type <> #{Post.types[:small_action]}\" : \"\"\n\n    result = DB.query_single(<<~SQL, topic_id: topic_id)\n      UPDATE topics\n      SET\n        highest_staff_post_number = (\n          SELECT COALESCE(MAX(post_number), 0) FROM posts\n          WHERE topic_id = :topic_id AND\n                deleted_at IS NULL\n        ),\n        highest_post_number = (\n          SELECT COALESCE(MAX(post_number), 0) FROM posts\n          WHERE topic_id = :topic_id AND\n                deleted_at IS NULL AND\n                post_type <> 4\n                #{post_type}\n        ),\n        posts_count = (\n          SELECT count(*) FROM posts\n          WHERE deleted_at IS NULL AND\n                topic_id = :topic_id AND\n                post_type <> 4\n                #{post_type}\n        ),\n        word_count = (\n          SELECT SUM(COALESCE(posts.word_count, 0)) FROM posts\n          WHERE topic_id = :topic_id AND\n                deleted_at IS NULL AND\n                post_type <> 4\n                #{post_type}\n        ),\n        last_posted_at = (\n          SELECT MAX(created_at) FROM posts\n          WHERE topic_id = :topic_id AND\n                deleted_at IS NULL AND\n                post_type <> 4\n                #{post_type}\n        ),\n        last_post_user_id = COALESCE((\n          SELECT user_id FROM posts\n          WHERE topic_id = :topic_id AND\n                deleted_at IS NULL AND\n                post_type <> 4\n                #{post_type}\n          ORDER BY created_at desc\n          LIMIT 1\n        ), last_post_user_id)\n      WHERE id = :topic_id\n      RETURNING highest_post_number\n    SQL\n\n    highest_post_number = result.first.to_i\n\n    # Update the forum topic user records\n    DB.exec(<<~SQL, highest: highest_post_number, topic_id: topic_id)\n      UPDATE topic_users\n      SET last_read_post_number = CASE\n                                  WHEN last_read_post_number > :highest THEN :highest\n                                  ELSE last_read_post_number\n                                  END\n      WHERE topic_id = :topic_id\n    SQL\n  end",
    "comment": "If a post is deleted we have to update our highest post counters and last post information",
    "label": "",
    "id": "755"
  },
  {
    "raw_code": "def update_statistics\n    feature_topic_users\n    update_action_counts\n    Topic.reset_highest(id)\n  end",
    "comment": "Updates the denormalized statistics of a topic including featured posters. They shouldn't go out of sync unless you do something drastic live move posts from one topic to another. this recalculates everything.",
    "label": "",
    "id": "756"
  },
  {
    "raw_code": "def slug\n    unless slug = read_attribute(:slug)\n      return \"\" if title.blank?\n      slug = slug_for_topic(title)\n      if new_record?\n        write_attribute(:slug, slug)\n      else\n        update_column(:slug, slug)\n      end",
    "comment": "Even if the slug column in the database is null, topic.slug will return something:",
    "label": "",
    "id": "757"
  },
  {
    "raw_code": "def last_post_url\n    \"#{Discourse.base_path}/t/#{slug}/#{id}/#{posts_count}\"\n  end",
    "comment": "NOTE: These are probably better off somewhere else. Having a model know about URLs seems a bit strange.",
    "label": "",
    "id": "758"
  },
  {
    "raw_code": "def set_or_create_timer(\n    status_type,\n    time,\n    by_user: nil,\n    based_on_last_post: false,\n    category_id: SiteSetting.uncategorized_category_id,\n    duration_minutes: nil,\n    silent: nil\n  )\n    if time.blank? && duration_minutes.blank?\n      return delete_topic_timer(status_type, by_user: by_user)\n    end",
    "comment": "Valid arguments for the time: * An integer, which is the number of hours from now to update the topic's status. * A timestamp, like \"2013-11-25 13:00\", when the topic's status should update. * A timestamp with timezone in JSON format. (e.g., \"2013-11-26T21:00:00.000Z\") * `nil` to delete the topic's status update. Options: * by_user: User who is setting the topic's status update. * based_on_last_post: True if time should be based on timestamp of the last post. * category_id: Category that the update will apply to. * duration_minutes: The duration of the timer in minutes, which is used if the timer is based on the last post or if the timer type is delete_replies. * silent: Affects whether the close topic timer status change will be silent or not.",
    "label": "",
    "id": "759"
  },
  {
    "raw_code": "def self.action_aliases\n    {}\n  end",
    "comment": "Can be used if several actions are equivalent",
    "label": "",
    "id": "760"
  },
  {
    "raw_code": "def self.typical_sensitivity\n    12.5\n  end",
    "comment": "This number comes from looking at forums in the wild and what numbers work. As the site accumulates real data it'll be based on the site activity instead.",
    "label": "",
    "id": "761"
  },
  {
    "raw_code": "def self.needs_review!(\n    target: nil,\n    topic: nil,\n    created_by:,\n    payload: nil,\n    reviewable_by_moderator: false,\n    potential_spam: true,\n    potentially_illegal: false,\n    target_created_by: nil\n  )\n    reviewable =\n      new(\n        target: target,\n        topic: topic,\n        created_by: created_by,\n        reviewable_by_moderator: reviewable_by_moderator,\n        payload: payload,\n        potential_spam: potential_spam,\n        potentially_illegal: potentially_illegal,\n        target_created_by: target_created_by,\n      )\n    reviewable.created_new!\n\n    if target.blank? || !Reviewable.where(target: target, type: reviewable.type).exists?\n      # If there is no target, or no existing reviewable with matching target and type, there's no chance of a conflict\n      reviewable.save!\n    else\n      # In this case, a reviewable might already exist for this (type, target_id) index.\n      # ActiveRecord can only validate indexes using a SELECT before the INSERT which\n      # is not safe under concurrency. Instead, we perform an UPDATE on the status, and return\n      # the previous value. We then know:\n      #\n      #   a) if a previous row existed\n      #   b) if it was changed\n      #\n      # And that allows us to complete our logic.\n\n      update_args = {\n        status: statuses[:pending],\n        id: target.id,\n        type: target.class.polymorphic_name,\n        potential_spam: potential_spam == true ? true : nil,\n        potentially_illegal: potentially_illegal == true ? true : nil,\n      }\n\n      row = DB.query_single(<<~SQL, update_args)\n        UPDATE reviewables\n        SET status = :status,\n          potential_spam = COALESCE(:potential_spam, reviewables.potential_spam),\n          potentially_illegal = COALESCE(:potentially_illegal, reviewables.potentially_illegal)\n        FROM reviewables AS old_reviewables\n        WHERE reviewables.target_id = :id\n          AND reviewables.target_type = :type\n        RETURNING old_reviewables.status\n      SQL\n      old_status = row[0]\n\n      if old_status.blank?\n        reviewable.save!\n      else\n        reviewable = find_by(target: target)\n\n        if old_status != statuses[:pending]\n          # If we're transitioning back from reviewed to pending, we should recalculate\n          # the score to prevent posts from being hidden.\n          reviewable.recalculate_score\n          reviewable.log_history(:transitioned, created_by)\n        end",
    "comment": "Create a new reviewable, or if the target has already been reviewed return it to the pending state and re-use it.  You probably want to call this to create your reviewable rather than `.create`.",
    "label": "",
    "id": "762"
  },
  {
    "raw_code": "def build_actions(actions, guardian, args)\n    raise NotImplementedError\n  end",
    "comment": "subclasses must implement \"build_actions\" to list the actions they're capable of",
    "label": "",
    "id": "763"
  },
  {
    "raw_code": "def build_editable_fields(actions, guardian, args)\n  end",
    "comment": "subclasses can implement \"build_editable_fields\" to list stuff that can be edited",
    "label": "",
    "id": "764"
  },
  {
    "raw_code": "def perform(performed_by, action_id, args = nil)\n    args ||= {}\n    perform_method = \"perform_#{aliases[action_id] || action_id}\".to_sym\n    guardian = args[:guardian] || Guardian.new(performed_by)\n\n    validate_action!(guardian, action_id, perform_method, args)\n\n    result = nil\n    update_count = false\n    Reviewable.transaction do\n      increment_version!(args[:version])\n      result = public_send(perform_method, performed_by, args)\n\n      raise ActiveRecord::Rollback unless result.success?\n\n      update_count = transition_to(result.transition_to, performed_by) if result.transition_to\n      update_flag_stats(**result.update_flag_stats) if result.update_flag_stats\n\n      recalculate_score if result.recalculate_score\n    end",
    "comment": "Delegates to a `perform_#{action_id}` method, which returns a `PerformResult` with the result of the operation and whether the status of the reviewable changed.",
    "label": "",
    "id": "765"
  },
  {
    "raw_code": "def updatable_reviewable_scores\n    reviewable_scores.pending\n  end",
    "comment": "Override this in specific reviewable type to include scores for non-pending reviewables",
    "label": "",
    "id": "766"
  },
  {
    "raw_code": "def create_result(status, transition_to = nil)\n    result = PerformResult.new(self, status)\n    result.transition_to = transition_to\n    yield result if block_given?\n    result\n  end",
    "comment": "@TODO (reviewable-refresh) This can be deprecated/removed once all reviewable types have been migrated, it now lives in ReviewableActionBuilder.",
    "label": "",
    "id": "767"
  },
  {
    "raw_code": "def delete_user_actions(actions, bundle = nil, require_reject_reason: false)\n    bundle ||=\n      actions.add_bundle(\n        \"reject_user\",\n        icon: \"user-xmark\",\n        label: \"reviewables.actions.reject_user.title\",\n      )\n\n    actions.add(:delete_user, bundle: bundle) do |a|\n      a.icon = \"user-xmark\"\n      a.label = \"reviewables.actions.reject_user.delete.title\"\n      a.require_reject_reason = require_reject_reason\n    end",
    "comment": "TODO (reviewable-refresh) This can be deprecated/removed once all reviewable types have been migrated.",
    "label": "",
    "id": "768"
  },
  {
    "raw_code": "def post_action_rate_limiter\n    return unless is_flag? || is_like?\n\n    return @rate_limiter if @rate_limiter.present?\n\n    %w[like flag].each do |type|\n      if public_send(\"is_#{type}?\")\n        limit = SiteSetting.get(\"max_#{type}s_per_day\")\n\n        if (is_flag? || is_like?) && user && user.trust_level >= 2\n          multiplier =\n            SiteSetting.get(\"tl#{user.trust_level}_additional_#{type}s_per_day_multiplier\").to_f\n          multiplier = 1.0 if multiplier < 1.0\n\n          limit = (limit * multiplier).to_i\n        end",
    "comment": "A custom rate limiter for this model",
    "label": "",
    "id": "769"
  },
  {
    "raw_code": "def self.transform_pluralized_key(key)\n    match = key.match(/(.*)\\.(zero|two|few|many)\\z/)\n    match ? match.to_a.second + \".other\" : key\n  end",
    "comment": "We use English as the source of truth when extracting interpolation keys, but some languages, like Arabic, have plural forms (zero, two, few, many) which don't exist in English (one, other), so we map that here in order to find the correct, English translation key in which to look.",
    "label": "",
    "id": "770"
  },
  {
    "raw_code": "def self.protected_system_fields\n    %i[name badge_type_id multiple_grant target_posts show_posts query trigger auto_revoke listable]\n  end",
    "comment": "fields that can not be edited on system badges",
    "label": "",
    "id": "771"
  },
  {
    "raw_code": "def update_user_titles!(new_title)\n    DB.exec(<<~SQL, granted_title_badge_id: self.id, title: new_title, updated_at: Time.zone.now)\n      UPDATE users AS u\n      SET title = :title, updated_at = :updated_at\n      FROM user_profiles AS up\n      WHERE up.user_id = u.id AND up.granted_title_badge_id = :granted_title_badge_id\n    SQL\n  end",
    "comment": " Update all user titles based on a badge to the new name",
    "label": "",
    "id": "772"
  },
  {
    "raw_code": "def reset_user_titles!\n    DB.exec(<<~SQL, granted_title_badge_id: self.id, updated_at: Time.zone.now)\n      UPDATE users AS u\n      SET title = badges.name, updated_at = :updated_at\n      FROM user_profiles AS up\n      INNER JOIN badges ON badges.id = up.granted_title_badge_id\n      WHERE up.user_id = u.id AND up.granted_title_badge_id = :granted_title_badge_id\n    SQL\n  end",
    "comment": " When a badge has its TranslationOverride cleared, reset all user titles granted to the standard name.",
    "label": "",
    "id": "773"
  },
  {
    "raw_code": "def self.create_from_base(params)\n    new_color_scheme = new(name: params[:name])\n    new_color_scheme.via_wizard = true if params[:via_wizard]\n    new_color_scheme.base_scheme_id = params[:base_scheme_id]\n\n    scheme_name = NAMES_TO_ID_MAP.invert[params[:base_scheme_id]]\n\n    colors =\n      BUILT_IN_SCHEMES[scheme_name.to_sym]&.map { |name, hex| { name: name, hex: hex } } if params[\n      :base_scheme_id\n    ]\n    colors ||= base.colors_hashes\n\n    # Override base values\n    params[:colors].each do |name, hex|\n      c = colors.find { |x| x[:name].to_s == name.to_s }\n      c[:hex] = hex\n    end if params[:colors]\n\n    new_color_scheme.colors = colors\n    new_color_scheme.skip_publish if params[:skip_publish]\n    new_color_scheme.save\n    new_color_scheme\n  end",
    "comment": "create_from_base will create a new ColorScheme that overrides Discourse's base color scheme with the given colors.",
    "label": "",
    "id": "774"
  },
  {
    "raw_code": "def self.set_approved_fields!(user, approved_by)\n    user.approved = true\n    user.approved_by ||= approved_by\n    user.approved_at ||= Time.zone.now\n  end",
    "comment": "Update's the user's fields for approval but does not save. This can be used when generating a new user that is approved on create",
    "label": "",
    "id": "775"
  },
  {
    "raw_code": "def self.staff_actions\n    @staff_actions ||= %i[\n      delete_user\n      change_trust_level\n      change_site_setting\n      change_theme\n      delete_theme\n      change_site_text\n      suspend_user\n      unsuspend_user\n      removed_suspend_user\n      removed_unsuspend_user\n      grant_badge\n      revoke_badge\n      check_email\n      delete_post\n      delete_topic\n      impersonate\n      roll_up\n      change_username\n      custom_staff\n      anonymize_user\n      reviewed_post\n      change_category_settings\n      delete_category\n      create_category\n      silence_user\n      unsilence_user\n      removed_silence_user\n      removed_unsilence_user\n      grant_admin\n      revoke_admin\n      grant_moderation\n      revoke_moderation\n      backup_create\n      revoke_email\n      deactivate_user\n      lock_trust_level\n      unlock_trust_level\n      activate_user\n      change_readonly_mode\n      backup_download\n      backup_destroy\n      post_locked\n      post_unlocked\n      check_personal_message\n      disabled_second_factor\n      post_edit\n      topic_published\n      recover_topic\n      post_approved\n      create_badge\n      change_badge\n      delete_badge\n      post_rejected\n      merge_user\n      entity_export\n      change_name\n      topic_timestamps_changed\n      approve_user\n      web_hook_create\n      web_hook_update\n      web_hook_destroy\n      web_hook_deactivate\n      embeddable_host_create\n      embeddable_host_update\n      embeddable_host_destroy\n      change_theme_setting\n      disable_theme_component\n      enable_theme_component\n      revoke_title\n      change_title\n      api_key_create\n      api_key_update\n      api_key_destroy\n      override_upload_secure_status\n      page_published\n      page_unpublished\n      add_email\n      update_email\n      destroy_email\n      topic_closed\n      topic_opened\n      topic_archived\n      topic_unarchived\n      post_staff_note_create\n      post_staff_note_destroy\n      watched_word_create\n      watched_word_destroy\n      delete_group\n      permanently_delete_post_revisions\n      create_public_sidebar_section\n      update_public_sidebar_section\n      destroy_public_sidebar_section\n      reset_bounce_score\n      update_directory_columns\n      deleted_unused_tags\n      renamed_tag\n      deleted_tag\n      chat_channel_status_change\n      chat_auto_remove_membership\n      create_watched_word_group\n      update_watched_word_group\n      delete_watched_word_group\n      topic_slow_mode_set\n      topic_slow_mode_removed\n      custom_emoji_create\n      custom_emoji_destroy\n      delete_post_permanently\n      delete_topic_permanently\n      tag_group_create\n      tag_group_destroy\n      tag_group_change\n      delete_associated_accounts\n      toggle_flag\n      delete_flag\n      update_flag\n      create_flag\n      change_theme_site_setting\n      stop_impersonating\n    ]\n  end",
    "comment": "Staff actions is a subset of all actions, used to audit actions taken by staff users.",
    "label": "",
    "id": "776"
  },
  {
    "raw_code": "def self.update_view_counts(last_seen = 1.hour.ago)\n    # NOTE: we only update the counts for users we have seen in the last hour\n    #  this avoids a very expensive query that may run on the entire user base\n    #  we also ensure we only touch the table if data changes\n\n    # Update denormalized topics_entered\n    DB.exec(<<~SQL, seen_at: last_seen)\n      UPDATE user_stats SET topics_entered = X.c\n       FROM\n      (SELECT v.user_id, COUNT(topic_id) AS c\n       FROM topic_views AS v\n       WHERE v.user_id IN (\n          SELECT u1.id FROM users u1 where u1.last_seen_at > :seen_at\n       )\n       GROUP BY v.user_id) AS X\n      WHERE\n        X.user_id = user_stats.user_id AND\n        X.c <> topics_entered\n    SQL\n\n    # Update denormalized posts_read_count\n    DB.exec(<<~SQL, seen_at: last_seen)\n      WITH filtered_users AS (\n        SELECT id FROM users u\n        JOIN user_stats ON user_id = u.id\n        WHERE last_seen_at > :seen_at\n        AND posts_read_count < 10000\n      )\n      UPDATE user_stats SET posts_read_count = X.c\n      FROM (SELECT pt.user_id, COUNT(*) as c\n            FROM filtered_users AS u\n            JOIN post_timings AS pt ON pt.user_id = u.id\n            JOIN topics t ON t.id = pt.topic_id\n            WHERE t.archetype = 'regular'\n            AND t.deleted_at IS NULL\n            GROUP BY pt.user_id\n           ) AS X\n      WHERE X.user_id = user_stats.user_id\n      AND X.c <> posts_read_count\n    SQL\n  end",
    "comment": "Updates the denormalized view counts for all users",
    "label": "",
    "id": "777"
  },
  {
    "raw_code": "def calc_topic_reply_count!(start_time = nil)\n    sql = <<~SQL\n      SELECT COUNT(DISTINCT posts.topic_id) AS count\n      FROM posts\n      INNER JOIN topics ON topics.id = posts.topic_id\n      WHERE posts.user_id = ?\n      AND topics.user_id <> posts.user_id\n      AND posts.deleted_at IS NULL AND topics.deleted_at IS NULL\n      AND topics.archetype <> 'private_message'\n      #{start_time.nil? ? \"\" : \"AND posts.created_at > ?\"}\n    SQL\n    if start_time.nil?\n      DB.query_single(sql, self.user_id).first\n    else\n      DB.query_single(sql, self.user_id, start_time).first\n    end",
    "comment": "topic_reply_count is a count of posts in other users' topics",
    "label": "",
    "id": "778"
  },
  {
    "raw_code": "def self.update_time_read!(id)\n    if last_seen = last_seen_cached(id)\n      diff = (Time.now.to_f - last_seen.to_f).round\n      if diff > 0 && diff < MAX_TIME_READ_DIFF\n        update_args = [\"time_read = time_read + ?\", diff]\n        UserStat.where(user_id: id).update_all(update_args)\n        UserVisit.where(user_id: id, visited_at: Time.zone.now.to_date).update_all(update_args)\n      end",
    "comment": "attempt to add total read time to user based on previous time this was called",
    "label": "",
    "id": "779"
  },
  {
    "raw_code": "def choose(args = {})\n    self.class.ensure_consistency!(topic.id.to_i)\n    update_participant_count\n  end",
    "comment": "Chooses which topic users to feature",
    "label": "",
    "id": "780"
  },
  {
    "raw_code": "def get_setting(setting_name)\n    target_setting = settings[setting_name.to_sym]\n    raise Discourse::NotFound unless target_setting\n    target_setting.value\n  end",
    "comment": "Retrieves a theme setting  @param setting_name [String, Symbol] The name of the setting to retrieve.  @return [Object] The value of the setting that matches the provided name.  @raise [Discourse::NotFound] If no setting is found with the provided name.  @example theme.get_setting(\"some_boolean\") => True theme.get_setting(\"some_string\") => \"hello\" theme.get_setting(:some_boolean) => True theme.get_setting(:some_string) => \"hello\" ",
    "label": "",
    "id": "781"
  },
  {
    "raw_code": "def update_link_counts\n    DB.exec(\n      \"UPDATE topics\n              SET incoming_link_count = incoming_link_count + 1\n              WHERE id = (SELECT topic_id FROM posts where id = ?)\",\n      post_id,\n    )\n    DB.exec(\n      \"UPDATE posts\n              SET incoming_link_count = incoming_link_count + 1\n              WHERE id = ?\",\n      post_id,\n    )\n  end",
    "comment": "Internal: Update appropriate link counts.",
    "label": "",
    "id": "782"
  },
  {
    "raw_code": "def ip_address=(val)\n    if val.nil?\n      self.errors.add(:ip_address, :invalid)\n      return\n    end",
    "comment": "In Rails 4.0.0, validators are run to handle invalid assignments to inet columns (as they should). In Rails 4.0.1, an exception is raised before validation happens, so we need this hack for inet/cidr columns:",
    "label": "",
    "id": "783"
  },
  {
    "raw_code": "def ip_address_with_mask\n    ip_address.try(:to_cidr_s)\n  end",
    "comment": "Return a string with the ip address and mask in standard format. e.g., \"127.0.0.0/8\".",
    "label": "",
    "id": "784"
  },
  {
    "raw_code": "def build_legacy_combined_actions(actions, guardian, args)\n    if post.trashed? && guardian.can_recover_post?(post)\n      build_action(actions, :approve_and_restore, icon: \"check\")\n    elsif post.hidden?\n      build_action(actions, :approve_and_unhide, icon: \"check\")\n    else\n      build_action(actions, :approve, icon: \"check\")\n    end",
    "comment": "TODO (reviewable-refresh): Remove this method when fully migrated to new UI",
    "label": "",
    "id": "785"
  },
  {
    "raw_code": "def build_new_separated_actions(actions, guardian, args)\n    build_post_actions_bundle(actions, guardian)\n    build_user_actions_bundle(actions, guardian)\n  end",
    "comment": "TODO (reviewable-refresh): Merge this method into build_actions when fully migrated to new UI",
    "label": "",
    "id": "786"
  },
  {
    "raw_code": "def perform_approve(performed_by, _args)\n    create_result(:success, :approved, [created_by_id], false)\n  end",
    "comment": "TODO (reviewable-refresh): Remove combined actions below when fully migrated to new UI",
    "label": "",
    "id": "787"
  },
  {
    "raw_code": "def access_control_post\n    Post.unscoped { super }\n  end",
    "comment": "when we access this post we don't care if the post is deleted",
    "label": "",
    "id": "788"
  },
  {
    "raw_code": "def get_optimized_image(width, height, opts = nil)\n    opts ||= {}\n\n    fix_image_extension if (!extension || extension.length == 0)\n\n    opts = opts.merge(raise_on_error: true)\n    begin\n      OptimizedImage.create_for(self, width, height, opts)\n    rescue => ex\n      Rails.logger.info ex if Rails.env.development?\n      opts = opts.merge(raise_on_error: false)\n      if fix_image_extension\n        OptimizedImage.create_for(self, width, height, opts)\n      else\n        nil\n      end",
    "comment": "this method attempts to correct old incorrect extensions",
    "label": "",
    "id": "789"
  },
  {
    "raw_code": "def get_dimension(key)\n    if v = read_attribute(key)\n      return v\n    end",
    "comment": "on demand image size calculation, this allows us to null out image sizes and still handle as needed",
    "label": "",
    "id": "790"
  },
  {
    "raw_code": "def ensure_email_is_present!(email)\n    if email.blank?\n      Rails.logger.warn(\n        \"email param was blank in InviteRedeemer for invite ID #{@invite.id}. The `redeeming_user` was #{@redeeming_user.present? ? \"(ID: #{@redeeming_user.id})\" : \"not\"} present.\",\n      )\n    end",
    "comment": "The email must be present in some form since many of the methods for processing + redemption rely on it. If it's still nil after these checks then we have hit an edge case and should not proceed!",
    "label": "",
    "id": "791"
  },
  {
    "raw_code": "def self.create_user_from_invite(\n    email:,\n    invite:,\n    username: nil,\n    name: nil,\n    password: nil,\n    user_custom_fields: nil,\n    ip_address: nil,\n    session: nil,\n    email_token: nil\n  )\n    if username && UsernameValidator.new(username).valid_format? &&\n         User.username_available?(username, email)\n      available_username = username\n    else\n      available_username = UserNameSuggester.suggest(email)\n    end",
    "comment": "This will _never_ be called if there is a redeeming_user being passed in to InviteRedeemer -- see invited_user below.",
    "label": "",
    "id": "792"
  },
  {
    "raw_code": "def invited_user\n    return @invited_user if defined?(@invited_user)\n\n    # The redeeming user is an already logged in user or a user who is\n    # activating their account who is redeeming the invite,\n    # which is valid for existing users to be invited to topics or groups.\n    if redeeming_user.present?\n      @invited_user = redeeming_user\n      return @invited_user\n    end",
    "comment": "Note that the invited_user is returned by #redeemed, so other places (e.g. the InvitesController) can perform further actions on it, this is why things like send_welcome_message are set without being saved on the model.",
    "label": "",
    "id": "793"
  },
  {
    "raw_code": "def self.ids_from_slugs(slugs)\n    return [] if slugs.blank?\n\n    params = {}\n    params_index = 0\n\n    sqls =\n      slugs.map do |slug|\n        category_slugs =\n          slug.split(\":\").first(SiteSetting.max_category_nesting).map { Slug.for(_1, \"\") }\n\n        sql = \"\"\n\n        if category_slugs.length == 1\n          params[:\"slug_#{params_index}\"] = category_slugs.first\n          sql = \"SELECT id FROM categories WHERE slug = :slug_#{params_index}\"\n          params_index += 1\n        else\n          category_slugs.each_with_index do |category_slug, index|\n            params[:\"slug_#{params_index}\"] = category_slug\n\n            sql =\n              if index == 0\n                \"SELECT id FROM categories WHERE slug = :slug_#{params_index} AND parent_category_id IS NULL\"\n              else\n                \"SELECT id FROM categories WHERE parent_category_id = (#{sql}) AND slug = :slug_#{params_index}\"\n              end",
    "comment": "Accepts an array of slugs with each item in the array Returns the category ids of the last slug in the array. The slugs array has to follow the proper category nesting hierarchy. If any of the slug in the array is invalid or if the slugs array does not follow the proper category nesting hierarchy, nil is returned.  When only a single slug is provided, the category id of all the categories with that slug is returned.",
    "label": "",
    "id": "794"
  },
  {
    "raw_code": "def self.post_template\n    I18n.t(\"category.post_template\", replace_paragraph: I18n.t(\"category.replace_paragraph\"))\n  end",
    "comment": "Internal: Generate the text of post prompting to enter category description.",
    "label": "",
    "id": "795"
  },
  {
    "raw_code": "def height_of_ancestors(max_height = SiteSetting.max_category_nesting)\n    parent_id = self.parent_category_id\n\n    return max_height if parent_id == id\n\n    DB.query(<<~SQL, id: id, parent_id: parent_id, max_height: max_height)[0].max\n      WITH RECURSIVE ancestors(parent_category_id, height) AS (\n        SELECT :parent_id :: integer, 0\n\n        UNION ALL\n\n        SELECT\n          categories.parent_category_id,\n          CASE\n            WHEN categories.parent_category_id = :id THEN :max_height\n            ELSE ancestors.height + 1\n          END\n        FROM categories, ancestors\n        WHERE categories.id = ancestors.parent_category_id\n        AND ancestors.height < :max_height\n      )\n\n      SELECT max(height) FROM ancestors\n    SQL\n  end",
    "comment": "This is used in a validation so has to produce accurate results before the record has been saved",
    "label": "",
    "id": "796"
  },
  {
    "raw_code": "def depth_of_descendants(max_depth = SiteSetting.max_category_nesting)\n    parent_id = self.parent_category_id\n\n    return max_depth if parent_id == id\n\n    DB.query(<<~SQL, id: id, parent_id: parent_id, max_depth: max_depth)[0].max\n      WITH RECURSIVE descendants(id, depth) AS (\n        SELECT :id :: integer, 0\n\n        UNION ALL\n\n        SELECT\n          categories.id,\n          CASE\n            WHEN categories.id = :parent_id THEN :max_depth\n            ELSE descendants.depth + 1\n          END\n        FROM categories, descendants\n        WHERE categories.parent_category_id = descendants.id\n        AND descendants.depth < :max_depth\n      )\n\n      SELECT max(depth) FROM descendants\n    SQL\n  end",
    "comment": "This is used in a validation so has to produce accurate results before the record has been saved",
    "label": "",
    "id": "797"
  },
  {
    "raw_code": "def set_permissions(permissions)\n    self.read_restricted, @permissions = Category.resolve_permissions(permissions)\n\n    # Ideally we can just call .clear here, but it runs SQL, we only want to run it\n    # on save.\n  end",
    "comment": "will reset permission on a topic to a particular set.  Available permissions are, :full, :create_post, :readonly hash can be:  :everyone => :full - everyone has everything :everyone => :readonly, :staff => :full 7 => 1  # you can pass a group_id and permission id",
    "label": "",
    "id": "798"
  },
  {
    "raw_code": "def auto_bump_topic!\n    return false if num_auto_bump_daily.to_i == 0\n\n    limiter = auto_bump_limiter\n    return false if !limiter.can_perform?\n\n    filters = []\n    DiscourseEvent.trigger(:filter_auto_bump_topics, self, filters)\n\n    relation = Topic\n\n    filters.each { |filter| relation = filter.call(relation) } if filters.length > 0\n\n    topic =\n      relation\n        .visible\n        .listable_topics\n        .exclude_scheduled_bump_topics\n        .where(category_id: self.id)\n        .where(\"id <> ?\", self.topic_id)\n        .where(\"bumped_at < ?\", (self.auto_bump_cooldown_days || 1).days.ago)\n        .where(\"pinned_at IS NULL AND NOT closed AND NOT archived\")\n        .order(\"bumped_at ASC\")\n        .limit(1)\n        .first\n\n    if topic\n      topic.add_small_action(Discourse.system_user, \"autobumped\", nil, bump: true)\n      limiter.performed!\n      true\n    else\n      false\n    end",
    "comment": "will automatically bump a single topic if number of automatically bumped topics is smaller than threshold",
    "label": "",
    "id": "799"
  },
  {
    "raw_code": "def rename_category_definition\n    return if topic.blank?\n    old_name = saved_changes.transform_values(&:first)[\"name\"]\n    if topic.title == I18n.t(\"category.topic_prefix\", category: old_name)\n      topic.update_attribute(:title, I18n.t(\"category.topic_prefix\", category: name))\n    end",
    "comment": "If the name changes, try and update the category definition topic too if it's an exact match",
    "label": "",
    "id": "800"
  },
  {
    "raw_code": "def self.import(user, url, title, contents, category_id: nil, cook_method: nil, tags: nil)\n    return unless url =~ %r{\\Ahttps?\\://}\n\n    original_contents = contents.dup.truncate(EMBED_CONTENT_CACHE_MAX_LENGTH)\n    contents = first_paragraph_from(contents) if SiteSetting.embed_truncate && cook_method.nil?\n    contents ||= \"\"\n    contents = contents.dup << imported_from_html(url)\n\n    url = normalize_url(url)\n\n    embed = topic_embed_by_url(url)\n    content_sha1 = Digest::SHA1.hexdigest(contents)\n    post = nil\n\n    # If there is no embed, create a topic, post and the embed.\n    if embed.blank?\n      Topic.transaction do\n        if eh = EmbeddableHost.record_for_url(url)\n          tags = eh.tags.presence&.map(&:name) || tags\n          user = eh.user.presence || user\n        end",
    "comment": "Import an article from a source (RSS/Atom/Other)",
    "label": "",
    "id": "801"
  },
  {
    "raw_code": "def self.absolutize_urls(url, contents)\n    url = normalize_url(url)\n    begin\n      uri = URI(UrlHelper.normalized_encode(url))\n    rescue URI::Error\n      return contents\n    end",
    "comment": "Convert any relative URLs to absolute. RSS is annoying for this.",
    "label": "",
    "id": "802"
  },
  {
    "raw_code": "def self.allowed_scopes\n    Set.new(SiteSetting.allow_user_api_key_scopes.split(\"|\"))\n  end",
    "comment": "Scopes allowed to be requested by external services",
    "label": "",
    "id": "803"
  },
  {
    "raw_code": "def notification_levels\n      NotificationLevels.topic_levels\n    end",
    "comment": "Enums",
    "label": "",
    "id": "804"
  },
  {
    "raw_code": "def lookup_for(user, topics)\n      # If the user isn't logged in, there's no last read posts\n      return {} if user.blank? || topics.blank?\n\n      topic_ids = topics.map(&:id)\n      create_lookup(TopicUser.where(topic_id: topic_ids, user_id: user.id))\n    end",
    "comment": "Find the information specific to a user in a forum topic",
    "label": "",
    "id": "805"
  },
  {
    "raw_code": "def change(user_id, topic_id, attrs)\n      # For plugin compatibility, remove after 01 Jan 2022\n      attrs.delete(:highest_seen_post_number) if attrs[:highest_seen_post_number]\n\n      # Sometimes people pass objs instead of the ids. We can handle that.\n      topic_id = topic_id.id if topic_id.is_a?(::Topic)\n      user_id = user_id.id if user_id.is_a?(::User)\n\n      topic_id = topic_id.to_i\n      user_id = user_id.to_i\n\n      TopicUser.transaction do\n        attrs = attrs.dup\n        if attrs[:notification_level]\n          attrs[:notifications_changed_at] ||= DateTime.now\n          attrs[:notifications_reason_id] ||= TopicUser.notification_reasons[:user_changed]\n        end",
    "comment": "Change attributes for a user (creates a record when none is present). First it tries an update since there's more likely to be an existing record than not. If the update returns 0 rows affected it then creates the row instead.",
    "label": "",
    "id": "806"
  },
  {
    "raw_code": "def self.update_post_action_cache(\n    user_id: nil,\n    post_id: nil,\n    topic_id: nil,\n    post_action_type: :like\n  )\n    raise ArgumentError, \"post_action_type must equal :like\" if post_action_type != :like\n    raise ArgumentError, \"post_id and user_id cannot be supplied together\" if user_id && post_id\n    action_type_name = \"liked\"\n\n    builder = DB.build <<~SQL\n      UPDATE topic_users tu\n      SET #{action_type_name} = x.state\n      FROM (\n        SELECT CASE WHEN EXISTS (\n          SELECT 1\n          FROM post_actions pa\n          JOIN posts p on p.id = pa.post_id\n          JOIN topics t ON t.id = p.topic_id\n          WHERE pa.deleted_at IS NULL AND\n                p.deleted_at IS NULL AND\n                t.deleted_at IS NULL AND\n                pa.post_action_type_id = :action_type_id AND\n                tu2.topic_id = t.id AND\n                tu2.user_id = pa.user_id\n          LIMIT 1\n        ) THEN true ELSE false END state, tu2.topic_id, tu2.user_id\n        FROM topic_users tu2\n        /*where*/\n      ) x\n      WHERE x.topic_id = tu.topic_id AND x.user_id = tu.user_id AND x.state != tu.#{action_type_name}\n    SQL\n\n    builder.where(\"tu2.user_id IN (:user_id)\", user_id: user_id) if user_id\n\n    builder.where(\"tu2.topic_id IN (:topic_id)\", topic_id: topic_id) if topic_id\n\n    if post_id\n      if !topic_id\n        builder.where(\n          \"tu2.topic_id IN (SELECT topic_id FROM posts WHERE id IN (:post_id))\",\n          post_id: post_id,\n        )\n      end",
    "comment": "Update the cached topic_user.liked column based on data from the post_actions table. This is useful when posts have moved around, or to ensure integrity of the data.  By default this will update data for all topics and all users. The parameters can be used to shrink the scope, and make it faster. user_id, post_id and topic_id can optionally be arrays of ids.  Providing post_id will automatically scope to the relevant user_id and topic_id. A provided `topic_id` value will always take precedence, which is useful when a post has been moved between topics.",
    "label": "",
    "id": "807"
  },
  {
    "raw_code": "def self.cap_unread!(user_id, count)\n    sql = <<SQL\n    UPDATE topic_users tu\n    SET last_read_post_number = max_number\n    FROM (\n      SELECT MAX(post_number) max_number, p.topic_id FROM posts p\n      WHERE deleted_at IS NULL\n      GROUP BY p.topic_id\n    ) m\n    WHERE tu.user_id = :user_id AND\n          m.topic_id = tu.topic_id AND\n          tu.topic_id IN (\n            #{TopicTrackingState.report_raw_sql(skip_new: true, select: \"topics.id\")}\n            offset :count\n          )\nSQL\n\n    DB.exec(sql, user_id: user_id, count: count)\n  end",
    "comment": "cap number of unread topics at count, bumping up last_read if needed",
    "label": "",
    "id": "808"
  },
  {
    "raw_code": "def self.safe_secret_key_base\n    if @safe_secret_key_base && @token_in_redis &&\n         (@token_last_validated + REDIS_VALIDATE_SECONDS) < Time.now\n      @token_last_validated = Time.now\n      token = Discourse.redis.without_namespace.get(REDIS_SECRET_KEY)\n      Discourse.redis.without_namespace.set(REDIS_SECRET_KEY, @safe_secret_key_base) if token.nil?\n    end",
    "comment": "In Rails secret_key_base is used to encrypt the cookie store the cookie store contains session data Discourse also uses this secret key to digest user auth tokens This method will - use existing token if already set in ENV or discourse.conf - generate a token on the fly if needed and cache in redis - skips caching generated token to redis if redis is skipped - enforce rules about token format falling back to redis if needed",
    "label": "",
    "id": "809"
  },
  {
    "raw_code": "def self.use_s3?\n    (\n      @use_s3 ||=\n        begin\n          if s3_bucket && s3_region &&\n               (s3_use_iam_profile || (s3_access_key_id && s3_secret_access_key))\n            :true\n          else\n            :false\n          end",
    "comment": "rubocop:disable Lint/BooleanSymbol",
    "label": "",
    "id": "810"
  },
  {
    "raw_code": "def self.s3_bucket_name\n    @s3_bucket_name ||= s3_bucket.downcase.split(\"/\")[0]\n  end",
    "comment": "rubocop:enable Lint/BooleanSymbol",
    "label": "",
    "id": "811"
  },
  {
    "raw_code": "def self.reset_s3_cache!\n    @use_s3 = nil\n  end",
    "comment": "for testing",
    "label": "",
    "id": "812"
  },
  {
    "raw_code": "def self.reset_redis_config!\n    @config = nil\n    @message_bus_config = nil\n  end",
    "comment": "For testing purposes",
    "label": "",
    "id": "813"
  },
  {
    "raw_code": "def initialize(original_topic, user, post_ids, move_to_pm: false, options: {})\n    @original_topic = original_topic\n    @original_topic_title = original_topic.title\n    @user = user\n    @post_ids = post_ids\n    # For now we store a copy of post_ids. If `freeze_original` is present, we will have new post_ids.\n    # When we create the new posts, we will pluck out post_ids out of this and replace with updated ids.\n    @post_ids_after_move = post_ids\n    @move_to_pm = move_to_pm\n    @options = options\n  end",
    "comment": "options: freeze_original: :boolean  - if true, the original topic will be frozen but not deleted and posts will be \"copied\" to topic",
    "label": "",
    "id": "814"
  },
  {
    "raw_code": "def topics\n    @topics ||= load_topics\n  end",
    "comment": "Lazy initialization",
    "label": "",
    "id": "815"
  },
  {
    "raw_code": "def unique_post_key\n    \"unique#{topic&.private_message? ? \"-pm\" : \"\"}-post-#{user_id}:#{raw_hash}\"\n  end",
    "comment": "The key we use in redis to ensure unique posts",
    "label": "",
    "id": "816"
  },
  {
    "raw_code": "def acting_user\n    @acting_user || user\n  end",
    "comment": "Sometimes the post is being edited by someone else, for example, a mod. If that's the case, they should not be bound by the original poster's restrictions, for example on not posting images.",
    "label": "",
    "id": "817"
  },
  {
    "raw_code": "def has_host_spam?\n    if acting_user.present? &&\n         (\n           acting_user.staged? || acting_user.mature_staged? ||\n             acting_user.has_trust_level?(TrustLevel[1])\n         )\n      return false\n    end",
    "comment": "Prevent new users from posting the same hosts too many times.",
    "label": "",
    "id": "818"
  },
  {
    "raw_code": "def excerpt(maxlength = nil, options = {})\n    Post.excerpt(cooked, maxlength, options.merge(post: self))\n  end",
    "comment": "Strip out most of the markup",
    "label": "",
    "id": "819"
  },
  {
    "raw_code": "def should_secure_uploads?\n    return false if !SiteSetting.secure_uploads?\n    topic_including_deleted = Topic.with_deleted.find_by(id: self.topic_id)\n    return false if topic_including_deleted.blank?\n\n    # NOTE: This is to be used for plugins where adding a new public upload\n    # type that should not be secured via UploadSecurity.register_custom_public_type\n    # is not an option. This also is not taken into account in the secure upload\n    # rake tasks, and will more than likely change in future.\n    modifier_result =\n      DiscoursePluginRegistry.apply_modifier(\n        :post_should_secure_uploads?,\n        nil,\n        self,\n        topic_including_deleted,\n      )\n    return modifier_result if !modifier_result.nil?\n\n    # NOTE: This is meant to be a stopgap solution to prevent secure uploads\n    # in a single place (private messages) for sensitive admin data exports.\n    # Ideally we would want a more comprehensive way of saying that certain\n    # upload types get secured which is a hybrid/mixed mode secure uploads,\n    # but for now this will do the trick.\n    return topic_including_deleted.private_message? if SiteSetting.secure_uploads_pm_only?\n\n    SiteSetting.login_required? || topic_including_deleted.private_message? ||\n      topic_including_deleted.read_restricted_category?\n  end",
    "comment": "NOTE (martin): This is turning into hack city; when changing this also consider how it interacts with UploadSecurity and the uploads.rake tasks.",
    "label": "",
    "id": "820"
  },
  {
    "raw_code": "def extract_quoted_post_numbers\n    temp_collector = []\n\n    # Create relationships for the quotes\n    raw\n      .scan(/\\[quote=\\\"([^\"]+)\"\\]/)\n      .each do |quote|\n        args = parse_quote_into_arguments(quote)\n        # If the topic attribute is present, ensure it's the same topic\n        if !(args[:topic].present? && topic_id != args[:topic]) && args[:post] != post_number\n          temp_collector << args[:post]\n        end",
    "comment": "TODO: move to post-analyzer? Determine what posts are quoted by this post",
    "label": "",
    "id": "821"
  },
  {
    "raw_code": "def trigger_post_process(\n    bypass_bump: false,\n    priority: :normal,\n    new_post: false,\n    skip_pull_hotlinked_images: false\n  )\n    args = {\n      bypass_bump: bypass_bump,\n      cooking_options: self.cooking_options,\n      new_post: new_post,\n      post_id: self.id,\n      skip_pull_hotlinked_images: skip_pull_hotlinked_images,\n    }\n\n    args[:image_sizes] = image_sizes if self.image_sizes.present?\n    args[:invalidate_oneboxes] = true if self.invalidate_oneboxes.present?\n    args[:queue] = priority.to_s if priority && priority != :normal\n\n    Jobs.enqueue(:process_post, args)\n    DiscourseEvent.trigger(:after_trigger_post_process, self)\n  end",
    "comment": "Enqueue post processing for this post",
    "label": "",
    "id": "822"
  },
  {
    "raw_code": "def self.action_aliases\n    {\n      agree_and_keep_hidden: :agree_and_keep,\n      agree_and_silence: :agree_and_keep,\n      agree_and_suspend: :agree_and_keep,\n      agree_and_edit: :agree_and_keep,\n      disagree_and_restore: :disagree,\n      ignore_and_do_nothing: :ignore,\n      delete_user_block: :delete_and_block_user, # legacy name mapped to concern method\n    }\n  end",
    "comment": "Penalties are handled by the modal after the action is performed",
    "label": "",
    "id": "823"
  },
  {
    "raw_code": "def build_legacy_combined_actions(actions, guardian, args)\n    # existing combined logic\n    agree_bundle =\n      actions.add_bundle(\"#{id}-agree\", icon: \"thumbs-up\", label: \"reviewables.actions.agree.title\")\n\n    if !post.user_deleted? && !post.hidden?\n      build_action(actions, :agree_and_hide, icon: \"far-eye-slash\", bundle: agree_bundle)\n    end",
    "comment": "TODO (reviewable-refresh): Remove legacy method once new UI fully deployed",
    "label": "",
    "id": "824"
  },
  {
    "raw_code": "def build_new_separated_actions(actions, guardian, args)\n    build_post_actions_bundle(actions, guardian)\n    build_user_actions_bundle(actions, guardian)\n  end",
    "comment": "TODO (reviewable-refresh): Merge into build_actions post rollout.",
    "label": "",
    "id": "825"
  },
  {
    "raw_code": "def self.remove_for(user_id, topic_id)\n    Notification.where(user_id: user_id, topic_id: topic_id).delete_all\n  end",
    "comment": "Clean up any notifications the user can no longer see. For example, if a topic was previously public then turns private.",
    "label": "",
    "id": "826"
  },
  {
    "raw_code": "def data_hash\n    @data_hash ||=\n      begin\n        return {} if data.blank?\n\n        parsed = JSON.parse(data)\n        return {} if parsed.blank?\n\n        parsed.with_indifferent_access\n      end",
    "comment": "Be wary of calling this frequently. O(n) JSON parsing can suck.",
    "label": "",
    "id": "827"
  },
  {
    "raw_code": "def self.like_types\n    [\n      Notification.types[:liked],\n      Notification.types[:liked_consolidated],\n      Notification.types[:reaction],\n    ]\n  end",
    "comment": "Update `index_notifications_user_menu_ordering_deprioritized_likes` index when updating this as this is used by `Notification.prioritized_list` to deprioritize like typed notifications. Also See `db/migrate/20240306063428_add_indexes_to_notifications.rb`.",
    "label": "",
    "id": "828"
  },
  {
    "raw_code": "def self.record_timing(args)\n    rows = DB.exec(<<~SQL, args)\n      UPDATE post_timings\n       SET msecs = msecs + :msecs\n       WHERE topic_id = :topic_id\n        AND user_id = :user_id\n        AND post_number = :post_number\n    SQL\n\n    record_new_timing(args) if rows == 0\n  end",
    "comment": "Increases a timer if a row exists, otherwise create it",
    "label": "",
    "id": "829"
  },
  {
    "raw_code": "def self.update_topic_counts\n    # Add new records or update existing records\n    DB.exec <<~SQL\n      WITH stats AS (\n        SELECT topics.category_id as category_id,\n               tags.id AS tag_id,\n               COUNT(topics.id) AS topic_count\n        FROM tags\n        INNER JOIN topic_tags ON tags.id = topic_tags.tag_id\n        INNER JOIN topics ON topics.id = topic_tags.topic_id\n               AND topics.deleted_at IS NULL\n               AND topics.category_id IS NOT NULL\n        GROUP BY topics.category_id, tags.id\n      )\n      INSERT INTO category_tag_stats(category_id, tag_id, topic_count)\n      SELECT category_id, tag_id, topic_count FROM stats\n      ON CONFLICT (category_id, tag_id) DO\n      UPDATE SET topic_count = EXCLUDED.topic_count\n    SQL\n\n    # Delete old records\n    DB.exec <<~SQL\n      DELETE FROM category_tag_stats\n      WHERE (category_id, tag_id) NOT IN (\n        SELECT topics.category_id as category_id,\n               tags.id AS tag_id\n        FROM tags\n        INNER JOIN topic_tags ON tags.id = topic_tags.tag_id\n        INNER JOIN topics ON topics.id = topic_tags.topic_id\n               AND topics.deleted_at IS NULL\n               AND topics.category_id IS NOT NULL\n        GROUP BY topics.category_id, tags.id\n      )\n    SQL\n  end",
    "comment": "Recalculate all topic counts if they got out of sync",
    "label": "",
    "id": "830"
  },
  {
    "raw_code": "def self.cleanup!\n    Bookmark.registered_bookmarkables.each(&:cleanup_deleted)\n  end",
    "comment": " Deletes bookmarks that are attached to the bookmarkable records that were deleted more than X days ago. We don't delete bookmarks instantly when trashable bookmarkables are deleted so that there is a grace period to un-delete.",
    "label": "",
    "id": "831"
  },
  {
    "raw_code": "def self.themes_with_overridden_settings\n    sql = <<~SQL\n      SELECT theme.id AS theme_id, theme.name AS theme_name,\n        tss.name AS setting_name, tss.value, tss.data_type\n      FROM themes theme\n      INNER JOIN theme_site_settings tss ON theme.id = tss.theme_id\n      WHERE theme.component = false AND tss.name IN (:setting_names)\n      ORDER BY tss.name, theme.name\n    SQL\n\n    DB\n      .query(sql, setting_names: SiteSetting.themeable_site_settings)\n      .each { |row| row.setting_name = row.setting_name.to_sym }\n      .select do |row|\n        # Do not consider this as an \"overridden\" setting if the value\n        # is the same as the default site setting value.\n        row.value !=\n          SiteSetting\n            .type_supervisor\n            .to_db_value(row.setting_name, SiteSetting.defaults[row.setting_name])\n            .first\n      end",
    "comment": "Gets a list of themes that have theme site setting records and the associated values for those settings, where the value is different from the default site setting value.  @return [Array<Hash>] an array of hashes where each hash contains: - :theme_id [Integer] the ID of the theme - :theme_name [String] the name of the theme - :setting_name [Symbol] the name of the setting - :value [String] the value of the setting - :data_type [Integer] the data type of the setting",
    "label": "",
    "id": "832"
  },
  {
    "raw_code": "def self.generate_theme_map\n    # Similar to what SiteSettings::DbProvider and SiteSettings::LocalProcessProvider do\n    # for their #all method, we can't try to load settings if the DB is not available,\n    # since this method is called within SiteSetting.refresh! which is called on boot.\n    return {} if !can_access_db?\n\n    theme_site_setting_values_map = {}\n    Theme\n      .includes(:theme_site_settings)\n      .not_components\n      .each do |theme|\n        SiteSetting.themeable_site_settings.each do |setting_name|\n          setting = theme.theme_site_settings.find { |s| s.name == setting_name.to_s }\n\n          value =\n            if setting.nil?\n              SiteSetting.defaults[setting_name]\n            else\n              SiteSetting.type_supervisor.to_rb_value(\n                setting.name.to_sym,\n                setting.value,\n                setting.data_type,\n              )\n            end",
    "comment": "Generates a map of theme IDs to their site setting values. When there is no theme site setting for a given theme, the default site setting value is used.  @return [Hash] a map where keys are theme IDs and values are hashes:  { 123 => { setting_name_1 => value_1, setting_name_2 => value_2, ... } }",
    "label": "",
    "id": "833"
  },
  {
    "raw_code": "def cook(raw, opts = {})\n    cook_method = opts[:cook_method]\n    return raw if cook_method == Post.cook_methods[:raw_html]\n\n    if cook_method == Post.cook_methods[:email]\n      cooked = EmailCook.new(raw).cook(opts)\n    else\n      cooked = PrettyText.cook(raw, opts)\n    end",
    "comment": "What we use to cook posts",
    "label": "",
    "id": "834"
  },
  {
    "raw_code": "def embedded_media_count\n    return 0 if @raw.blank?\n\n    # TODO - do we need to look for tags other than img, video and audio?\n    cooked_stripped\n      .css(\"img\", \"video\", \"audio\")\n      .reject do |t|\n        if dom_class = t[\"class\"]\n          (Post.allowed_image_classes & dom_class.split).count > 0\n        end",
    "comment": "How many images are present in the post",
    "label": "",
    "id": "835"
  },
  {
    "raw_code": "def attachment_count\n    return 0 if @raw.blank?\n\n    attachments =\n      cooked_stripped.css(\"a.attachment[href^=\\\"#{Discourse.store.absolute_base_url}\\\"]\")\n    attachments +=\n      cooked_stripped.css(\n        \"a.attachment[href^=\\\"#{Discourse.store.relative_base_url}\\\"]\",\n      ) if Discourse.store.internal?\n    attachments.count\n  end",
    "comment": "How many attachments are present in the post",
    "label": "",
    "id": "836"
  },
  {
    "raw_code": "def self.parse_uri_rfc2396(uri)\n    @parser ||= defined?(URI::RFC2396_Parser) ? URI::RFC2396_Parser.new : URI\n    @parser.parse(uri)\n  end",
    "comment": "from rack ... compat with ruby 2.2",
    "label": "",
    "id": "837"
  },
  {
    "raw_code": "def linked_hosts\n    all_links = raw_links + @onebox_urls\n\n    return {} if all_links.blank?\n    return @linked_hosts if @linked_hosts.present?\n\n    @linked_hosts = {}\n\n    all_links.each do |u|\n      begin\n        uri = self.class.parse_uri_rfc2396(u)\n        host = uri.host\n        @linked_hosts[host] ||= 1 unless host.nil?\n      rescue URI::Error\n        # An invalid URI does not count as a host\n        next\n      end",
    "comment": "Count how many hosts are linked in the post",
    "label": "",
    "id": "838"
  },
  {
    "raw_code": "def raw_links\n    return [] if @raw.blank?\n    return @raw_links if @raw_links.present?\n\n    @raw_links = []\n    cooked_stripped\n      .css(\"a\")\n      .each do |l|\n        # Don't include @mentions in the link count\n        next if link_is_a_mention?(l)\n        # Don't include heading anchor in the link count\n        next if link_is_an_anchor?(l)\n        # Don't include hashtags in the link count\n        next if link_is_a_hashtag?(l)\n        @raw_links << l[\"href\"].to_s\n      end",
    "comment": "Returns an array of all links in a post excluding mentions",
    "label": "",
    "id": "839"
  },
  {
    "raw_code": "def link_count\n    raw_links.size + @onebox_urls.size\n  end",
    "comment": "How many links are present in the post",
    "label": "",
    "id": "840"
  },
  {
    "raw_code": "def self.translations\n    {\n      original_poster: I18n.t(:original_poster),\n      most_recent_poster: I18n.t(:most_recent_poster),\n      frequent_poster: I18n.t(:frequent_poster),\n      joiner: I18n.t(:poster_description_joiner),\n    }\n  end",
    "comment": "localization is fast, but this allows us to avoid calling it in a loop which adds up",
    "label": "",
    "id": "841"
  },
  {
    "raw_code": "def link_to_self\n    errors.add(:base, \"can't link to the same topic\") if (topic_id == link_topic_id)\n  end",
    "comment": "Make sure a topic can't link to itself",
    "label": "",
    "id": "842"
  },
  {
    "raw_code": "def self.safe_create_topic_link(\n    post_id:,\n    user_id:,\n    topic_id:,\n    url:,\n    domain: nil,\n    internal: false,\n    link_topic_id: nil,\n    link_post_id: nil,\n    quote: false,\n    extension: nil,\n    reflection: false\n  )\n    domain ||= Discourse.current_hostname\n\n    sql = <<~SQL\n      WITH new_row AS(\n        INSERT INTO topic_links(\n          post_id,\n          user_id,\n          topic_id,\n          url,\n          domain,\n          internal,\n          link_topic_id,\n          link_post_id,\n          quote,\n          extension,\n          reflection,\n          created_at,\n          updated_at\n        ) VALUES (\n          :post_id,\n          :user_id,\n          :topic_id,\n          :url,\n          :domain,\n          :internal,\n          :link_topic_id,\n          :link_post_id,\n          :quote,\n          :extension,\n          :reflection,\n          :now,\n          :now\n        )\n        ON CONFLICT DO NOTHING\n        RETURNING id\n      )\n      SELECT COALESCE(\n        (SELECT id FROM new_row),\n        (SELECT id FROM topic_links WHERE post_id = :post_id AND topic_id = :topic_id AND url = :url)\n      ), (SELECT id FROM new_row) IS NOT NULL\n    SQL\n\n    topic_link_id, new_record =\n      DB.query_single(\n        sql,\n        post_id: post_id,\n        user_id: user_id,\n        topic_id: topic_id,\n        url: url,\n        domain: domain,\n        internal: internal,\n        link_topic_id: link_topic_id,\n        link_post_id: link_post_id,\n        quote: quote,\n        extension: extension,\n        reflection: reflection,\n        now: Time.now,\n      )\n\n    DB.after_commit { crawl_link_title(topic_link_id) } if new_record\n\n    topic_link_id\n  end",
    "comment": "This pattern is used to create topic links very efficiently with minimal errors under heavy concurrent use  It avoids a SELECT to find out if the record is there and minimizes all the work it needs to do in case a record is missing  It handles calling the required callback and has parity with Rails implementation  Usually we would rely on ActiveRecord but in this case we have had lots of churn around creation of topic links leading to hard to debug log messages in production ",
    "label": "",
    "id": "843"
  },
  {
    "raw_code": "def ensure_payload_url_allowed\n    return if payload_url.blank?\n    uri = URI(payload_url.strip)\n\n    allowed =\n      begin\n        FinalDestination::SSRFDetector.lookup_and_filter_ips(uri.hostname).present?\n      rescue FinalDestination::SSRFDetector::DisallowedIpError\n        false\n      end",
    "comment": "This check is to improve UX IPs are re-checked at request time",
    "label": "",
    "id": "844"
  },
  {
    "raw_code": "def self.feature_topics(batched: false, batch_size: nil)\n    current = {}\n    CategoryFeaturedTopic\n      .select(:topic_id, :category_id)\n      .order(:rank)\n      .each { |f| (current[f.category_id] ||= []) << f.topic_id }\n\n    batch_size ||= DEFAULT_BATCH_SIZE\n\n    next_category_id = batched ? Discourse.redis.get(NEXT_CATEGORY_ID_KEY).to_i : 0\n\n    categories =\n      Category\n        .select(:id, :topic_id, :num_featured_topics)\n        .where(\"id >= ?\", next_category_id)\n        .order(\"id ASC\")\n        .limit(batch_size)\n        .to_a\n\n    if batched\n      if categories.length == batch_size\n        next_id = Category.where(\"id > ?\", categories.last.id).order(:id).pick(:id)\n        next_id ? Discourse.redis.setex(NEXT_CATEGORY_ID_KEY, 1.day, next_id) : clear_batch!\n      else\n        clear_batch!\n      end",
    "comment": "Populates the category featured topics.",
    "label": "",
    "id": "845"
  },
  {
    "raw_code": "def toggle_mute(user_id)\n    change_level user_id, (muted?(user_id) ? levels[:regular] : levels[:muted])\n  end",
    "comment": "Enable/disable the mute on the topic",
    "label": "",
    "id": "846"
  },
  {
    "raw_code": "def self.create_from(args = {})\n    url = args[:url][0...TopicLink.max_url_length]\n    return nil if url.blank?\n\n    uri = UrlHelper.relaxed_parse(url)\n    urls = Set.new\n    urls << url\n    if url =~ /\\Ahttp/\n      urls << url.sub(/\\Ahttps/, \"http\")\n      urls << url.sub(/\\Ahttp:/, \"https:\")\n      urls << UrlHelper.schemaless(url)\n    end",
    "comment": "Create a click from a URL and post_id",
    "label": "",
    "id": "847"
  },
  {
    "raw_code": "def self.refresh_daily!\n    DistributedMutex.synchronize(\"update_top_topics\", validity: 5.minutes) do\n      transaction do\n        remove_invisible_topics\n        add_new_visible_topics\n\n        update_counts_and_compute_scores_for(:daily)\n      end",
    "comment": "The top topics we want to refresh often",
    "label": "",
    "id": "848"
  },
  {
    "raw_code": "def self.refresh_older!\n    DistributedMutex.synchronize(\"update_top_topics\", validity: 5.minutes) do\n      older_periods = periods - %i[daily all]\n\n      transaction { older_periods.each { |period| update_counts_and_compute_scores_for(period) } }\n\n      compute_top_score_for(:all)\n    end",
    "comment": "We don't have to refresh these as often",
    "label": "",
    "id": "849"
  },
  {
    "raw_code": "def build_legacy_combined_actions(actions, guardian, args)\n    unless approved?\n      if topic&.closed?\n        build_action(actions, :approve_post_closed, icon: \"check\", confirm: true)\n      else\n        build_action(actions, :approve_post, icon: \"check\") if target_created_by.present?\n      end",
    "comment": "TODO (reviewable-refresh): Remove this method once new UI is fully deployed",
    "label": "",
    "id": "850"
  },
  {
    "raw_code": "def self.report_top_referrers(report)\n    report.y_titles[:num_clicks] = I18n.t(\"reports.#{report.type}.num_clicks\")\n    report.y_titles[:num_topics] = I18n.t(\"reports.#{report.type}.num_topics\")\n\n    num_clicks =\n      link_count_per_user(\n        start_date: report.start_date,\n        end_date: report.end_date,\n        category_id: report.category_id,\n        include_subcategories: report.include_subcategories,\n      )\n    num_topics =\n      topic_count_per_user(\n        start_date: report.start_date,\n        end_date: report.end_date,\n        category_id: report.category_id,\n        include_subcategories: report.include_subcategories,\n      )\n    user_id_lookup =\n      User\n        .where(username: num_clicks.keys)\n        .select(:id, :username, :uploaded_avatar_id)\n        .inject({}) do |sum, v|\n          sum[v.username] = {\n            id: v.id,\n            user_avatar_template: User.avatar_template(v.username, v.uploaded_avatar_id),\n          }\n          sum\n        end",
    "comment": "Return top 10 users who brought traffic to the site within the last 30 days",
    "label": "",
    "id": "851"
  },
  {
    "raw_code": "def self.report_top_traffic_sources(report)\n    report.y_titles[:num_clicks] = I18n.t(\"reports.#{report.type}.num_clicks\")\n    report.y_titles[:num_topics] = I18n.t(\"reports.#{report.type}.num_topics\")\n    report.y_titles[:num_users] = I18n.t(\"reports.#{report.type}.num_users\")\n\n    num_clicks =\n      link_count_per_domain(\n        start_date: report.start_date,\n        end_date: report.end_date,\n        category_id: report.category_id,\n        include_subcategories: report.include_subcategories,\n      )\n    num_topics =\n      topic_count_per_domain(\n        num_clicks.keys,\n        category_id: report.category_id,\n        include_subcategories: report.include_subcategories,\n        start_date: report.start_date,\n        end_date: report.end_date,\n      )\n    report.data = []\n    num_clicks.each_key do |domain|\n      report.data << {\n        domain: domain,\n        num_clicks: num_clicks[domain],\n        num_topics: num_topics[domain],\n      }\n    end",
    "comment": "Return top 10 domains that brought traffic to the site within the last 30 days",
    "label": "",
    "id": "852"
  },
  {
    "raw_code": "def self.group_id_from_param(group_param)\n    return group_param.id if group_param.is_a?(Group)\n    return group_param if group_param.is_a?(Integer)\n    return Group[group_param].id if group_param.is_a?(Symbol)\n    return group_param.to_i if group_param.to_i.to_s == group_param\n\n    # subtle, using Group[] ensures the group exists in the DB\n    Group[group_param.to_sym].id\n  end",
    "comment": "given something that might be a group name, id, or record, return the group id",
    "label": "",
    "id": "853"
  },
  {
    "raw_code": "def destroy_deletions\n    if @deletions\n      @deletions.each do |gu|\n        gu.destroy\n        User.where(\n          \"id = ? AND primary_group_id = ?\",\n          gu.user_id,\n          gu.group_id,\n        ).update_all \"primary_group_id = NULL\"\n      end",
    "comment": "hack around AR",
    "label": "",
    "id": "854"
  },
  {
    "raw_code": "def self.clear_debounce_cache!\n    Discourse.redis.keys(\"__SEARCH__LOG_*\").each { |k| Discourse.redis.del(k) }\n  end",
    "comment": "for testing",
    "label": "",
    "id": "855"
  },
  {
    "raw_code": "def self.find_id_by_slug(slug)\n    self.pluck(:id, :name).each { |id, name| return id if Slug.for(name) == slug }\n    nil\n  end",
    "comment": "TODO: long term we can cache this if TONs of tag groups exist",
    "label": "",
    "id": "856"
  },
  {
    "raw_code": "def self.by_day(start_date, end_date, group_id = nil)\n    counts_by_day_query(start_date, end_date, group_id).count\n  end",
    "comment": "A count of visits in a date range by day",
    "label": "",
    "id": "857"
  },
  {
    "raw_code": "def sync_notification_channel_position\n    @unread_notifications_by_type = nil\n    self.notification_channel_position = MessageBus.last_id(\"/notification/#{id}\")\n  end",
    "comment": "tricky, we need our bus to be subscribed from the right spot",
    "label": "",
    "id": "858"
  },
  {
    "raw_code": "def password_required!\n    @password_required = true\n  end",
    "comment": "Indicate that this is NOT a passwordless account for the purposes of validation",
    "label": "",
    "id": "859"
  },
  {
    "raw_code": "def small_avatar_url\n    avatar_template_url.gsub(\"{size}\", \"45\")\n  end",
    "comment": "Don't pass this up to the client - it's meant for server side use This is used in - self oneboxes in open graph data - emails",
    "label": "",
    "id": "860"
  },
  {
    "raw_code": "def like_count\n    UserAction.where(user_id: id, action_type: UserAction::WAS_LIKED).count\n  end",
    "comment": "The following count methods are somewhat slow - definitely don't use them in a loop. They might need to be denormalized",
    "label": "",
    "id": "861"
  },
  {
    "raw_code": "def has_trust_level?(level)\n    raise InvalidTrustLevel.new(\"Invalid trust level #{level}\") unless TrustLevel.valid?(level)\n\n    admin? || moderator? || staged? || TrustLevel.compare(trust_level, level)\n  end",
    "comment": "Use this helper to determine if the user has a particular trust level. Takes into account admin, etc.",
    "label": "",
    "id": "862"
  },
  {
    "raw_code": "def admin?\n    admin\n  end",
    "comment": "a touch faster than automatic",
    "label": "",
    "id": "863"
  },
  {
    "raw_code": "def flag_linked_posts_as_spam\n    results = []\n\n    disagreed_flag_post_ids =\n      PostAction\n        .where(post_action_type_id: post_action_type_view.types[:spam])\n        .where.not(disagreed_at: nil)\n        .pluck(:post_id)\n\n    topic_links\n      .includes(:post)\n      .where.not(post_id: disagreed_flag_post_ids)\n      .each do |tl|\n        message =\n          I18n.t(\n            \"flag_reason.spam_hosts\",\n            base_path: Discourse.base_path,\n            locale: SiteSetting.default_locale,\n          )\n        results << PostActionCreator.create(Discourse.system_user, tl.post, :spam, message: message)\n      end",
    "comment": "Flag all posts from a user as spam",
    "label": "",
    "id": "864"
  },
  {
    "raw_code": "def email=(new_email)\n    if primary_email\n      primary_email.email = new_email\n    else\n      build_primary_email email: new_email, skip_validate_email: !should_validate_email_address?\n    end",
    "comment": "Shortcut to set the primary email of the user. Automatically removes any identical secondary emails.",
    "label": "",
    "id": "865"
  },
  {
    "raw_code": "def self.resolve_modifier_for_themes(theme_ids, modifier_name)\n    return nil if !(config = self.modifiers[modifier_name])\n\n    all_values =\n      self\n        .where(theme_id: theme_ids)\n        .where.not(modifier_name => nil)\n        .map { |s| s.public_send(modifier_name) }\n    case config[:type]\n    when :boolean\n      all_values.any?\n    when :string_array\n      all_values.flatten(1)\n    else\n      raise ThemeModifierSetError, \"Invalid theme modifier combine_mode\"\n    end",
    "comment": "Given the ids of multiple active themes / theme components, this function will combine them into a 'resolved' behavior",
    "label": "",
    "id": "866"
  },
  {
    "raw_code": "def self.load_modifiers\n    hash = {}\n    columns_hash.each do |column_name, info|\n      next if %w[id theme_id theme_setting_modifiers].include?(column_name)\n\n      type = nil\n      if info.type == :string && info.array?\n        type = :string_array\n      elsif info.type == :boolean && !info.array?\n        type = :boolean\n      else\n        if !%i[boolean string].include?(info.type)\n          raise ThemeModifierSetError, \"Invalid theme modifier column type\"\n        end",
    "comment": "Build the list of modifiers from the DB schema. This allows plugins to introduce new modifiers by adding columns to the table",
    "label": "",
    "id": "867"
  },
  {
    "raw_code": "def self.report(user, topic_id = nil)\n    tag_ids = muted_tag_ids(user)\n    sql = new_and_unread_sql(topic_id, user, tag_ids)\n    sql = tags_included_wrapped_sql(sql)\n\n    report =\n      DB.query(\n        sql + \"\\n\\n LIMIT :max_topics\",\n        {\n          user_id: user.id,\n          topic_id: topic_id,\n          min_new_topic_date: Time.at(SiteSetting.min_new_topics_time).to_datetime,\n          max_topics: TopicTrackingState::MAX_TOPICS,\n          user_first_unread_at: user.user_stat.first_unread_at,\n        }.merge(treat_as_new_topic_params),\n      )\n\n    report\n  end",
    "comment": "Sam: this is a hairy report, in particular I need custom joins and fancy conditions Dropping to sql_builder so I can make sense of it.  Keep in mind, we need to be able to filter on a GROUP of users, and zero in on topic all our existing scope work does not do this  This code needs to be VERY efficient as it is triggered via the message bus and may steal cycles from usual requests",
    "label": "",
    "id": "868"
  },
  {
    "raw_code": "def find_user_data\n    if @guardian.current_user && @all_topics.present?\n      topic_lookup = TopicUser.lookup_for(@guardian.current_user, @all_topics)\n      @all_topics.each { |ft| ft.user_data = topic_lookup[ft.id] }\n    end",
    "comment": "Attach some data for serialization to each topic",
    "label": "",
    "id": "869"
  },
  {
    "raw_code": "def sort_unpinned\n    if @guardian.current_user && @all_topics.present?\n      categories_with_descendants.each do |c|\n        next if c.displayable_topics.blank? || c.displayable_topics.size <= c.num_featured_topics\n        unpinned = []\n        c.displayable_topics.each do |t|\n          unpinned << t if t.pinned_at && PinnedCheck.unpinned?(t, t.user_data)\n        end",
    "comment": "Put unpinned topics at the end of the list",
    "label": "",
    "id": "870"
  },
  {
    "raw_code": "def self.extract_from(post)\n    doc = Nokogiri::HTML5.fragment(post.cooked)\n\n    uniq = {}\n\n    doc\n      .css(\"aside.quote[data-topic]\")\n      .each do |a|\n        topic_id = a[\"data-topic\"].to_i\n        post_number = a[\"data-post\"].to_i\n\n        next if topic_id == 0 || post_number == 0\n        next if uniq[[topic_id, post_number]]\n        next if post.topic_id == topic_id && post.post_number == post_number\n\n        uniq[[topic_id, post_number]] = true\n      end",
    "comment": "NOTE we already have a path that does this for topic links, however topic links exclude quotes and links within a topic we are double parsing this fragment, this may be worth optimising later",
    "label": "",
    "id": "871"
  },
  {
    "raw_code": "def get_localization(locale = I18n.locale)\n    locale_str = locale.to_s.sub(\"-\", \"_\")\n\n    # prioritise exact match\n    if match = localizations.find { |l| l.locale == locale_str }\n      return match\n    end",
    "comment": "Returns the localization for the given locale, or the best match if an exact match is not found. The query used to find the localization is optimized for performance, and assumes that localizations are indexed by locale, and have been preloaded where necessary. @return [Localization, nil] the localization object for the given locale, or nil if no match is found.",
    "label": "",
    "id": "872"
  },
  {
    "raw_code": "def recalculate_stats_interval\n      30 # minutes\n    end",
    "comment": "Could be configurable, multisite need to support it.",
    "label": "",
    "id": "873"
  },
  {
    "raw_code": "def build_post_actions_bundle(actions, guardian)\n    bundle =\n      actions.add_bundle(\n        \"#{id}-post-actions\",\n        label: \"reviewables.actions.post_actions.bundle_title\",\n      )\n\n    # Always include the no-op action\n    build_action(actions, :no_action_post, bundle:)\n\n    return bundle unless target_post\n\n    if target_post.trashed? && guardian.can_recover_post?(target_post)\n      build_action(actions, :restore_post, bundle:)\n    end",
    "comment": "Standard post-actions bundle. Consumers should use the returned bundle value when adding post-focused actions.  @param actions [Reviewable::Actions] Actions instance to add the bundle to. @param guardian [Guardian] Guardian instance to check permissions.  @return [Reviewable::Actions::Bundle] The created post actions bundle.",
    "label": "",
    "id": "874"
  },
  {
    "raw_code": "def build_user_actions_bundle(actions, guardian)\n    bundle =\n      actions.add_bundle(\n        \"#{id}-user-actions\",\n        label: \"reviewables.actions.user_actions.bundle_title\",\n      )\n\n    # Always include the no-op action\n    build_action(actions, :no_action_user, bundle:)\n\n    return bundle unless target_user\n\n    if guardian.can_silence_user?(target_user)\n      build_action(actions, :silence_user, bundle:, client_action: \"silence\")\n    end",
    "comment": "Standard user-actions bundle and default user actions.  @param actions [Reviewable::Actions] Actions instance to add the bundle to. @param guardian [Guardian] Guardian instance to check permissions.  @return [Reviewable::Actions::Bundle] The created user actions bundle.",
    "label": "",
    "id": "875"
  },
  {
    "raw_code": "def build_actions(actions, guardian, args)\n    if guardian.can_see_reviewable_ui_refresh?\n      build_new_separated_actions(actions, guardian, args)\n    else\n      build_legacy_combined_actions(actions, guardian, args)\n    end",
    "comment": "Build actions for the reviewable based on the current state and guardian permissions.  @TODO (reviewable-refresh) Replace this method with {Reviewable#build_actions} once the new UI is fully implemented.  @param actions [Reviewable::Actions] Actions instance to add the bundle to. @param guardian [Guardian] Guardian instance to check permissions. @param args [Hash] Additional arguments for building actions.  @return [void]",
    "label": "",
    "id": "876"
  },
  {
    "raw_code": "def build_legacy_combined_actions(actions, guardian, args)\n    raise NotImplementedError, \"Including class must implement #build_legacy_combined_actions\"\n  end",
    "comment": "Build legacy combined actions for the reviewable.  Classes that include this module should implement this method to define the legacy combined actions for their specific reviewable type.  @TODO (reviewable-refresh) Remove this method once the new UI is fully implemented.  @param actions [Reviewable::Actions] Actions instance to add the bundle to. @param guardian [Guardian] Guardian instance to check permissions. @param args [Hash] Additional arguments for building actions.  @return [void]",
    "label": "",
    "id": "877"
  },
  {
    "raw_code": "def build_new_separated_actions(actions, guardian, args)\n    raise NotImplementedError, \"Including class must implement #build_new_separated_actions\"\n  end",
    "comment": "Build new separated actions for the reviewable.  Classes that include this module should implement this method to define the new separated actions for their specific reviewable type.  @TODO (reviewable-refresh) Remove this method once the new UI is fully implemented.  @param actions [Reviewable::Actions] Actions instance to add the bundle to. @param guardian [Guardian] Guardian instance to check permissions. @param args [Hash] Additional arguments for building actions.  @return [void]",
    "label": "",
    "id": "878"
  },
  {
    "raw_code": "def build_action(\n    actions,\n    id,\n    icon: nil,\n    button_class: nil,\n    bundle: nil,\n    client_action: nil,\n    confirm: false,\n    require_reject_reason: false\n  )\n    actions.add(id, bundle: bundle) do |action|\n      prefix = \"reviewables.actions.#{id}\"\n      action.icon = icon if icon\n      action.button_class = button_class if button_class\n      action.label = \"#{prefix}.title\"\n      action.description = \"#{prefix}.description\"\n      action.client_action = client_action if client_action\n      action.confirm_message = \"#{prefix}.confirm\" if confirm\n      action.completed_message = \"#{prefix}.complete\"\n      action.require_reject_reason = require_reject_reason\n    end",
    "comment": "Build a single reviewable action and add it to the provided actions list. This is the canonical API used by both the legacy and refreshed UI code paths.  @param actions [Reviewable::Actions] Actions instance to add to. @param id [Symbol] Symbol for the action, used to derive I18n keys. @param icon [String] Optional name of the icon to display with the action. Ignored in the refreshed UI. @param button_class [String] Optional CSS class for buttons in clients that render it. @param bundle [Reviewable::Actions::Bundle] Optional bundle object returned by add_bundle to group actions. @param client_action [String] Optional client-side action identifier (e.g. \"edit\"). @param confirm [Boolean] When true, uses \"reviewables.actions.<id>.confirm\" for confirm_message. @param require_reject_reason [Boolean] When true, requires a rejection reason for the action.  @return [Reviewable::Actions] The updated actions instance.",
    "label": "",
    "id": "879"
  },
  {
    "raw_code": "def target_user\n    try(:target_created_by)\n  end",
    "comment": "Returns the user associated with the reviewable, if applicable. For most reviewables, this will be the user who created the reviewable, though some reviewables may need to implement this method differently (for example, ReviewableUser).  @return [User] The user associated with the reviewable.",
    "label": "",
    "id": "880"
  },
  {
    "raw_code": "def target_post\n    @post ||=\n      if defined?(target) && target.is_a?(Post)\n        target\n      elsif defined?(target_id)\n        Post.with_deleted.find_by(id: target_id)\n      end",
    "comment": "Returns the post associated with the reviewable, if applicable. This method assumes that the including class has a `target` that is a Post or a `target_id` that can be used to look up the Post.  @return [Post, nil] The post associated with the reviewable, or nil if not found.",
    "label": "",
    "id": "881"
  },
  {
    "raw_code": "def delete_opts\n    {\n      delete_posts: true,\n      prepare_for_destroy: true,\n      block_urls: true,\n      delete_as_spammer: true,\n      context: \"review\",\n    }\n  end",
    "comment": "Options for deleting a user, used by perform_delete_user and perform_delete_and_block_user.",
    "label": "",
    "id": "882"
  },
  {
    "raw_code": "def create_result(status, transition_to = nil, flagging_user_ids = [], recalculate_score = true)\n    result = Reviewable::PerformResult.new(self, status)\n    result.transition_to = transition_to\n    if flagging_user_ids.any? && target_post\n      result.update_flag_stats = {\n        status: map_reviewable_status_to_flag_status(transition_to),\n        user_ids: flagging_user_ids,\n      }\n      result.recalculate_score = recalculate_score\n    end",
    "comment": "Create a result object.  @param status [Symbol] The status of the result. @param transition_to [Symbol] The state to transition to. @param recalculate_score [Boolean] Whether to recalculate the score. @yield [result] The result object.  @return [Reviewable::PerformResult] The created result object.",
    "label": "",
    "id": "883"
  },
  {
    "raw_code": "def custom_fields_for_ids(ids, allowed_fields)\n      klass = \"#{name}CustomField\".constantize\n      foreign_key = \"#{name.underscore}_id\".to_sym\n\n      result = {}\n\n      return result if allowed_fields.blank?\n\n      klass\n        .where(foreign_key => ids, :name => allowed_fields)\n        .order(:id)\n        .pluck(foreign_key, :name, :value)\n        .each do |cf|\n          result[cf[0]] ||= {}\n          append_custom_field(result[cf[0]], cf[1], cf[2])\n        end",
    "comment": "To avoid n+1 queries, use this function to retrieve lots of custom fields in one go and create a \"sideloaded\" version for easy querying by id.",
    "label": "",
    "id": "884"
  },
  {
    "raw_code": "def upsert_custom_fields(fields)\n    fields.each do |k, v|\n      row_count = _custom_fields.where(name: k).update_all(value: v, updated_at: Time.now)\n      _custom_fields.create!(name: k, value: v) if row_count == 0\n\n      custom_fields[k.to_s] = v # We normalize custom_fields as strings\n    end",
    "comment": "`upsert_custom_fields` will only insert/update existing fields, and will not delete anything. It is safer under concurrency and is recommended when you just want to attach fields to things without maintaining a specific set of fields.",
    "label": "",
    "id": "885"
  },
  {
    "raw_code": "def create_singular(name, value, field_type = nil)\n    write_value = value.is_a?(Hash) || field_type == :json ? value.to_json : value\n    write_value = \"t\" if write_value.is_a?(TrueClass)\n    write_value = \"f\" if write_value.is_a?(FalseClass)\n    row_count = DB.exec(<<~SQL, name: name, value: write_value, id: id, now: Time.zone.now)\n      INSERT INTO #{_custom_fields.table_name} (#{custom_fields_fk}, name, value, created_at, updated_at)\n      VALUES (:id, :name, :value, :now, :now)\n      ON CONFLICT DO NOTHING\n    SQL\n    _custom_fields.where(name: name).update_all(value: write_value) if row_count == 0\n  end",
    "comment": "We support unique indexes on certain fields. In the event two concurrent processes attempt to update the same custom field we should catch the error and perform an update instead.",
    "label": "",
    "id": "886"
  },
  {
    "raw_code": "def staff?\n    admin || moderator\n  end",
    "comment": "any user that is either a moderator or an admin",
    "label": "",
    "id": "887"
  },
  {
    "raw_code": "def perform_increment!(key, async: false)\n        if async\n          CachedCounting.ensure_thread!\n          CachedCounting.queue(key, self)\n        else\n          CachedCounting.queue(key, self)\n          CachedCounting.clear_flush_to_db_lock!\n          CachedCounting.flush_in_memory\n          CachedCounting.flush_to_db\n        end",
    "comment": "perform increment is a risky call in test, it shifts stuff to background threads and leaks data in the DB Require caller is deliberate if they want that  Splitting implementation to avoid any perf impact given this is a method that is called a lot",
    "label": "",
    "id": "888"
  },
  {
    "raw_code": "def query_loaded_from_slugs(category_slugs, categories)\n      category_slugs\n        .map(&:downcase)\n        .map do |slug|\n          slug_path = split_slug_path(slug)\n          next if slug_path.blank?\n\n          slug_path.map! { CGI.escape(_1) } if SiteSetting.slug_generation_method == \"encoded\"\n          parent_slug, child_slug = slug_path.last(2)\n\n          # Category slugs can be in the parent:child format, if there\n          # is no child then the \"parent\" part of the slug is just the\n          # entire slug we look for.\n          #\n          # Otherwise if the child slug is present, we find the child\n          # by its slug then find the parent by its slug and the child's\n          # parent ID to make sure they match.\n          if child_slug.present?\n            categories.find do |cat|\n              if cat.slug.casecmp?(child_slug) && cat.parent_category_id\n                categories.find do |parent_category|\n                  parent_category.id == cat.parent_category_id &&\n                    parent_category.slug.casecmp?(parent_slug)\n                end",
    "comment": " Finds any categories that match the provided slugs, supporting the parent:child format for category slugs (only one level of depth supported).  @param {Array} category_slugs - Slug strings to look up, can also be in the parent:child format @param {Array} categories - An array of Category models scoped to the user's guardian permissions.",
    "label": "",
    "id": "889"
  },
  {
    "raw_code": "def report_consolidated_page_views_browser_detection(report)\n      Report.report_site_traffic(report)\n    end",
    "comment": "NOTE: This report is deprecated, once use_legacy_pageviews is always false or no longer needed we can delete this.  The new version of this report is site_traffic.",
    "label": "",
    "id": "890"
  },
  {
    "raw_code": "def report_consolidated_page_views(report)\n      filters = %w[page_view_logged_in page_view_anon page_view_crawler]\n\n      report.modes = [Report::MODES[:stacked_chart]]\n\n      requests =\n        filters.map do |filter|\n          color = report.colors[:turquoise]\n          color = report.colors[:lime] if filter == \"page_view_anon\"\n          color = report.colors[:purple] if filter == \"page_view_crawler\"\n\n          {\n            req: filter,\n            label: I18n.t(\"reports.consolidated_page_views.xaxis.#{filter}\"),\n            color: color,\n            data: ApplicationRequest.where(req_type: ApplicationRequest.req_types[filter]),\n          }\n        end",
    "comment": "NOTE: This report is superseded by \"SiteTraffic\". Eventually once use_legacy_pageviews is always false or no longer needed, and users no longer rely on the data in this old report in the transition period, we can delete this.",
    "label": "",
    "id": "891"
  },
  {
    "raw_code": "def discourse_config_environment(testing: false)\n    # TODO: Can this come from Ember CLI somehow?\n    config = {\n      modulePrefix: \"discourse\",\n      environment: Rails.env,\n      rootURL: Discourse.base_path,\n      locationType: \"history\",\n      EmberENV: {\n        FEATURES: {\n        },\n        EXTEND_PROTOTYPES: false,\n      },\n      APP: {\n        name: \"discourse\",\n        version: \"#{Discourse::VERSION::STRING} #{Discourse.git_version}\",\n        # LOG_RESOLVER: true,\n        # LOG_ACTIVE_GENERATION: true,\n        # LOG_TRANSITIONS: true,\n        # LOG_TRANSITIONS_INTERNAL: true,\n        # LOG_VIEW_LOOKUPS: true,\n      },\n    }\n\n    if testing\n      config[:environment] = \"test\"\n      config[:locationType] = \"none\"\n      config[:APP][:LOG_ACTIVE_GENERATION] = false\n      config[:APP][:LOG_VIEW_LOOKUPS] = false\n      config[:APP][:rootElement] = \"#ember-testing\"\n      config[:APP][:autoboot] = false\n    end",
    "comment": "This generated equivalent of Ember's config/environment.js is used in development, production, and theme tests. (i.e. everywhere except regular tests)",
    "label": "",
    "id": "892"
  },
  {
    "raw_code": "def crawlable_meta_data(opts = nil)\n    opts ||= {}\n    opts[:url] ||= \"#{Discourse.base_url_no_prefix}#{request.fullpath}\"\n\n    # if slug generation method is encoded, non encoded urls can sneak in\n    # via bots\n    url = opts[:url]\n    if url.encoding.name != \"UTF-8\" || !url.valid_encoding?\n      opts[:url] = url.dup.force_encoding(\"UTF-8\").scrub!\n    end",
    "comment": "Creates open graph and twitter card meta data",
    "label": "",
    "id": "893"
  },
  {
    "raw_code": "def replace_plugin_html(name)\n    if (html = build_plugin_html(name)).present?\n      html\n    else\n      yield\n      nil\n    end",
    "comment": "If there is plugin HTML return that, otherwise yield to the template",
    "label": "",
    "id": "894"
  },
  {
    "raw_code": "def core_tree_hash\n  Tempfile.create do |f|\n    f.close\n\n    git_dir = capture(\"git\", \"rev-parse\", \"--git-dir\").strip\n    FileUtils.cp \"#{git_dir}/index\", f.path\n\n    env = { \"GIT_INDEX_FILE\" => f.path }\n\n    # Remove all files from the index, then add only JS_SOURCE_PATHS\n    system(env, \"git\", \"rm\", \"-r\", \"--cached\", \".\", \"--quiet\", exception: true)\n    system(env, \"git\", \"add\", *JS_SOURCE_PATHS, exception: true)\n\n    capture(env, \"git\", \"write-tree\").strip\n  end",
    "comment": "Returns a git tree-hash representing the current state of Discourse core JS source paths. Only files in JS_SOURCE_PATHS are included in the tree hash.",
    "label": "",
    "id": "895"
  },
  {
    "raw_code": "def unbundled_require(gem)\n  if defined?(::Bundler)\n    spec_path = Dir.glob(\"#{Gem.dir}/specifications/#{gem}-*.gemspec\").last\n    raise LoadError if spec_path.nil?\n\n    spec = Gem::Specification.load spec_path\n    spec.activate\n  end",
    "comment": "based on https://gist.github.com/zaius/2643079",
    "label": "",
    "id": "896"
  },
  {
    "raw_code": "def format_number(n)\n  n.to_s.gsub(/(\\d)(?=\\d{3}+(?:\\.|$))(\\d{3}\\..*)?/, '\\1,\\2')\nend",
    "comment": "http://rubyforge.org/snippet/download.php?type=snippet&id=511",
    "label": "",
    "id": "897"
  },
  {
    "raw_code": "def best_of(a, b)\n    return a unless b\n    return b unless a\n\n    a[50] < b[50] ? a : b\n  end",
    "comment": "NOTE: we run the most expensive page first in the bench",
    "label": "",
    "id": "898"
  },
  {
    "raw_code": "def initialize\n    db_password = ENV[\"DB_PASS\"] || \"import_password\"\n    local_db = ActiveRecord::Base.connection_db_config.configuration_hash\n    @raw_connection =\n      PG.connect(\n        dbname: local_db[:database],\n        host: \"localhost\",\n        port: local_db[:port],\n        user: \"postgres\",\n        password: db_password,\n      )\n\n    @source_db_config = {\n      dbname: ENV[\"DB_NAME\"] || \"dd_demo\",\n      host: ENV[\"DB_HOST\"] || \"localhost\",\n      user: \"postgres\",\n      password: db_password,\n    }\n\n    raise \"SOURCE_BASE_URL missing!\" unless ENV[\"SOURCE_BASE_URL\"]\n\n    @source_base_url = ENV[\"SOURCE_BASE_URL\"]\n    @uploads_path = ENV[\"UPLOADS_PATH\"]\n    @uploader = ImportScripts::Uploader.new\n\n    @source_cdn = ENV[\"SOURCE_CDN\"] if ENV[\"SOURCE_CDN\"]\n\n    local_version = @raw_connection.exec(\"select max(version) from schema_migrations\")\n    local_version = local_version.first[\"max\"]\n    source_version = source_raw_connection.exec(\"select max(version) from schema_migrations\")\n    source_version = source_version.first[\"max\"]\n\n    if local_version != source_version\n      raise \"DB schema mismatch. Databases must be at the same migration version. Local is #{local_version}, other is #{source_version}\"\n    end",
    "comment": "DB_NAME: name of database being merged into the current local db DB_HOST: hostname of database being merged DB_PASS: password used to access the Discourse database by the postgres user UPLOADS_PATH: absolute path of the directory containing \"original\" and \"optimized\" dirs. e.g. /home/discourse/other-site/public/uploads/default SOURCE_BASE_URL: base url of the site being merged. e.g. https://meta.discourse.org SOURCE_CDN: (optional) base url of the CDN of the site being merged. e.g. https://discourse-cdn-sjc1.com/business4",
    "label": "",
    "id": "899"
  },
  {
    "raw_code": "def create_permalinks\n    puts \"\", \"Creating permalinks...\", \"\"\n\n    puts \"    User pages...\"\n\n    start = Time.now\n    count = 0\n    now = Time.zone.now\n\n    sql = \"COPY permalinks (url, created_at, updated_at, external_url) FROM STDIN\"\n\n    @raw_connection.copy_data(sql, @encoder) do\n      User\n        .includes(:_custom_fields)\n        .find_each do |u|\n          count += 1\n          ucf = u.custom_fields\n          if ucf && ucf[\"import_id\"]\n            vanilla_username = ucf[\"import_username\"] || u.username\n            @raw_connection.put_copy_data(\n              [\"profile/#{vanilla_username}\", now, now, \"/users/#{u.username}\"],\n            )\n          end",
    "comment": "TODO: too slow",
    "label": "",
    "id": "900"
  },
  {
    "raw_code": "def find_upload(post, attachment_id)\n    sql =\n      \"SELECT a.attachmentid attachment_id, a.userid user_id, a.filename filename\n             FROM #{TABLE_PREFIX}attachment a\n            WHERE a.attachmentid = #{attachment_id}\"\n    results = mysql_query(sql)\n\n    unless row = results.first\n      puts \"Couldn't find attachment record for attachment_id = #{attachment_id} post.id = #{post.id}\"\n      return\n    end",
    "comment": "find the uploaded file information from the db",
    "label": "",
    "id": "901"
  },
  {
    "raw_code": "def count(sql)\n    query(sql).first[:count]\n  end",
    "comment": "Executes a database query and returns the value of the 'count' column.",
    "label": "",
    "id": "902"
  },
  {
    "raw_code": "def parse_code(text, fragment, index)\n    next_fragment = next_fragment(index)\n\n    next_code = next_fragment.dig(:attributes, :\"code-block\")\n    if next_code\n      previous_fragment = previous_fragment(index)\n      previous_code = previous_fragment.dig(:attributes, :\"code-block\")\n\n      if previous_code\n        text = text.gsub(/\\\\n(.*?)\\\\n/) { \"\\n```\\n#{$1}\\n```\\n\" }\n      else\n        last_pos = text.rindex(/\\n/)\n\n        if last_pos\n          array = [text[0..last_pos].strip, text[last_pos + 1..text.length].strip]\n          text = array.join(\"\\n```\\n\")\n        else\n          text = \"\\n```\\n#{text}\"\n        end",
    "comment": "In the Quill format used by Vanilla Forums, a line is rendered as `code` when it's followed by a fragment with attributes: {'code-block': true}.",
    "label": "",
    "id": "903"
  },
  {
    "raw_code": "def table_name(name = nil)\n    DB_TABLE_PREFIX + name\n  end",
    "comment": "add the prefix to the table name",
    "label": "",
    "id": "904"
  },
  {
    "raw_code": "def get_knowledge_about_group\n    group_table = table_name \"common_usergroup\"\n    result =\n      mysql_query(\n        \"SELECT groupid group_id, radminid role_id\n             FROM #{group_table};\",\n      )\n    @moderator_group_id = []\n    @admin_group_id = []\n    #@banned_group_id = [4,5] # \n\n    result.each do |group|\n      case group[\"role_id\"]\n      when 1 # \n        @admin_group_id << group[\"group_id\"]\n      when 2,\n           3 # Discourse3\n        @moderator_group_id << group[\"group_id\"]\n      end",
    "comment": "find which group members can be granted as admin",
    "label": "",
    "id": "905"
  },
  {
    "raw_code": "def is_first_pm(pm_id, thread_id)\n    result =\n      mysql_query(\n        \"\n          SELECT pmid id\n            FROM #{table_name \"ucenter_pm_indexes\"}\n           WHERE plid = #{thread_id}\n        ORDER BY id\",\n      )\n    result.first[\"id\"].to_s == pm_id.to_s\n  end",
    "comment": "search for first pm id for the series of pm",
    "label": "",
    "id": "906"
  },
  {
    "raw_code": "def import_attachments\n    setting = AUTHORIZED_EXTENSIONS.join(\"|\")\n    SiteSetting.authorized_extensions = setting if setting != SiteSetting.authorized_extensions\n\n    attachment_regex = %r{\\[attach\\](\\d+)\\[/attach\\]}\n    attachment_link_regex = %r{\\[x-attach\\](.+)\\[/x-attach\\]}\n\n    current_count = 0\n    total_count =\n      mysql_query(\"SELECT count(*) count FROM #{table_name \"forum_post\"};\").first[\"count\"]\n\n    success_count = 0\n    fail_count = 0\n\n    puts \"\", \"Importing attachments...\", \"\"\n\n    Post.find_each do |post|\n      next unless post.custom_fields[\"import_id\"] == post.custom_fields[\"import_id\"].to_i.to_s\n\n      user = post.user\n\n      current_count += 1\n      print_status current_count, total_count\n\n      new_raw = post.raw.dup\n\n      inline_attachments = []\n\n      new_raw.gsub!(attachment_regex) do |s|\n        attachment_id = $1.to_i\n        inline_attachments.push attachment_id\n\n        upload, filename = find_upload(user, post, attachment_id)\n        unless upload\n          fail_count += 1\n          next\n        end",
    "comment": "This step is done separately because it can take multiple attempts to get right (because of missing files, wrong paths, authorized extensions, etc.).",
    "label": "",
    "id": "907"
  },
  {
    "raw_code": "def discuzx_avatar_fullpath(user_id, absolute = true)\n    padded_id = user_id.to_s.rjust(9, \"0\")\n\n    part_1 = padded_id[0..2]\n    part_2 = padded_id[3..4]\n    part_3 = padded_id[5..6]\n    part_4 = padded_id[-2..-1]\n    file_name = \"#{part_4}_avatar_big.jpg\"\n\n    if absolute\n      [File.join(DISCUZX_BASE_DIR, AVATAR_DIR, part_1, part_2, part_3, file_name), file_name]\n    else\n      [File.join(AVATAR_DIR, part_1, part_2, part_3, file_name), file_name]\n    end",
    "comment": "Create the full path to the discuz avatar specified from user id",
    "label": "",
    "id": "908"
  },
  {
    "raw_code": "def find_post_id_by_quote_number(raw)\n    case raw\n    when /\\[url=forum.php\\?mod=redirect&goto=findpost&pid=(\\d+)&ptid=\\d+\\]/ #standard\n      $1\n    when %r{\\[url=https?://#{ORIGINAL_SITE_PREFIX}/redirect.php\\?goto=findpost&pid=(\\d+)&ptid=\\d+\\]} # old discuz 7 format\n      $1\n    when %r{\\[quote\\][\\S\\s]*pid=(\\d+)[\\S\\s]*\\[/quote\\]} # quote\n      $1\n    end",
    "comment": "post id is in the quote block",
    "label": "",
    "id": "909"
  },
  {
    "raw_code": "def upload_inline_image(data)\n    return unless data\n\n    puts \"Creating inline image\"\n\n    encoded_photo = data[\"data:image/png;base64,\".length..-1]\n    if encoded_photo\n      raw_file = Base64.decode64(encoded_photo)\n    else\n      puts \"Error parsed inline photo\", data[0..20]\n      return\n    end",
    "comment": "for some reason, discuz inlined some png file the corresponding image stored is broken in a way",
    "label": "",
    "id": "910"
  },
  {
    "raw_code": "def find_upload(user, post, upload_id)\n    attachment_table = table_name \"forum_attachment\"\n    # search for table id\n    sql =\n      \"SELECT a.pid post_id,\n                  a.aid upload_id,\n                  a.tableid table_id\n             FROM #{attachment_table} a\n            WHERE a.pid = #{post.custom_fields[\"import_id\"]}\n              AND a.aid = #{upload_id};\"\n    results = mysql_query(sql)\n\n    unless (meta_data = results.first)\n      puts \"Couldn't find forum_attachment record meta data for post.id = #{post.id}, import_id = #{post.custom_fields[\"import_id\"]}\"\n      return nil\n    end",
    "comment": "find the uploaded file and real name from the db",
    "label": "",
    "id": "911"
  },
  {
    "raw_code": "def not_find_upload(post, attachment_id)\n    sql =\n      \"SELECT a.attachmentid attachment_id, a.userid user_id, a.filedataid file_id, a.filename filename,\n                  a.caption caption\n             FROM #{TABLE_PREFIX}attachment a\n            WHERE a.attachmentid = #{attachment_id}\"\n    results = mysql_query(sql)\n\n    unless row = results.first\n      puts \"Couldn't find attachment record for post.id = #{post.id}, import_id = #{post.custom_fields[\"import_id\"]}\"\n      return\n    end",
    "comment": "find the uploaded file information from the db",
    "label": "",
    "id": "912"
  },
  {
    "raw_code": "def execute\n    raise NotImplementedError\n  end",
    "comment": "Implementation will do most of its work in its execute method. It will need to call create_users, create_categories, and create_posts.",
    "label": "",
    "id": "913"
  },
  {
    "raw_code": "def create_groups(results, opts = {})\n    created = 0\n    skipped = 0\n    failed = 0\n    total = opts[:total] || results.count\n\n    results.each do |result|\n      g = yield(result)\n\n      if g.nil? || group_id_from_imported_group_id(g[:id])\n        skipped += 1\n      else\n        new_group = create_group(g, g[:id])\n        created_group(new_group)\n\n        if new_group.valid?\n          add_group(g[:id].to_s, new_group)\n          created += 1\n        else\n          failed += 1\n          puts \"Failed to create group id #{g[:id]} #{new_group.name}: #{new_group.errors.full_messages}\"\n        end",
    "comment": "Iterate through a list of groups to be imported. Takes a collection and yields to the block for each element. Block should return a hash with the attributes for each element. Required fields are :id and :name, where :id is the id of the group in the original datasource. The given id will not be used to create the Discourse group record.",
    "label": "",
    "id": "914"
  },
  {
    "raw_code": "def create_users(results, opts = {})\n    created = 0\n    skipped = 0\n    failed = 0\n    total = opts[:total] || results.count\n\n    results.each do |result|\n      u = yield(result)\n\n      # block returns nil to skip a user\n      if u.nil?\n        skipped += 1\n      else\n        import_id = u[:id]\n\n        if user_id_from_imported_user_id(import_id)\n          skipped += 1\n        else\n          new_user = create_user(u, import_id)\n          created_user(new_user)\n\n          if new_user && new_user.valid? && new_user.user_profile && new_user.user_profile.valid?\n            add_user(import_id.to_s, new_user)\n            created += 1\n          else\n            failed += 1\n            puts \"Failed to create user id: #{import_id}, username: #{new_user.try(:username)}, email: #{new_user.try(:email)}\"\n            if new_user.try(:errors)\n              puts \"user errors: #{new_user.errors.full_messages}\"\n              if new_user.try(:user_profile).try(:errors)\n                puts \"user_profile errors: #{new_user.user_profile.errors.full_messages}\"\n              end",
    "comment": "Iterate through a list of user records to be imported. Takes a collection, and yields to the block for each element. Block should return a hash with the attributes for the User model. Required fields are :id and :email, where :id is the id of the user in the original datasource. The given id will not be used to create the Discourse user record.",
    "label": "",
    "id": "915"
  },
  {
    "raw_code": "def create_categories(results)\n    created = 0\n    skipped = 0\n    total = results.count\n\n    results.each do |c|\n      params = yield(c)\n\n      # block returns nil to skip\n      if params.nil? || category_id_from_imported_category_id(params[:id])\n        skipped += 1\n      else\n        # Basic massaging on the category name\n        params[:name] = \"Blank\" if params[:name].blank?\n        params[:name] = params[:name].strip\n        params[:name] = params[:name][0..49]\n\n        # make sure categories don't go more than 2 levels deep\n        if params[:parent_category_id]\n          top = Category.find_by_id(params[:parent_category_id])\n          top = top.parent_category while (top&.height_of_ancestors || -1) + 1 >=\n            SiteSetting.max_category_nesting\n          params[:parent_category_id] = top.id if top\n        end",
    "comment": "Iterates through a collection to create categories. The block should return a hash with attributes for the new category. Required fields are :id and :name, where :id is the id of the category in the original datasource. The given id will not be used to create the Discourse category record. Optional attributes are position, description, and parent_category_id.",
    "label": "",
    "id": "916"
  },
  {
    "raw_code": "def create_posts(results, opts = {})\n    skipped = 0\n    created = 0\n    total = opts[:total] || results.count\n    start_time = get_start_time(\"posts-#{total}\") # the post count should be unique enough to differentiate between posts and PMs\n\n    results.each do |r|\n      params = yield(r)\n\n      # block returns nil to skip a post\n      if params.nil?\n        skipped += 1\n      else\n        import_id = params.delete(:id).to_s\n\n        if post_id_from_imported_post_id(import_id)\n          skipped += 1\n        else\n          begin\n            new_post = create_post(params, import_id)\n            if new_post.is_a?(Post)\n              add_post(import_id, new_post)\n              add_topic(new_post)\n              created_post(new_post)\n              created += 1\n            else\n              skipped += 1\n              puts \"Error creating post #{import_id}. Skipping.\"\n              p new_post\n            end",
    "comment": "Iterates through a collection of posts to be imported. It can create topics and replies. Attributes will be passed to the PostCreator. Topics should give attributes title and category. Replies should provide topic_id. Use topic_lookup_from_imported_post_id to find the topic.",
    "label": "",
    "id": "917"
  },
  {
    "raw_code": "def create_bookmarks(results, opts = {})\n    created = 0\n    skipped = 0\n    total = opts[:total] || results.count\n\n    user = User.new\n    post = Post.new\n\n    results.each do |result|\n      params = yield(result)\n\n      # only the IDs are needed, so this should be enough\n      if params.nil?\n        skipped += 1\n      else\n        user.id = user_id_from_imported_user_id(params[:user_id])\n        post.id = post_id_from_imported_post_id(params[:post_id])\n\n        if user.id.nil? || post.id.nil?\n          skipped += 1\n          puts \"Skipping bookmark for user id #{params[:user_id]} and post id #{params[:post_id]}\"\n        else\n          begin\n            manager = BookmarkManager.new(user)\n            bookmark = manager.create_for(bookmarkable_id: post.id, bookmarkable_type: \"Post\")\n\n            created += 1 if manager.errors.none?\n            skipped += 1 if manager.errors.any?\n          rescue StandardError\n            skipped += 1\n          end",
    "comment": "Iterate through a list of bookmark records to be imported. Takes a collection, and yields to the block for each element. Block should return a hash with the attributes for the bookmark. Required fields are :user_id and :post_id, where both ids are the values in the original datasource.",
    "label": "",
    "id": "918"
  },
  {
    "raw_code": "def update_last_seen_at\n    puts \"\", \"Updating last seen at on users\"\n\n    DB.exec(\"UPDATE users SET last_seen_at = created_at WHERE last_seen_at IS NULL\")\n    DB.exec(\"UPDATE users SET last_seen_at = last_posted_at WHERE last_posted_at IS NOT NULL\")\n  end",
    "comment": "scripts that are able to import last_seen_at from the source data should override this method",
    "label": "",
    "id": "919"
  },
  {
    "raw_code": "def parse_tag_params(params)\n    params\n      .to_s\n      .strip\n      .scan(/(?<param>\\w+)=(?<value>(?:(?>\\S+)|\\s+(?!\\w+=))*)/)\n      .inject({}) do |h, e|\n        h[e[0]] = e[1]\n        h\n      end",
    "comment": "param1=value1=still1 value1 param2=value2 ... => {'param1' => 'value1=still1 value1', 'param2' => 'value2 ...'}",
    "label": "",
    "id": "920"
  },
  {
    "raw_code": "def build_nested_tag_regex(ltag, rtag = nil)\n      rtag ||= \"/\" + ltag\n      /\n        \\[#{ltag}(?-x:[ =](?<params>[^\\]]*))?\\]            # consume open tag, followed by...\n          (?<inner>(?:\n            (?> [^\\[]+ )                                   # non-tags, or...\n            |\n            \\[(?! #{ltag}(?-x:[ =][^\\]]*)?\\] | #{rtag}\\])  # different tags, or ...\n            |\n            (?<re>                                         # recursively matched tags of the same kind\n              \\[#{ltag}(?-x:[ =][^\\]]*)?\\]\n                (?:\n                  (?> [^\\[]+ )\n                  |\n                  \\[(?! #{ltag}(?-x:[ =][^\\]]*)?\\] | #{rtag}\\])\n                  |\n                  \\g<re>                                   # recursion here\n                )*\n              \\[#{rtag}\\]\n            )\n          )*)\n        \\[#{rtag}\\]\n      /x\n    end",
    "comment": "[tag param=value param2=value2] text [tag nested=true]text[/tag] [/tag] => match[:params] == 'param=value param2=value2' match[:inner] == \"\\n  text\\n  [tag nested=true]text[/tag]\\n\"",
    "label": "",
    "id": "921"
  },
  {
    "raw_code": "def import_categories_from_thread_prefixes\n    puts \"\", \"importing categories...\"\n\n    categories =\n      mysql_query(\n        \"\n                              SELECT prefix_id id\n                              FROM #{TABLE_PREFIX}thread_prefix\n                              ORDER BY prefix_id ASC\n                            \",\n      ).to_a\n\n    create_categories(categories) do |category|\n      { id: category[\"id\"], name: \"Category-#{category[\"id\"]}\" }\n    end",
    "comment": "This method is an alternative to import_categories. It uses prefixes instead of nodes.",
    "label": "",
    "id": "922"
  },
  {
    "raw_code": "def check_parent_id(id)\n    return nil if SITE_ID > 0 && id == SITE_ID\n    return CATEGORY_MAP_TO if CATEGORY_MAP_FROM > 0 && id == CATEGORY_MAP_FROM\n    id\n  end",
    "comment": "Some category parent id's need to be adjusted",
    "label": "",
    "id": "923"
  },
  {
    "raw_code": "def import_avatar(user, avatar_url)\n    if @filestore_root_directory.blank? || avatar_url.blank? || avatar_url.include?(\"anonymous\")\n      return\n    end",
    "comment": "TODO move into base importer (create_user) and use consistent error handling",
    "label": "",
    "id": "924"
  },
  {
    "raw_code": "def map_first_post(row, mapped)\n    mapped[:category] = @lookup.category_id_from_imported_category_id(row[:forum_id])\n    mapped[:title] = CGI.unescapeHTML(row[:topic_title]).strip[0...255]\n    mapped[:pinned_at] = mapped[:created_at] unless row[:topic_type] == Constants::POST_NORMAL\n    mapped[:pinned_globally] = row[:topic_type] == Constants::POST_GLOBAL\n    mapped[:post_create_action] = proc do |post|\n      @permalink_importer.create_for_topic(post.topic, row[:topic_id])\n    end",
    "comment": "TODO: use this to figure out to pin posts",
    "label": "",
    "id": "925"
  },
  {
    "raw_code": "def convert_username(username, post_id)\n    count = 0\n    username.gsub!(/\\s+/) do |a|\n      count += 1\n      \"_\"\n    end",
    "comment": "Discourse usernames don't allow spaces",
    "label": "",
    "id": "926"
  },
  {
    "raw_code": "def post_id_to_post_num_and_topic(quoted_post_id, post_id)\n    quoted_post_id_from_imported = post_id_from_imported_post_id(quoted_post_id.to_i)\n    if quoted_post_id_from_imported\n      begin\n        post = Post.find(quoted_post_id_from_imported)\n        \"post:#{post.post_number}, topic:#{post.topic_id}\"\n      rescue StandardError\n        puts \"Could not find migrated post #{quoted_post_id_from_imported} quoted by original post #{post_id} as #{quoted_post_id}\"\n        \"\"\n      end",
    "comment": "Take an original post id and return the migrated topic id and post number for it",
    "label": "",
    "id": "927"
  },
  {
    "raw_code": "def find_upload(post, attachment_id)\n    sql =\n      \"SELECT a.attachmentid attachment_id, a.userid user_id, a.attachmentid file_id, a.filename filename,\n                  LENGTH(a.filedata) AS dbsize, filedata\n             FROM #{TABLE_PREFIX}attachment a\n            WHERE a.attachmentid = #{attachment_id}\"\n    results = mysql_query(sql)\n\n    unless row = results.first\n      puts \"\",\n           \"\\tCouldn't find attachment record #{attachment_id} for post.id = #{post.id}, import_id = #{post.custom_fields[\"import_id\"]}\"\n      return nil, nil\n    end",
    "comment": "find the uploaded file information from the db",
    "label": "",
    "id": "928"
  },
  {
    "raw_code": "def find_upload(post, attachment_id)\n    sql =\n      \"SELECT a.attachmentid attachment_id, a.userid user_id, a.filedataid file_id, a.filename filename,\n                  LENGTH(fd.filedata) AS dbsize, filedata, a.caption caption\n             FROM #{TABLE_PREFIX}attachment a\n             LEFT JOIN #{TABLE_PREFIX}filedata fd ON fd.filedataid = a.filedataid\n            WHERE a.attachmentid = #{attachment_id}\"\n    results = mysql_query(sql)\n\n    unless row = results.first\n      puts \"Couldn't find attachment record for post.id = #{post.id}, import_id = #{post.custom_fields[\"import_id\"]}\"\n      return\n    end",
    "comment": "find the uploaded file information from the db",
    "label": "",
    "id": "929"
  },
  {
    "raw_code": "def create_upload(user_id, path, source_filename)\n      tmp = copy_to_tempfile(path)\n\n      UploadCreator.new(tmp, source_filename).create_for(user_id)\n    rescue => e\n      STDERR.puts \"Failed to create upload: #{e}\"\n      nil\n    ensure\n      begin\n        tmp.close\n      rescue StandardError\n        nil\n      end",
    "comment": "Creates an upload. Expects path to be the full path and filename of the source file. @return [Upload]",
    "label": "",
    "id": "930"
  },
  {
    "raw_code": "def post_id_from_imported_post_id(import_id)\n      @posts[import_id] || @posts[import_id.to_s]\n    end",
    "comment": "Get the Discourse Post id based on the id of the source record",
    "label": "",
    "id": "931"
  },
  {
    "raw_code": "def topic_lookup_from_imported_post_id(import_id)\n      post_id = post_id_from_imported_post_id(import_id)\n      post_id ? @topics[post_id] : nil\n    end",
    "comment": "Get the Discourse topic info (a hash) based on the id of the source record",
    "label": "",
    "id": "932"
  },
  {
    "raw_code": "def group_id_from_imported_group_id(import_id)\n      @groups[import_id] || @groups[import_id.to_s]\n    end",
    "comment": "Get the Discourse Group id based on the id of the source group",
    "label": "",
    "id": "933"
  },
  {
    "raw_code": "def find_group_by_import_id(import_id)\n      GroupCustomField.where(name: \"import_id\", value: import_id.to_s).first.try(:group)\n    end",
    "comment": "Get the Discourse Group based on the id of the source group",
    "label": "",
    "id": "934"
  },
  {
    "raw_code": "def user_id_from_imported_user_id(import_id)\n      @users[import_id] || @users[import_id.to_s]\n    end",
    "comment": "Get the Discourse User id based on the id of the source user",
    "label": "",
    "id": "935"
  },
  {
    "raw_code": "def find_user_by_import_id(import_id)\n      UserCustomField.where(name: \"import_id\", value: import_id.to_s).first.try(:user)\n    end",
    "comment": "Get the Discourse User based on the id of the source user",
    "label": "",
    "id": "936"
  },
  {
    "raw_code": "def category_id_from_imported_category_id(import_id)\n      @categories[import_id] || @categories[import_id.to_s]\n    end",
    "comment": "Get the Discourse Category id based on the id of the source category",
    "label": "",
    "id": "937"
  },
  {
    "raw_code": "def initialize(settings, database)\n      @settings = settings\n      super()\n\n      @database = database\n      @php_config = database.get_config_values\n      @importers = ImporterFactory.new(@database, @lookup, @uploader, @settings, @php_config)\n    end",
    "comment": "@param settings [ImportScripts::PhpBB3::Settings] @param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1]",
    "label": "",
    "id": "938"
  },
  {
    "raw_code": "def use_bbcode_to_md?\n      false\n    end",
    "comment": "Do not use the bbcode_to_md in base.rb. It will be used in text_processor.rb instead.",
    "label": "",
    "id": "939"
  },
  {
    "raw_code": "def initialize(avatar_importer, settings)\n      @avatar_importer = avatar_importer\n      @settings = settings\n    end",
    "comment": "@param avatar_importer [ImportScripts::PhpBB3::AvatarImporter] @param settings [ImportScripts::PhpBB3::Settings]",
    "label": "",
    "id": "940"
  },
  {
    "raw_code": "def suspend_user(user, row, disable_email = false)\n      if row[:user_inactive_reason] == Constants::INACTIVE_MANUAL\n        user.suspended_at = Time.now\n        user.suspended_till = 200.years.from_now\n        ban_reason =\n          row[:ban_reason].blank? ? \"Account deactivated by administrator\" : row[:ban_reason] # TODO i18n\n      elsif row[:ban_start].present?\n        user.suspended_at = Time.zone.at(row[:ban_start])\n        user.suspended_till = row[:ban_end] > 0 ? Time.zone.at(row[:ban_end]) : 200.years.from_now\n        ban_reason = row[:ban_reason]\n      else\n        return\n      end",
    "comment": "Suspends the user if it is currently banned.",
    "label": "",
    "id": "941"
  },
  {
    "raw_code": "def initialize(database, lookup, text_processor, attachment_importer, settings)\n      @database = database\n      @lookup = lookup\n      @text_processor = text_processor\n      @attachment_importer = attachment_importer\n      @settings = settings\n    end",
    "comment": "@param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1] @param lookup [ImportScripts::LookupContainer] @param text_processor [ImportScripts::PhpBB3::TextProcessor] @param attachment_importer [ImportScripts::PhpBB3::AttachmentImporter] @param settings [ImportScripts::PhpBB3::Settings]",
    "label": "",
    "id": "942"
  },
  {
    "raw_code": "def sorted_user_ids(author_id, to_address)\n      user_ids = get_recipient_user_ids(to_address)\n      user_ids << author_id unless author_id.nil?\n      user_ids.uniq!\n      user_ids.sort!\n    end",
    "comment": "Creates a sorted array consisting of the message's author and recipients.",
    "label": "",
    "id": "943"
  },
  {
    "raw_code": "def find_topic_id(row, current_user_ids)\n      topic_title = get_topic_title(row).downcase\n      topic_titles = [topic_title]\n      topic_titles << topic_title[RE_PREFIX.length..-1] if topic_title.start_with?(RE_PREFIX)\n\n      Post\n        .select(:topic_id)\n        .joins(:topic)\n        .joins(:_custom_fields)\n        .where(\n          [\n            \"LOWER(topics.title) IN (:titles) AND post_custom_fields.name = 'import_user_ids' AND post_custom_fields.value = :user_ids\",\n            { titles: topic_titles, user_ids: current_user_ids.join(\",\") },\n          ],\n        )\n        .order(\"topics.created_at DESC\")\n        .first\n        .try(:topic_id)\n    end",
    "comment": "Tries to find a Discourse topic (private message) that has the same title as the current message. The users involved in these messages must match too.",
    "label": "",
    "id": "944"
  },
  {
    "raw_code": "def initialize(\n      lookup,\n      text_processor,\n      attachment_importer,\n      poll_importer,\n      permalink_importer,\n      settings\n    )\n      @lookup = lookup\n      @text_processor = text_processor\n      @attachment_importer = attachment_importer\n      @poll_importer = poll_importer\n      @permalink_importer = permalink_importer\n      @settings = settings\n    end",
    "comment": "@param lookup [ImportScripts::LookupContainer] @param text_processor [ImportScripts::PhpBB3::TextProcessor] @param attachment_importer [ImportScripts::PhpBB3::AttachmentImporter] @param poll_importer [ImportScripts::PhpBB3::PollImporter] @param permalink_importer [ImportScripts::PhpBB3::PermalinkImporter] @param settings [ImportScripts::PhpBB3::Settings]",
    "label": "",
    "id": "945"
  },
  {
    "raw_code": "def initialize(database, uploader, settings, phpbb_config)\n      @database = database\n      @uploader = uploader\n\n      @attachment_path = File.join(settings.base_dir, phpbb_config[:attachment_path])\n    end",
    "comment": "@param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1] @param uploader [ImportScripts::Uploader] @param settings [ImportScripts::PhpBB3::Settings] @param phpbb_config [Hash]",
    "label": "",
    "id": "946"
  },
  {
    "raw_code": "def initialize(uploader, settings, phpbb_config)\n      @uploader = uploader\n      @settings = settings\n\n      @uploaded_avatar_path = File.join(settings.base_dir, phpbb_config[:avatar_path])\n      @gallery_path = File.join(settings.base_dir, phpbb_config[:avatar_gallery_path])\n      @avatar_salt = phpbb_config[:avatar_salt]\n    end",
    "comment": "@param uploader [ImportScripts::Uploader] @param settings [ImportScripts::PhpBB3::Settings] @param phpbb_config [Hash]",
    "label": "",
    "id": "947"
  },
  {
    "raw_code": "def download_avatar(url)\n      max_image_size_kb = SiteSetting.max_image_size_kb.kilobytes\n\n      begin\n        avatar_file =\n          FileHelper.download(\n            url,\n            max_file_size: max_image_size_kb,\n            tmp_file_name: \"discourse-avatar\",\n            follow_redirect: true,\n          )\n      rescue StandardError => err\n        warn \"Error downloading avatar: #{err.message}. Skipping...\"\n        return nil\n      end",
    "comment": "Tries to download the remote avatar.",
    "label": "",
    "id": "948"
  },
  {
    "raw_code": "def initialize(lookup, text_processor, permalink_importer, settings)\n      @lookup = lookup\n      @text_processor = text_processor\n      @permalink_importer = permalink_importer\n      @settings = settings\n    end",
    "comment": "@param lookup [ImportScripts::LookupContainer] @param text_processor [ImportScripts::PhpBB3::TextProcessor] @param permalink_importer [ImportScripts::PhpBB3::PermalinkImporter] @param settings [ImportScripts::PhpBB3::Settings]",
    "label": "",
    "id": "949"
  },
  {
    "raw_code": "def update_category_description(category, row)\n      return if row[:forum_desc].blank? && row[:first_post_time].blank?\n\n      topic = category.topic\n      post = topic.first_post\n\n      if row[:first_post_time].present?\n        created_at = Time.zone.at(row[:first_post_time])\n\n        topic.created_at = created_at\n        topic.save\n\n        post.created_at = created_at\n        post.save\n      end",
    "comment": "@param category [Category]",
    "label": "",
    "id": "950"
  },
  {
    "raw_code": "def initialize(settings)\n      @settings = settings\n    end",
    "comment": "@param settings [ImportScripts::PhpBB3::PermalinkSettings]",
    "label": "",
    "id": "951"
  },
  {
    "raw_code": "def initialize(database, lookup, uploader, settings, phpbb_config)\n      @database = database\n      @lookup = lookup\n      @uploader = uploader\n      @settings = settings\n      @phpbb_config = phpbb_config\n    end",
    "comment": "@param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1] @param lookup [ImportScripts::LookupContainer] @param uploader [ImportScripts::Uploader] @param settings [ImportScripts::PhpBB3::Settings] @param phpbb_config [Hash]",
    "label": "",
    "id": "952"
  },
  {
    "raw_code": "def initialize(lookup, database, text_processor, settings)\n      @lookup = lookup\n      @database = database\n      @text_processor = text_processor\n      @settings = settings\n    end",
    "comment": "@param lookup [ImportScripts::LookupContainer] @param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1] @param text_processor [ImportScripts::PhpBB3::TextProcessor] @param settings [ImportScripts::PhpBB3::Settings]",
    "label": "",
    "id": "953"
  },
  {
    "raw_code": "def create_raw(topic_id, poll_data)\n      poll_data.options = get_poll_options(topic_id)\n      get_poll_text(poll_data)\n    end",
    "comment": "@param poll_data [ImportScripts::PhpBB3::PollData]",
    "label": "",
    "id": "954"
  },
  {
    "raw_code": "def update_poll(topic_id, post, poll_data)\n      if poll = post.polls.first\n        update_anonymous_voters(topic_id, poll_data, poll)\n        create_votes(topic_id, poll_data, poll)\n      end",
    "comment": "@param post [Post] @param poll_data [ImportScripts::PhpBB3::PollData]",
    "label": "",
    "id": "955"
  },
  {
    "raw_code": "def get_poll_text(poll_data)\n      title =\n        begin\n          @text_processor.process_raw_text(poll_data.title)\n        rescue StandardError\n          poll_data.title\n        end",
    "comment": "@param poll_data [ImportScripts::PhpBB3::PollData]",
    "label": "",
    "id": "956"
  },
  {
    "raw_code": "def update_anonymous_voters(topic_id, poll_data, poll)\n      row = @database.get_voters(topic_id)\n\n      if row[:anonymous_voters] > 0\n        poll.update!(anonymous_voters: row[:anonymous_voters])\n\n        poll.poll_options.each_with_index do |option, index|\n          imported_option = poll_data.options[index]\n\n          if imported_option[:anonymous_votes] > 0\n            option.update!(anonymous_votes: imported_option[:anonymous_votes])\n          end",
    "comment": "@param poll_data [ImportScripts::PhpBB3::PollData] @param poll [Poll]",
    "label": "",
    "id": "957"
  },
  {
    "raw_code": "def map_poll_options(poll_data, poll)\n      option_ids = {}\n\n      poll.poll_options.each_with_index do |option, index|\n        imported_option = poll_data.options[index]\n\n        imported_option[:ids].each { |imported_id| option_ids[imported_id] = option.id }\n      end",
    "comment": "@param poll_data [ImportScripts::PhpBB3::PollData] @param poll [Poll]",
    "label": "",
    "id": "958"
  },
  {
    "raw_code": "def create_votes(topic_id, poll_data, poll)\n      mapped_option_ids = map_poll_options(poll_data, poll)\n      rows = @database.fetch_poll_votes(topic_id)\n\n      rows.each do |row|\n        option_id = mapped_option_ids[row[:poll_option_id]]\n        user_id = @lookup.user_id_from_imported_user_id(@settings.prefix(row[:user_id]))\n\n        if option_id.present? && user_id.present?\n          PollVote.create!(poll: poll, poll_option_id: option_id, user_id: user_id)\n        end",
    "comment": "@param poll_data [ImportScripts::PhpBB3::PollData] @param poll [Poll]",
    "label": "",
    "id": "959"
  },
  {
    "raw_code": "def self.create(database_settings)\n      Database.new(database_settings).create_database\n    end",
    "comment": "@param database_settings [ImportScripts::PhpBB3::DatabaseSettings]",
    "label": "",
    "id": "960"
  },
  {
    "raw_code": "def initialize(database_settings)\n      @database_settings = database_settings\n      @database_client = create_database_client\n    end",
    "comment": "@param database_settings [ImportScripts::PhpBB3::DatabaseSettings]",
    "label": "",
    "id": "961"
  },
  {
    "raw_code": "def create_database\n      version = get_phpbb_version\n\n      if version.start_with?(\"3.0\")\n        require_relative \"database_3_0\"\n        Database_3_0.new(@database_client, @database_settings)\n      elsif version.start_with?(\"3.1\") || version.start_with?(\"3.2\") || version.start_with?(\"3.3\")\n        require_relative \"database_3_1\"\n        Database_3_1.new(@database_client, @database_settings)\n      else\n        raise UnsupportedVersionError, <<~TEXT\n          Unsupported version (#{version}) of phpBB detected.\n          Currently only version 3.0, 3.1, 3.2 and 3.3 are supported by this importer.\n        TEXT\n      end",
    "comment": "@return [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1]",
    "label": "",
    "id": "962"
  },
  {
    "raw_code": "def initialize(database_client, database_settings)\n      @database_client = database_client\n\n      @batch_size = database_settings.batch_size\n      @table_prefix = database_settings.table_prefix\n    end",
    "comment": "@param database_client [Mysql2::Client] @param database_settings [ImportScripts::PhpBB3::DatabaseSettings]",
    "label": "",
    "id": "963"
  },
  {
    "raw_code": "def query(sql, *last_columns)\n      rows = @database_client.query(sql, cache_rows: true, symbolize_keys: true)\n      return rows if last_columns.length == 0\n\n      result = [rows]\n      last_row = find_last_row(rows)\n\n      last_columns.each { |column| result.push(last_row ? last_row[column] : nil) }\n      result\n    end",
    "comment": "Executes a database query.",
    "label": "",
    "id": "964"
  },
  {
    "raw_code": "def count(sql)\n      query(sql).first[:count]\n    end",
    "comment": "Executes a database query and returns the value of the 'count' column.",
    "label": "",
    "id": "965"
  },
  {
    "raw_code": "def initialize(uploader, database, settings, phpbb_config)\n      @uploader = uploader\n      @database = database\n      @smilies_path = File.join(settings.base_dir, phpbb_config[:smilies_path])\n\n      @smiley_map = {}\n      add_default_smilies\n      add_configured_smilies(settings.emojis)\n    end",
    "comment": "@param uploader [ImportScripts::Uploader] @param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1] @param settings [ImportScripts::PhpBB3::Settings] @param phpbb_config [Hash]",
    "label": "",
    "id": "966"
  },
  {
    "raw_code": "def initialize(lookup, database, smiley_processor, settings, phpbb_config)\n      @lookup = lookup\n      @database = database\n      @smiley_processor = smiley_processor\n      @he = HTMLEntities.new\n      @use_xml_to_markdown =\n        phpbb_config[:phpbb_version].start_with?(\"3.2\") ||\n          phpbb_config[:phpbb_version].start_with?(\"3.3\")\n\n      @settings = settings\n      @new_site_prefix = settings.new_site_prefix\n      create_internal_link_regexps(settings.original_site_prefix)\n    end",
    "comment": "@param lookup [ImportScripts::LookupContainer] @param database [ImportScripts::PhpBB3::Database_3_0 | ImportScripts::PhpBB3::Database_3_1] @param smiley_processor [ImportScripts::PhpBB3::SmileyProcessor] @param settings [ImportScripts::PhpBB3::Settings] @param phpbb_config [Hash]",
    "label": "",
    "id": "967"
  },
  {
    "raw_code": "def process_attachments(text, attachments)\n      attachment_regexp =\n        %r{\\[attachment=([\\d])+\\]<!-- [\\w]+ -->([^<]+)<!-- [\\w]+ -->\\[/attachment\\]?}i\n      unreferenced_attachments = attachments.dup\n\n      text.gsub!(attachment_regexp) do\n        index = $1.to_i\n        real_filename = $2\n        unreferenced_attachments[index] = nil\n        attachments.fetch(index, real_filename)\n      end",
    "comment": "This replaces existing [attachment] BBCodes with the corresponding HTML tags for Discourse. All attachments that haven't been referenced in the text are appended to the end of the text.",
    "label": "",
    "id": "968"
  },
  {
    "raw_code": "def to_markdown(md_parent)\n      markdown = +\"\"\n\n      md_parent.children.each do |md_node|\n        prefix = md_node.prefix\n        text = md_node.children&.any? ? to_markdown(md_node) : md_node.text\n        postfix = md_node.postfix\n\n        parent_prefix = prefix_from_parent(md_parent)\n\n        if parent_prefix && md_node.xml_node_name != \"br\" &&\n             (md_parent.prefix_children || !markdown.empty?)\n          prefix = \"#{parent_prefix}#{prefix}\"\n        end",
    "comment": "@param md_parent [MarkdownNode]",
    "label": "",
    "id": "969"
  },
  {
    "raw_code": "def initialize(xml_node_name:, parent:)\n      @xml_node_name = xml_node_name\n\n      @text = +\"\"\n      @prefix = +\"\"\n      @postfix = +\"\"\n\n      @prefix_linebreaks = 0\n      @postfix_linebreaks = 0\n\n      @prefix_linebreak_type = LINEBREAK_AUTO\n      @postfix_linebreak_type = LINEBREAK_AUTO\n\n      @parent = parent\n      @children = []\n\n      if @parent\n        @previous_sibling = @parent.children.last\n        @previous_sibling.next_sibling = self if @previous_sibling\n        @parent.children << self\n      end",
    "comment": "@param xml_node_name [String] @param parent [MarkdownNode]",
    "label": "",
    "id": "970"
  },
  {
    "raw_code": "def initialize(database, settings)\n      @database = database\n      @settings = settings\n      @split_regex = settings.split_regex\n    end",
    "comment": "@param database [ImportScripts::Mbox::Database] @param settings [ImportScripts::Mbox::Settings]",
    "label": "",
    "id": "971"
  },
  {
    "raw_code": "def title(value = (getter = true; nil))\n        if getter\n          return(\n            @title ||=\n              I18n.t(\n                \"importer.default_step_title\",\n                type: name&.demodulize&.underscore&.humanize(capitalize: false),\n              )\n          )\n        end",
    "comment": "stree-ignore",
    "label": "",
    "id": "972"
  },
  {
    "raw_code": "def table_name(value = (getter = true; nil))\n        return @table_name if getter\n        @table_name = value\n      end",
    "comment": "stree-ignore",
    "label": "",
    "id": "973"
  },
  {
    "raw_code": "def column_names(value = (getter = true; nil))\n        return @column_names if getter\n        @column_names = value\n      end",
    "comment": "stree-ignore",
    "label": "",
    "id": "974"
  },
  {
    "raw_code": "def total_rows_query(query = (getter = true; nil), *parameters)\n        return [@total_rows_query, @total_rows_query_parameters] if getter\n\n        @total_rows_query = query\n        @total_rows_query_parameters = parameters\n        nil\n      end",
    "comment": "stree-ignore",
    "label": "",
    "id": "975"
  },
  {
    "raw_code": "def rows_query(query = (getter = true; nil), *parameters)\n        return [@rows_query, @rows_query_parameters] if getter\n\n        @rows_query = query\n        @rows_query_parameters = parameters\n        nil\n      end",
    "comment": "stree-ignore",
    "label": "",
    "id": "976"
  },
  {
    "raw_code": "def reset_memoization(instance, *variables)\n  variables.each do |var|\n    instance.remove_instance_variable(var) if instance.instance_variable_defined?(var)\n  end",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "977"
  },
  {
    "raw_code": "def self.test_setup(x = nil)\n    RateLimiter.disable\n    PostActionNotifier.disable\n    SearchIndexer.disable\n    UserActionManager.disable\n    NotificationEmailer.disable\n    SiteIconManager.disable\n    WordWatcher.disable_cache\n\n    SiteSetting.provider.all.each { |setting| SiteSetting.remove_override!(setting.name) }\n    SiteSetting.refresh!(refresh_site_settings: false, refresh_theme_site_settings: true)\n\n    # very expensive IO operations\n    SiteSetting.automatically_download_gravatars = false\n\n    Discourse.clear_readonly!\n    Sidekiq::Worker.clear_all\n\n    I18n.locale = SiteSettings::DefaultsProvider::DEFAULT_LOCALE\n\n    RspecErrorTracker.clear_exceptions\n\n    if $test_cleanup_callbacks\n      $test_cleanup_callbacks.reverse_each(&:call)\n      $test_cleanup_callbacks = nil\n    end",
    "comment": "This is run before each test and before each before_all block",
    "label": "",
    "id": "978"
  },
  {
    "raw_code": "def test_multisite_connection(name)\n    RailsMultisite::ConnectionManagement.with_connection(name) do\n      ActiveRecord::Base.transaction(joinable: false) do\n        yield\n        raise ActiveRecord::Rollback\n      end",
    "comment": "Normally we `use_transactional_fixtures` to clear out a database after a test runs. However, this does not apply to tests done for multisite. The second time a test runs you can end up with stale data that breaks things. This method will force a rollback after using a multisite connection.",
    "label": "",
    "id": "979"
  },
  {
    "raw_code": "def freeze_time_safe\n  freeze_time(DateTime.parse(\"2014-08-26 12:00:00\"))\nend",
    "comment": "Time.now can cause flaky tests, especially in cases like leap days. This method freezes time at a \"safe\" specific time (the Discourse 1.1 release date), so it will not be affected by further temporal disruptions.",
    "label": "",
    "id": "980"
  },
  {
    "raw_code": "def swap_2_different_characters(str)\n  swap1 = 0\n  swap2 = str.split(\"\").find_index { |c| c != str[swap1] }\n  # if the string is made up of 1 character\n  return str if !swap2\n  str = str.dup\n  str[swap1], str[swap2] = str[swap2], str[swap1]\n  str\nend",
    "comment": "this takes a string and returns a copy where 2 different characters are swapped. e.g. swap_2_different_characters(\"abc\") => \"bac\" swap_2_different_characters(\"aac\") => \"caa\"",
    "label": "",
    "id": "981"
  },
  {
    "raw_code": "def extract_locale(path)\n  path[/\\.([^.]{2,})\\.yml$/, 1]\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "982"
  },
  {
    "raw_code": "def list_files(base_dir, pattern = \"*\")\n  Dir[File.join(\"#{base_dir}\", pattern)]\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "983"
  },
  {
    "raw_code": "def auth_token_for(user)\n  {\n    provider: \"github\",\n    extra: {\n      all_emails: [{ email: user.email, primary: true, verified: true }],\n    },\n    info: {\n      email: user.email,\n      nickname: user.username,\n      name: user.name,\n      image: \"https://avatars3.githubusercontent.com/u/#{user.username}\",\n    },\n    uid: \"100\",\n  }\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "984"
  },
  {
    "raw_code": "def validate\n    @validator ||= TopicTitleLengthValidator.new(attributes: :title)\n    @validator.validate_each(record, :title, record.title)\n  end",
    "comment": "simulate Rails behavior (singleton)",
    "label": "",
    "id": "985"
  },
  {
    "raw_code": "def validate\n    @validator ||= MaxEmojisValidator.new(attributes: :title)\n    @validator.validate_each(record, :title, record.title)\n  end",
    "comment": "simulate Rails behavior (singleton)",
    "label": "",
    "id": "986"
  },
  {
    "raw_code": "def create_notification(type, user = nil)\n    user ||= Fabricate(:user)\n    Notification.create(\n      data: \"{\\\"a\\\": 1}\",\n      user: user,\n      notification_type: Notification.types[type],\n      topic: topic,\n      post_number: post.post_number,\n      skip_send_email: true,\n    )\n  end",
    "comment": "something is off with fabricator",
    "label": "",
    "id": "987"
  },
  {
    "raw_code": "def headers(locale)\n      { HTTP_ACCEPT_LANGUAGE: locale }\n    end",
    "comment": "Using /bootstrap.json because it returns a locale-dependent value",
    "label": "",
    "id": "988"
  },
  {
    "raw_code": "def create_notification(user_id, resp_code, matcher)\n  notification_count = Notification.count\n  post \"/notifications.json\",\n       params: {\n         notification_type: Notification.types[:mentioned],\n         user_id: user_id,\n         data: { message: \"tada\" }.to_json,\n       }\n  expect(response.status).to eq(resp_code)\n  expect(Notification.count).public_send(matcher, eq(notification_count))\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "989"
  },
  {
    "raw_code": "def custom(name, translation_key: nil)\n        AboutPageSiteActivityItem.new(\n          container.find(\".about__activities-item.#{name}\"),\n          translation_key:,\n        )\n      end",
    "comment": "used by plugins",
    "label": "",
    "id": "990"
  },
  {
    "raw_code": "def select_month(month)\n        parsed_month =\n          begin\n            Integer(month)\n          rescue StandardError\n            nil\n          end",
    "comment": "The month is 0-based. Month name can be provided too.",
    "label": "",
    "id": "991"
  },
  {
    "raw_code": "def has_custom_count?(text)\n        container.find(\".about__activities-item-count\").has_text?(text)\n      end",
    "comment": "used by plugins",
    "label": "",
    "id": "992"
  },
  {
    "raw_code": "def has_custom_period?(text)\n        period_element.has_text?(text)\n      end",
    "comment": "used by plugins",
    "label": "",
    "id": "993"
  },
  {
    "raw_code": "def has_search_menu?\n        page.has_css?(\".search-menu .search-menu-panel\", visible: false)\n      end",
    "comment": "This is used for cases like header and welcome banner search, where we show the search results with a quick tip, but the panel itself is not technically \"visible\" in CSS terms.",
    "label": "",
    "id": "994"
  },
  {
    "raw_code": "def visit(category)\n        page.visit(\"/c/#{category.id}\")\n        self\n      end",
    "comment": "keeping the various category related features combined for now",
    "label": "",
    "id": "995"
  },
  {
    "raw_code": "def has_form_template_enabled?\n        find(\".d-toggle-switch .toggle-template-type\", visible: false)[\"aria-checked\"] == \"true\"\n      end",
    "comment": "Edit Category Page",
    "label": "",
    "id": "996"
  },
  {
    "raw_code": "def has_form_template_table?\n        page.has_selector?(\"table.form-templates__table\")\n      end",
    "comment": "Form Template Index",
    "label": "",
    "id": "997"
  },
  {
    "raw_code": "def type_in_template_name(input)\n        find(\".form-templates__form-name-input\").fill_in(with: input)\n        self\n      end",
    "comment": "Form Template new/edit form related",
    "label": "",
    "id": "998"
  },
  {
    "raw_code": "def stub_empty_traffic_source_data\n      IncomingLinksReport.stubs(:link_count_per_domain).returns({})\n      IncomingLinksReport.stubs(:topic_count_per_domain).returns({})\n      IncomingLinksReport.stubs(:user_count_per_domain).returns({})\n    end",
    "comment": "TODO: STOP THE STUBBING",
    "label": "",
    "id": "999"
  },
  {
    "raw_code": "def stub_empty_referred_topics_data\n      IncomingLinksReport.stubs(:link_count_per_topic).returns({})\n    end",
    "comment": "TODO: STOP THE STUBBING",
    "label": "",
    "id": "1000"
  },
  {
    "raw_code": "def post_with_body(body, user = nil)\n    args = post_args.merge(raw: body)\n    args[:user] = user if user.present?\n    Fabricate.build(:post, args)\n  end",
    "comment": "Help us build a post with a raw body",
    "label": "",
    "id": "1001"
  },
  {
    "raw_code": "def run(*args)\n  out, err, status = Open3.capture3(*args)\n  raise \"Command failed: #{args.inspect}\\n#{out}\\n#{err}\" unless status.success?\n  out\nend",
    "comment": "frozen_string_literal: true",
    "label": "",
    "id": "1002"
  },
  {
    "raw_code": "def wait_for_animation(element, timeout: Capybara.default_max_wait_time)\n    old_element_x = nil\n    old_element_y = nil\n\n    try_until_success(timeout: timeout) do\n      current_element_x = element.rect[:x]\n      current_element_y = element.rect[:y]\n\n      stopped_moving = current_element_x == old_element_x && current_element_y == old_element_y\n\n      old_element_x = current_element_x\n      old_element_y = current_element_y\n\n      raise Capybara::ExpectationNotMet if !stopped_moving\n    end",
    "comment": "Waits for an element to stop animating up to timeout seconds, then raises a Capybara error if it does not stop.  This is based on getBoundingClientRect, where Y is the distance from the top of the element to the top of the viewport, and X is the distance from the leftmost edge of the element to the left of the viewport. The viewpoint origin (0, 0) is at the top left of the page.  Once X and Y stop changing based on the current vs previous position, then we know the animation has stopped and the element is stabilised, at which point we can click on it without fear of Capybara mis-clicking.  c.f. https://developer.mozilla.org/en-US/docs/Web/API/Element/getBoundingClientRect",
    "label": "",
    "id": "1003"
  },
  {
    "raw_code": "def with_security_key(user)\n    # The public and private keys are complicated to generate programmatically, so we generate it by running the\n    # `spec/user_preferences/security_keys_spec.rb` test and uncommenting the lines that print the keys.\n    public_key_base64 =\n      \"pQECAyYgASFYIJhY+jDNJM8g0lyKP3ivDxs+mrKXqfKUY3f7Uo4pWTPDIlggj03xktSm0JTSqbDefhu5WAKH7VRQmWXotjtI/8ka/P0=\"\n    private_key_base64 =\n      \"MIGHAgEAMBMGByqGSM49AgEGCCqGSM49AwEHBG0wawIBAQQg2AWg10o6aoM0s55halZvcQLnpM2tVO2D8Ugw7wFCjzyhRANCAASYWPowzSTPINJcij94rw8bPpqyl6nylGN3-1KOKVkzw49N8ZLUptCU0qmw3n4buVgCh-1UUJll6LY7SP_JGvz9\"\n    credential_id_base64 = Base64.strict_encode64(SecureRandom.random_bytes(32))\n    credential_id_bytes = Base64.urlsafe_decode64(credential_id_base64)\n    private_key_bytes = Base64.urlsafe_decode64(private_key_base64)\n\n    with_virtual_authenticator do |cdp_client, authenticator_id|\n      cdp_client.send_message(\n        \"WebAuthn.addCredential\",\n        params: {\n          authenticatorId: authenticator_id,\n          credential: {\n            credentialId: Base64.strict_encode64(credential_id_bytes),\n            isResidentCredential: false,\n            rpId: DiscourseWebauthn.rp_id,\n            privateKey: Base64.strict_encode64(private_key_bytes),\n            signCount: 1,\n          },\n        },\n      )\n\n      Fabricate(\n        :user_security_key,\n        user:,\n        public_key: public_key_base64,\n        credential_id: credential_id_base64,\n        name: \"First Key\",\n      )\n\n      yield\n    end",
    "comment": "This method can be used to run a system test with a user that has a physical security key by adding a virtual authenticator to the browser. It will automatically remove the virtual authenticator after the block is executed.  Example: with_security_key(user, options) do <your system test code here> end ",
    "label": "",
    "id": "1004"
  },
  {
    "raw_code": "def wait_for_timeout(ms = 100)\n    page.driver.with_playwright_page { |pw_page| pw_page.wait_for_timeout(ms) }\n  end",
    "comment": "should be used only on very rare occasion when you need to wait for something that is not visually changing on the page",
    "label": "",
    "id": "1005"
  },
  {
    "raw_code": "def upload_theme(set_theme_as_default: true)\n    theme = RemoteTheme.import_theme_from_directory(directory_from_caller)\n\n    if theme.component\n      raise NotAThemeError,\n            \"Uploaded theme is a theme component, please use the `upload_theme_component` method instead.\"\n    end",
    "comment": "Uploads a theme from a directory.  @param set_theme_as_default [Boolean] Whether to set the uploaded theme as the default theme for the site. Defaults to true.  @return [Theme] The uploaded theme model given by `models/theme.rb`.  @example Upload a theme and set it as default upload_theme(\"/path/to/theme\")",
    "label": "",
    "id": "1006"
  },
  {
    "raw_code": "def invoke_rake_task(task_name, *args)\n    Rake::Task[task_name].invoke(*args)\n  ensure\n    Rake::Task[task_name].reenable\n  end",
    "comment": "Invokes a Rake task in a way that is safe for the test environment",
    "label": "",
    "id": "1007"
  },
  {
    "raw_code": "def upload_theme_component(parent_theme_id: SiteSetting.default_theme_id)\n    theme = RemoteTheme.import_theme_from_directory(directory_from_caller)\n\n    if !theme.component\n      raise NotAComponentThemeError,\n            \"Uploaded theme is not a theme component, please use the `upload_theme` method instead.\"\n    end",
    "comment": "Uploads a theme component from a directory.  @param parent_theme_id [Integer] The ID of the theme to add the theme component to. Defaults to `SiteSetting.default_theme_id`.  @return [Theme] The uploaded theme model given by `models/theme.rb`.  @example Upload a theme component upload_theme_component(\"/path/to/theme_component\")  @example Upload a theme component and add it to a specific theme upload_theme_component(\"/path/to/theme_component\", parent_theme_id: 123)",
    "label": "",
    "id": "1008"
  },
  {
    "raw_code": "def run_theme_migration(theme, migration_name)\n    migration_theme_field = theme.theme_fields.find_by(name: migration_name)\n    theme.migrate_settings(fields: [migration_theme_field], allow_out_of_sequence_migration: true)\n    nil\n  end",
    "comment": "Runs named migration for a given theme.  @params [Theme] theme The theme to run the migration for. @params [String] migration_name The name of the migration to run.  @return [nil]  @example run_theme_migration(theme, \"0001-migrate-some-settings\")",
    "label": "",
    "id": "1009"
  },
  {
    "raw_code": "def valid_security_key_data\n    {\n      credential_id:\n        \"9GiFosW50+s+juyJlyxKEVAsk3gZLo9XWIhX47eC4gHfDsldF3TWR43Tcl/+3gLTL5t1TjpmcbKA2DUV2eKrBw==\",\n      public_key:\n        \"pQECAyYgASFYIPMGM1OpSuCU5uks+BulAdfVxdlJiYcgGac5Y+LnLXC9Ilgghy0BKvRvptmQdtWz33Jjnf8Y6+HD85XdRiqmo1KMGPE=\",\n    }\n  end",
    "comment": " Usage notes:  The valid_security_key_auth_post_data is derived from an actual YubiKey login attempt that is successful. No security risk is posed by this; this YubiKey has only ever been used for local credentials.  To make this all work together you need to create a UserSecurityKey for a user using valid_security_key_data, and you override DiscourseWebauthn::ChallengeGenerator.generate to return a DiscourseWebauthn::ChallengeGenerator::ChallengeSession object using valid_security_key_challenge_data.  This is because the challenge is embedded in the post data's authenticatorData and must match up. See simulate_localhost_webauthn_challenge for a real example. All of the valid security key data is sourced from a localhost login (with origin http://localhost:3000).",
    "label": "",
    "id": "1010"
  },
  {
    "raw_code": "def valid_passkey_challenge\n    \"66b47014ef72937d8320ed893dc797e8a9a6d5098b89b185ca3d439b3656\"\n  end",
    "comment": "Passkey data sourced from a key generated in a local browser with webauthn.create that includes the user verification flag on localhost:3000 usin puts statements in the passkeys session controllers",
    "label": "",
    "id": "1011"
  },
  {
    "raw_code": "def expect_enqueued_with(job:, args: {}, at: nil, expectation: true)\n    klass = job.instance_of?(Class) ? job : \"::Jobs::#{job.to_s.camelcase}\".constantize\n    at = at.to_f if at.is_a?(Time)\n    expected = { job: job, args: args, at: at }.compact\n    original_jobs = klass.jobs.dup\n\n    yield if block_given?\n\n    matched_job = false\n    jobs = klass.jobs - original_jobs\n    matched_job = match_jobs(jobs: jobs, args: args, at: at) if jobs.present?\n\n    expect(matched_job).to(\n      eq(expectation),\n      (\n        if expectation\n          \"No enqueued job with #{expected}\\nFound:\\n #{jobs.inspect}\"\n        else\n          \"Enqueued job with #{expected} found\"\n        end",
    "comment": "Assert job is enqueued:  expect_enqueued_with(job: :post_process, args: { post_id: post.id }) do post.update!(raw: 'new raw') end  Asserting jobs enqueued with delay:  expect_enqueued_with( job: :post_process, args: { post_id: post.id }, at: Time.zone.now + 1.hour ) do post.update!(raw: 'new raw') end",
    "label": "",
    "id": "1012"
  },
  {
    "raw_code": "def expect_not_enqueued_with(job:, args: {}, at: nil)\n    expect_enqueued_with(job: job, args: args, at: at, expectation: false) { yield if block_given? }\n  end",
    "comment": "Assert job is not enqueued:  expect_not_enqueued_with(job: :post_process) do post.update!(raw: 'new raw') end  Assert job is not enqueued with specific params  expect_not_enqueued_with(job: :post_process, args: { post_id: post.id }) do post.update!(raw: 'new raw') end",
    "label": "",
    "id": "1013"
  },
  {
    "raw_code": "def job_enqueued?(job:, args: {}, at: nil)\n    klass = job.instance_of?(Class) ? job : \"::Jobs::#{job.to_s.camelcase}\".constantize\n    at = at.to_f if at.is_a?(Time)\n    match_jobs(jobs: klass.jobs, args: args, at: at)\n  end",
    "comment": "Checks whether a job has been enqueued with the given arguments  job_enqueued?(job: :post_process, args: { post_id: post.id }) => true/false job_enqueued?(job: :post_process, args: { post_id: post.id }, at: Time.zone.now + 1.hour) => true/false",
    "label": "",
    "id": "1014"
  },
  {
    "raw_code": "def expect_job_enqueued(job:, args: {}, at: nil)\n    expect(job_enqueued?(job: job, args: args, at: at)).to eq(true)\n  end",
    "comment": "Same as job_enqueued? except it checks the expectation is true. Use this if you need to check if more than one job is enqueued from a single command, unlike expect_enqueued_with which needs a block to run code for the expectation to work. E.g.  expect_not_enqueued_with(job: :close_topic, args: { topic_timer_id: deleted_timer.id }) expect_not_enqueued_with(job: :close_topic, args: { topic_timer_id: future_timer.id }) subject.execute expect_job_enqueued(job: :close_topic, args: { topic_timer_id: timer1.id }) expect_job_enqueued(job: :open_topic, args: { topic_timer_id: timer2.id })",
    "label": "",
    "id": "1015"
  }
]